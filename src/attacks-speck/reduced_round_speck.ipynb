{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-round SPECK 32/32 (FNN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from pipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_rr.make_train_data import make_train_data\n",
    "from dataset_rr.speck import Speck"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_samples = 10**6\n",
    "n_eval_samples = 10**5\n",
    "n_rounds = 1\n",
    "\n",
    "cipher = Speck(n_rounds=n_rounds)\n",
    "\n",
    "key = cipher.draw_keys(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples, train_labels = make_train_data(n_train_samples, cipher, key)\n",
    "test_samples, test_labels = make_train_data(n_eval_samples, cipher, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Training Labels Shape: (1000000, 32)\n",
      "===== Label Shape: (32,)\n",
      "===== Training Samples Shape: (1000000, 32)\n",
      "===== Sample Shape: (32,)\n",
      "===== Testing Labels Shape: (100000, 32)\n",
      "===== Testing Samples Shape: (100000, 32)\n"
     ]
    }
   ],
   "source": [
    "get_dataset_info(train_labels, train_samples, test_labels, test_samples)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from keras import Sequential\n",
    "from keras.layers import Input, Dense, BatchNormalization, LayerNormalization\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model hyperparameters\n",
    "In this code block, we specify most parameters and hyperparameters that will be used in the training of the neural network.\n",
    "\n",
    "Add customization here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = np.shape(train_samples[0])\n",
    "\n",
    "# output dimension\n",
    "dim = len(train_labels[0])\n",
    "\n",
    "# units per hidden layer\n",
    "units = dim*16\n",
    "\n",
    "loss_scc = 'sparse_categorical_crossentropy'\n",
    "loss_mse = 'mse'\n",
    "loss_bce = 'binary_crossentropy'\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.1,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.01)\n",
    "learning_rate = 0.1\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "metrics = ['accuracy', 'binary_accuracy']\n",
    "epochs = 70\n",
    "batch_size = 5000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "In this code block, we create the model, according to the parameters and the topology we want to achieve. \n",
    "We then compile it specifying the optimizer, the loss and the metrics we want outputted.\n",
    "\n",
    "Add customization here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_42 (Dense)            (None, 512)               16896     \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 32)                16416     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,083,936\n",
      "Trainable params: 1,083,936\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Â Type of model\n",
    "neural_network = Sequential()\n",
    "\n",
    "# Input layer\n",
    "neural_network.add(Input(shape=input_shape))\n",
    "\n",
    "# Hidden layers\n",
    "#neural_network.add(BatchNormalization())\n",
    "neural_network.add(Dense(units=units, activation='relu'))\n",
    "neural_network.add(Dense(units=units, activation='relu'))\n",
    "neural_network.add(Dense(units=units, activation='relu'))\n",
    "neural_network.add(Dense(units=units, activation='relu'))\n",
    "neural_network.add(Dense(units=units, activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "neural_network.add(Dense(units=dim, activation='sigmoid'))\n",
    "\n",
    "# Summary\n",
    "neural_network.summary()\n",
    "\n",
    "# Compile model\n",
    "neural_network.compile(optimizer=optimizer, loss=loss_mse, metrics=metrics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "In this code block, we train the model. It outputs, for each epoch, the loss and metrics.\n",
    "\n",
    "This block mostly stays the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "180/180 [==============================] - 28s 152ms/step - loss: 0.1578 - accuracy: 0.0018 - binary_accuracy: 0.7126 - val_loss: 0.1163 - val_accuracy: 6.0000e-05 - val_binary_accuracy: 0.7802\n",
      "Epoch 2/70\n",
      "180/180 [==============================] - 27s 150ms/step - loss: 0.1056 - accuracy: 4.7778e-05 - binary_accuracy: 0.8092 - val_loss: 0.0943 - val_accuracy: 1.0000e-05 - val_binary_accuracy: 0.8397\n",
      "Epoch 3/70\n",
      "180/180 [==============================] - 26s 147ms/step - loss: 0.0759 - accuracy: 4.3333e-05 - binary_accuracy: 0.8845 - val_loss: 0.0544 - val_accuracy: 1.0000e-04 - val_binary_accuracy: 0.9255\n",
      "Epoch 4/70\n",
      "180/180 [==============================] - 26s 143ms/step - loss: 0.0398 - accuracy: 9.4333e-04 - binary_accuracy: 0.9483 - val_loss: 0.0262 - val_accuracy: 0.0022 - val_binary_accuracy: 0.9696\n",
      "Epoch 5/70\n",
      "180/180 [==============================] - 25s 140ms/step - loss: 0.0465 - accuracy: 0.0017 - binary_accuracy: 0.9501 - val_loss: 0.0483 - val_accuracy: 0.0058 - val_binary_accuracy: 0.9513\n",
      "Epoch 6/70\n",
      "180/180 [==============================] - 25s 139ms/step - loss: 0.0418 - accuracy: 0.0105 - binary_accuracy: 0.9569 - val_loss: 0.0376 - val_accuracy: 0.0220 - val_binary_accuracy: 0.9616\n",
      "Epoch 7/70\n",
      "180/180 [==============================] - 25s 138ms/step - loss: 0.0364 - accuracy: 0.0457 - binary_accuracy: 0.9631 - val_loss: 0.0356 - val_accuracy: 0.0690 - val_binary_accuracy: 0.9641\n",
      "Epoch 8/70\n",
      "180/180 [==============================] - 25s 139ms/step - loss: 0.0350 - accuracy: 0.0855 - binary_accuracy: 0.9648 - val_loss: 0.0349 - val_accuracy: 0.1110 - val_binary_accuracy: 0.9647\n",
      "Epoch 9/70\n",
      "180/180 [==============================] - 25s 139ms/step - loss: 0.0347 - accuracy: 0.1188 - binary_accuracy: 0.9650 - val_loss: 0.0353 - val_accuracy: 0.1098 - val_binary_accuracy: 0.9643\n",
      "Epoch 10/70\n",
      "180/180 [==============================] - 25s 140ms/step - loss: 0.0336 - accuracy: 0.1384 - binary_accuracy: 0.9663 - val_loss: 0.0335 - val_accuracy: 0.1611 - val_binary_accuracy: 0.9664\n",
      "Epoch 11/70\n",
      "180/180 [==============================] - 25s 140ms/step - loss: 0.0333 - accuracy: 0.1693 - binary_accuracy: 0.9666 - val_loss: 0.0335 - val_accuracy: 0.2017 - val_binary_accuracy: 0.9662\n",
      "Epoch 12/70\n",
      "180/180 [==============================] - 25s 139ms/step - loss: 0.0330 - accuracy: 0.1895 - binary_accuracy: 0.9670 - val_loss: 0.0327 - val_accuracy: 0.2132 - val_binary_accuracy: 0.9673\n",
      "Epoch 13/70\n",
      "180/180 [==============================] - 25s 139ms/step - loss: 0.0328 - accuracy: 0.2081 - binary_accuracy: 0.9671 - val_loss: 0.0331 - val_accuracy: 0.2206 - val_binary_accuracy: 0.9667\n",
      "Epoch 14/70\n",
      "180/180 [==============================] - 25s 139ms/step - loss: 0.1974 - accuracy: 0.1432 - binary_accuracy: 0.8012 - val_loss: 0.4451 - val_accuracy: 0.0158 - val_binary_accuracy: 0.5547\n",
      "Epoch 15/70\n",
      "180/180 [==============================] - 25s 138ms/step - loss: 0.4439 - accuracy: 0.0193 - binary_accuracy: 0.5561 - val_loss: 0.4438 - val_accuracy: 0.0235 - val_binary_accuracy: 0.5562\n",
      "Epoch 16/70\n",
      "180/180 [==============================] - 25s 139ms/step - loss: 0.4433 - accuracy: 0.0369 - binary_accuracy: 0.5567 - val_loss: 0.4435 - val_accuracy: 0.0450 - val_binary_accuracy: 0.5566\n",
      "Epoch 17/70\n",
      "180/180 [==============================] - 25s 139ms/step - loss: 0.4431 - accuracy: 0.0548 - binary_accuracy: 0.5569 - val_loss: 0.4433 - val_accuracy: 0.0663 - val_binary_accuracy: 0.5567\n",
      "Epoch 18/70\n",
      "180/180 [==============================] - 25s 140ms/step - loss: 0.4430 - accuracy: 0.0687 - binary_accuracy: 0.5570 - val_loss: 0.4433 - val_accuracy: 0.0716 - val_binary_accuracy: 0.5567\n",
      "Epoch 19/70\n",
      "180/180 [==============================] - 25s 138ms/step - loss: 0.4430 - accuracy: 0.0788 - binary_accuracy: 0.5571 - val_loss: 0.4432 - val_accuracy: 0.0797 - val_binary_accuracy: 0.5568\n",
      "Epoch 20/70\n",
      "180/180 [==============================] - 25s 139ms/step - loss: 0.4429 - accuracy: 0.0874 - binary_accuracy: 0.5571 - val_loss: 0.4432 - val_accuracy: 0.0940 - val_binary_accuracy: 0.5568\n",
      "Epoch 21/70\n",
      "180/180 [==============================] - 25s 139ms/step - loss: 0.4429 - accuracy: 0.0950 - binary_accuracy: 0.5571 - val_loss: 0.4432 - val_accuracy: 0.0973 - val_binary_accuracy: 0.5568\n",
      "Epoch 22/70\n",
      "180/180 [==============================] - 25s 139ms/step - loss: 0.4429 - accuracy: 0.1021 - binary_accuracy: 0.5571 - val_loss: 0.4431 - val_accuracy: 0.1026 - val_binary_accuracy: 0.5569\n",
      "Epoch 23/70\n",
      "180/180 [==============================] - 25s 139ms/step - loss: 0.4429 - accuracy: 0.1077 - binary_accuracy: 0.5571 - val_loss: 0.4434 - val_accuracy: 0.0979 - val_binary_accuracy: 0.5566\n",
      "Epoch 24/70\n",
      "180/180 [==============================] - 25s 140ms/step - loss: 0.4429 - accuracy: 0.1079 - binary_accuracy: 0.5571 - val_loss: 0.4431 - val_accuracy: 0.1039 - val_binary_accuracy: 0.5569\n",
      "Epoch 25/70\n",
      "180/180 [==============================] - 25s 138ms/step - loss: 0.4429 - accuracy: 0.1159 - binary_accuracy: 0.5572 - val_loss: 0.4431 - val_accuracy: 0.1177 - val_binary_accuracy: 0.5569\n",
      "Epoch 26/70\n",
      "180/180 [==============================] - 25s 139ms/step - loss: 0.4243 - accuracy: 0.0800 - binary_accuracy: 0.5736 - val_loss: 0.3155 - val_accuracy: 0.0024 - val_binary_accuracy: 0.6629\n",
      "Epoch 27/70\n",
      "180/180 [==============================] - 25s 140ms/step - loss: 0.0643 - accuracy: 0.0586 - binary_accuracy: 0.9304 - val_loss: 0.0386 - val_accuracy: 0.1357 - val_binary_accuracy: 0.9612\n",
      "Epoch 28/70\n",
      "180/180 [==============================] - 25s 139ms/step - loss: 0.0381 - accuracy: 0.1853 - binary_accuracy: 0.9618 - val_loss: 0.0379 - val_accuracy: 0.2231 - val_binary_accuracy: 0.9620\n",
      "Epoch 29/70\n",
      "180/180 [==============================] - 25s 140ms/step - loss: 0.0378 - accuracy: 0.2264 - binary_accuracy: 0.9622 - val_loss: 0.0380 - val_accuracy: 0.2177 - val_binary_accuracy: 0.9618\n",
      "Epoch 30/70\n",
      "180/180 [==============================] - 25s 140ms/step - loss: 0.0377 - accuracy: 0.2421 - binary_accuracy: 0.9622 - val_loss: 0.0376 - val_accuracy: 0.2530 - val_binary_accuracy: 0.9623\n",
      "Epoch 31/70\n",
      "180/180 [==============================] - 25s 141ms/step - loss: 0.0374 - accuracy: 0.2672 - binary_accuracy: 0.9626 - val_loss: 0.0375 - val_accuracy: 0.2725 - val_binary_accuracy: 0.9624\n",
      "Epoch 32/70\n",
      "180/180 [==============================] - 25s 141ms/step - loss: 0.0374 - accuracy: 0.2804 - binary_accuracy: 0.9626 - val_loss: 0.0374 - val_accuracy: 0.3058 - val_binary_accuracy: 0.9625\n",
      "Epoch 33/70\n",
      "180/180 [==============================] - 25s 140ms/step - loss: 0.0513 - accuracy: 0.1772 - binary_accuracy: 0.9482 - val_loss: 0.0531 - val_accuracy: 0.2090 - val_binary_accuracy: 0.9469\n",
      "Epoch 34/70\n",
      "180/180 [==============================] - 25s 140ms/step - loss: 0.0530 - accuracy: 0.2270 - binary_accuracy: 0.9470 - val_loss: 0.0531 - val_accuracy: 0.2398 - val_binary_accuracy: 0.9469\n",
      "Epoch 35/70\n",
      "180/180 [==============================] - 25s 141ms/step - loss: 0.0529 - accuracy: 0.2592 - binary_accuracy: 0.9471 - val_loss: 0.0530 - val_accuracy: 0.2534 - val_binary_accuracy: 0.9470\n",
      "Epoch 36/70\n",
      "180/180 [==============================] - 25s 140ms/step - loss: 0.0529 - accuracy: 0.2785 - binary_accuracy: 0.9471 - val_loss: 0.0530 - val_accuracy: 0.2823 - val_binary_accuracy: 0.9470\n",
      "Epoch 37/70\n",
      "180/180 [==============================] - 25s 140ms/step - loss: 0.0529 - accuracy: 0.2933 - binary_accuracy: 0.9471 - val_loss: 0.0530 - val_accuracy: 0.3087 - val_binary_accuracy: 0.9470\n",
      "Epoch 38/70\n",
      "180/180 [==============================] - 25s 139ms/step - loss: 0.0529 - accuracy: 0.3056 - binary_accuracy: 0.9471 - val_loss: 0.0529 - val_accuracy: 0.3136 - val_binary_accuracy: 0.9470\n",
      "Epoch 39/70\n",
      "180/180 [==============================] - 25s 140ms/step - loss: 0.0528 - accuracy: 0.3187 - binary_accuracy: 0.9472 - val_loss: 0.0534 - val_accuracy: 0.3237 - val_binary_accuracy: 0.9464\n",
      "Epoch 40/70\n",
      "180/180 [==============================] - 25s 139ms/step - loss: 0.0699 - accuracy: 0.1627 - binary_accuracy: 0.9292 - val_loss: 0.0594 - val_accuracy: 0.1811 - val_binary_accuracy: 0.9406\n",
      "Epoch 41/70\n",
      "180/180 [==============================] - 25s 139ms/step - loss: 0.0592 - accuracy: 0.2135 - binary_accuracy: 0.9408 - val_loss: 0.0593 - val_accuracy: 0.2240 - val_binary_accuracy: 0.9407\n",
      "Epoch 42/70\n",
      "180/180 [==============================] - 25s 139ms/step - loss: 0.0592 - accuracy: 0.2437 - binary_accuracy: 0.9409 - val_loss: 0.0593 - val_accuracy: 0.2437 - val_binary_accuracy: 0.9407\n",
      "Epoch 43/70\n",
      "180/180 [==============================] - 25s 140ms/step - loss: 0.0591 - accuracy: 0.2609 - binary_accuracy: 0.9409 - val_loss: 0.0592 - val_accuracy: 0.2614 - val_binary_accuracy: 0.9407\n",
      "Epoch 44/70\n",
      "180/180 [==============================] - 25s 140ms/step - loss: 0.0591 - accuracy: 0.2715 - binary_accuracy: 0.9409 - val_loss: 0.0592 - val_accuracy: 0.2831 - val_binary_accuracy: 0.9408\n",
      "Epoch 45/70\n",
      "180/180 [==============================] - 25s 139ms/step - loss: 0.0591 - accuracy: 0.2824 - binary_accuracy: 0.9409 - val_loss: 0.0592 - val_accuracy: 0.2879 - val_binary_accuracy: 0.9408\n",
      "Epoch 46/70\n",
      "180/180 [==============================] - 25s 139ms/step - loss: 0.0591 - accuracy: 0.2888 - binary_accuracy: 0.9409 - val_loss: 0.0592 - val_accuracy: 0.2887 - val_binary_accuracy: 0.9408\n",
      "Epoch 47/70\n",
      "180/180 [==============================] - 27s 148ms/step - loss: 0.0591 - accuracy: 0.2950 - binary_accuracy: 0.9409 - val_loss: 0.0592 - val_accuracy: 0.2953 - val_binary_accuracy: 0.9408\n",
      "Epoch 48/70\n",
      "180/180 [==============================] - 26s 145ms/step - loss: 0.0594 - accuracy: 0.2969 - binary_accuracy: 0.9405 - val_loss: 0.0764 - val_accuracy: 0.3490 - val_binary_accuracy: 0.9205\n",
      "Epoch 49/70\n",
      "180/180 [==============================] - 26s 144ms/step - loss: 0.0599 - accuracy: 0.2016 - binary_accuracy: 0.9400 - val_loss: 0.0592 - val_accuracy: 0.2378 - val_binary_accuracy: 0.9408\n",
      "Epoch 50/70\n",
      "180/180 [==============================] - 26s 146ms/step - loss: 0.0591 - accuracy: 0.2461 - binary_accuracy: 0.9409 - val_loss: 0.0592 - val_accuracy: 0.2628 - val_binary_accuracy: 0.9407\n",
      "Epoch 51/70\n",
      "180/180 [==============================] - 26s 145ms/step - loss: 0.0591 - accuracy: 0.2631 - binary_accuracy: 0.9409 - val_loss: 0.0592 - val_accuracy: 0.2627 - val_binary_accuracy: 0.9408\n",
      "Epoch 52/70\n",
      "180/180 [==============================] - 27s 148ms/step - loss: 0.0591 - accuracy: 0.2710 - binary_accuracy: 0.9409 - val_loss: 0.0591 - val_accuracy: 0.2707 - val_binary_accuracy: 0.9408\n",
      "Epoch 53/70\n",
      "180/180 [==============================] - 28s 153ms/step - loss: 0.0591 - accuracy: 0.2813 - binary_accuracy: 0.9409 - val_loss: 0.0592 - val_accuracy: 0.2805 - val_binary_accuracy: 0.9408\n",
      "Epoch 54/70\n",
      "180/180 [==============================] - 27s 149ms/step - loss: 0.0591 - accuracy: 0.2842 - binary_accuracy: 0.9409 - val_loss: 0.0592 - val_accuracy: 0.2736 - val_binary_accuracy: 0.9408\n",
      "Epoch 55/70\n",
      "180/180 [==============================] - 29s 160ms/step - loss: 0.0591 - accuracy: 0.2881 - binary_accuracy: 0.9409 - val_loss: 0.0591 - val_accuracy: 0.2979 - val_binary_accuracy: 0.9408\n",
      "Epoch 56/70\n",
      "180/180 [==============================] - 26s 143ms/step - loss: 0.0591 - accuracy: 0.2918 - binary_accuracy: 0.9409 - val_loss: 0.0591 - val_accuracy: 0.2950 - val_binary_accuracy: 0.9408\n",
      "Epoch 57/70\n",
      "180/180 [==============================] - 24s 134ms/step - loss: 0.1023 - accuracy: 0.1540 - binary_accuracy: 0.8961 - val_loss: 0.1021 - val_accuracy: 0.1096 - val_binary_accuracy: 0.8978\n",
      "Epoch 58/70\n",
      "180/180 [==============================] - 24s 134ms/step - loss: 0.1014 - accuracy: 0.1813 - binary_accuracy: 0.8986 - val_loss: 0.0999 - val_accuracy: 0.2231 - val_binary_accuracy: 0.9001\n",
      "Epoch 59/70\n",
      "180/180 [==============================] - 24s 135ms/step - loss: 0.0997 - accuracy: 0.2467 - binary_accuracy: 0.9003 - val_loss: 0.0998 - val_accuracy: 0.2662 - val_binary_accuracy: 0.9002\n",
      "Epoch 60/70\n",
      "180/180 [==============================] - 24s 135ms/step - loss: 0.0997 - accuracy: 0.2840 - binary_accuracy: 0.9004 - val_loss: 0.0998 - val_accuracy: 0.2915 - val_binary_accuracy: 0.9002\n",
      "Epoch 61/70\n",
      "180/180 [==============================] - 24s 134ms/step - loss: 0.0996 - accuracy: 0.3095 - binary_accuracy: 0.9004 - val_loss: 0.0998 - val_accuracy: 0.3049 - val_binary_accuracy: 0.9002\n",
      "Epoch 62/70\n",
      "180/180 [==============================] - 24s 134ms/step - loss: 0.0996 - accuracy: 0.3271 - binary_accuracy: 0.9004 - val_loss: 0.0998 - val_accuracy: 0.3372 - val_binary_accuracy: 0.9002\n",
      "Epoch 63/70\n",
      "180/180 [==============================] - 24s 135ms/step - loss: 0.0996 - accuracy: 0.3413 - binary_accuracy: 0.9004 - val_loss: 0.0997 - val_accuracy: 0.3457 - val_binary_accuracy: 0.9002\n",
      "Epoch 64/70\n",
      "180/180 [==============================] - 25s 139ms/step - loss: 0.0996 - accuracy: 0.3554 - binary_accuracy: 0.9004 - val_loss: 0.0997 - val_accuracy: 0.3605 - val_binary_accuracy: 0.9003\n",
      "Epoch 65/70\n",
      "180/180 [==============================] - 24s 135ms/step - loss: 0.0996 - accuracy: 0.3671 - binary_accuracy: 0.9004 - val_loss: 0.0997 - val_accuracy: 0.3759 - val_binary_accuracy: 0.9003\n",
      "Epoch 66/70\n",
      "180/180 [==============================] - 24s 135ms/step - loss: 0.0996 - accuracy: 0.3781 - binary_accuracy: 0.9004 - val_loss: 0.0997 - val_accuracy: 0.3850 - val_binary_accuracy: 0.9003\n",
      "Epoch 67/70\n",
      "180/180 [==============================] - 24s 135ms/step - loss: 0.0996 - accuracy: 0.3885 - binary_accuracy: 0.9004 - val_loss: 0.0998 - val_accuracy: 0.3889 - val_binary_accuracy: 0.9002\n",
      "Epoch 68/70\n",
      "180/180 [==============================] - 24s 134ms/step - loss: 0.0998 - accuracy: 0.3741 - binary_accuracy: 0.9002 - val_loss: 0.0998 - val_accuracy: 0.3487 - val_binary_accuracy: 0.9001\n",
      "Epoch 69/70\n",
      "180/180 [==============================] - 24s 134ms/step - loss: 0.0997 - accuracy: 0.3737 - binary_accuracy: 0.9003 - val_loss: 0.0997 - val_accuracy: 0.3760 - val_binary_accuracy: 0.9002\n",
      "Epoch 70/70\n",
      "180/180 [==============================] - 24s 134ms/step - loss: 0.0996 - accuracy: 0.3942 - binary_accuracy: 0.9004 - val_loss: 0.0997 - val_accuracy: 0.3985 - val_binary_accuracy: 0.9003\n"
     ]
    }
   ],
   "source": [
    "history = train_model(neural_network, train_samples, train_labels, \n",
    "                      batch_size=batch_size, \n",
    "                      epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15783682465553284, 0.10555192083120346, 0.07586967200040817, 0.03977176174521446, 0.04646357148885727, 0.041769839823246, 0.03639882430434227, 0.03497932106256485, 0.03466518595814705, 0.03364760801196098, 0.03329853713512421, 0.03298182785511017, 0.032810986042022705, 0.19744260609149933, 0.44386544823646545, 0.44332221150398254, 0.4431290030479431, 0.44302743673324585, 0.44297555088996887, 0.44294825196266174, 0.442905992269516, 0.4428950548171997, 0.4428803324699402, 0.44289273023605347, 0.4428500831127167, 0.4242929220199585, 0.06432530283927917, 0.03807825222611427, 0.03775850683450699, 0.037679169327020645, 0.03742580860853195, 0.03740697354078293, 0.05127374455332756, 0.05297714099287987, 0.05291775241494179, 0.052902091294527054, 0.05286538228392601, 0.0528910867869854, 0.05283598229289055, 0.06988374888896942, 0.05922018736600876, 0.05915306508541107, 0.05913059040904045, 0.059112899005413055, 0.05910145863890648, 0.05909530818462372, 0.05908878892660141, 0.059426289051771164, 0.05989270657300949, 0.05909033119678497, 0.05907540023326874, 0.05907486006617546, 0.05906621366739273, 0.059069931507110596, 0.0590650700032711, 0.059078093618154526, 0.10229577869176865, 0.10138591378927231, 0.09969457983970642, 0.09965506941080093, 0.0996398851275444, 0.09963222593069077, 0.0996258407831192, 0.09962105005979538, 0.09961625188589096, 0.09961458295583725, 0.09961775690317154, 0.09978494793176651, 0.09965168684720993, 0.09962274879217148]\n",
      "[0.11632081121206284, 0.09431900084018707, 0.054382212460041046, 0.026183098554611206, 0.048325199633836746, 0.03759056329727173, 0.03561899811029434, 0.03486579656600952, 0.03526832163333893, 0.03346162289381027, 0.033539142459630966, 0.032730910927057266, 0.033059436827898026, 0.44513222575187683, 0.4437650144100189, 0.443464457988739, 0.4433267116546631, 0.4433065354824066, 0.4432443082332611, 0.44322270154953003, 0.44317272305488586, 0.44313862919807434, 0.4433513581752777, 0.4431319236755371, 0.4431079030036926, 0.31547811627388, 0.03861319646239281, 0.037916816771030426, 0.037983428686857224, 0.03761766850948334, 0.0375458300113678, 0.03742252290248871, 0.05311973765492439, 0.05305035039782524, 0.05300702154636383, 0.05297437682747841, 0.052964791655540466, 0.05294851213693619, 0.05341129004955292, 0.05938201770186424, 0.05928882956504822, 0.059256263077259064, 0.059244491159915924, 0.059203777462244034, 0.05919012054800987, 0.05918266996741295, 0.05919082835316658, 0.07637954503297806, 0.059191375970840454, 0.059220701456069946, 0.05916064605116844, 0.059149209409952164, 0.059151824563741684, 0.059154052287340164, 0.05914521962404251, 0.05914447829127312, 0.10213152319192886, 0.09988148510456085, 0.09979797154664993, 0.09977617114782333, 0.09976886957883835, 0.09976062178611755, 0.09974674135446548, 0.09973515570163727, 0.09973854571580887, 0.09972990304231644, 0.09976153075695038, 0.09983290731906891, 0.09974081069231033, 0.09972970932722092]\n",
      "[5.999999848427251e-05, 9.999999747378752e-06, 9.999999747378752e-05, 0.002199999988079071, 0.005849999841302633, 0.021970000118017197, 0.06902000308036804, 0.11101999878883362, 0.10977999866008759, 0.16106000542640686, 0.2016800045967102, 0.2131900042295456, 0.22055000066757202, 0.015809999778866768, 0.023509999737143517, 0.04496999830007553, 0.06633999943733215, 0.07162000238895416, 0.07969000190496445, 0.09401000291109085, 0.09726999700069427, 0.10262999683618546, 0.09794999659061432, 0.10394000262022018, 0.11765000224113464, 0.0023799999617040157, 0.13569000363349915, 0.223130002617836, 0.21765999495983124, 0.2529900074005127, 0.27246999740600586, 0.30583998560905457, 0.20900000631809235, 0.23984000086784363, 0.25341999530792236, 0.2823199927806854, 0.3086700141429901, 0.31358999013900757, 0.32374998927116394, 0.18105000257492065, 0.2240000069141388, 0.24369999766349792, 0.26144999265670776, 0.28314998745918274, 0.28790000081062317, 0.2887200117111206, 0.29528000950813293, 0.3490400016307831, 0.23778000473976135, 0.262800008058548, 0.26273998618125916, 0.2707200050354004, 0.2805199921131134, 0.27360999584198, 0.2978599965572357, 0.29497000575065613, 0.1096000000834465, 0.22308999300003052, 0.2661899924278259, 0.2915099859237671, 0.30485999584198, 0.3372499942779541, 0.34571999311447144, 0.3604699969291687, 0.3758699893951416, 0.38503000140190125, 0.38888999819755554, 0.3486500084400177, 0.3759799897670746, 0.39847999811172485]\n"
     ]
    }
   ],
   "source": [
    "h_loss = history.history['loss']\n",
    "h_val_loss = history.history['val_loss']\n",
    "h_val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "print(h_loss)\n",
    "print(h_val_loss)\n",
    "print(h_val_accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "Here, we evaluate the neural network with the test data.\n",
    "\n",
    "This block stays the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 44ms/step - loss: 0.0996 - accuracy: 0.3995 - binary_accuracy: 0.9003\n",
      "Test loss: 0.09964519739151001\n",
      "Test accuracy: 0.39945000410079956\n"
     ]
    }
   ],
   "source": [
    "results = neural_network.evaluate(test_samples, test_labels, batch_size=batch_size)\n",
    "print(\"Test loss: {}\".format(results[0]))\n",
    "print(\"Test accuracy: {}\".format(results[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(neural_network, '1_round_speck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
