{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplified AES Key Recovery: 1st bit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "In this attack, we aim to recover the first bit of the key using a binary classifier. We train a neural network on plaintext-ciphertext pairs as samples and the first bit of the key as labels. We use the educational simplified AES, which has only 16 bits keys and 16 bits blocks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-02 16:21:42.203469: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from dataset.datasets import SimplifiedAESDatasetCiphertextPlaintextPairKey\n",
    "from pipeline import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: dataset/assets/moby-dick.txt\n",
      "Error: dataset/assets/shakespeare.txt\n"
     ]
    }
   ],
   "source": [
    "data = SimplifiedAESDatasetCiphertextPlaintextPairKey('large')\n",
    "\n",
    "train_labels, train_samples, test_labels, test_samples = data.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Training Labels Shape: (11565605, 16)\n",
      "===== Label Shape: (16,)\n",
      "===== Training Samples Shape: (11565605, 32)\n",
      "===== Sample Shape: (32,)\n",
      "===== Testing Labels Shape: (4956688, 16)\n",
      "===== Testing Samples Shape: (4956688, 32)\n"
     ]
    }
   ],
   "source": [
    "get_dataset_info(train_labels, train_samples, test_labels, test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = train_samples.astype(float)\n",
    "test_samples = test_samples.astype(float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "We add 1 preprocessing step:\n",
    "As our goal is only to recover the first bit of the key, we only keep the first bit of the labels to train our network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_1st_bit = np.array([l[0] for l in train_labels]).astype(float)\n",
    "test_labels_1st_bit = np.array([l[0] for l in test_labels]).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Training Labels Shape: (11565605,)\n",
      "===== Label Shape: ()\n",
      "===== Training Samples Shape: (11565605, 32)\n",
      "===== Sample Shape: (32,)\n",
      "===== Testing Labels Shape: (4956688,)\n",
      "===== Testing Samples Shape: (4956688, 32)\n"
     ]
    }
   ],
   "source": [
    "get_dataset_info(train_labels_1st_bit, train_samples, test_labels_1st_bit, test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from keras import Sequential\n",
    "from keras.layers import Input, Dense, BatchNormalization, LayerNormalization\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model hyperparameters\n",
    "In this code block, we specify most parameters and hyperparameters that will be used in the training of the neural network.\n",
    "\n",
    "Add customization here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = np.shape(train_samples[0])\n",
    "\n",
    "# output dimension\n",
    "dim = 1\n",
    "\n",
    "# units per hidden layer\n",
    "units = 256\n",
    "\n",
    "# lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "#     initial_learning_rate=0.001,\n",
    "#     decay_steps=10000,\n",
    "#     decay_rate=-0.9)\n",
    "\n",
    "loss_scc = 'sparse_categorical_crossentropy'\n",
    "loss_mse = 'mse'\n",
    "loss_bce = 'binary_crossentropy'\n",
    "learning_rate = 0.001\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "metrics = ['binary_accuracy']\n",
    "epochs = 50\n",
    "batch_size = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "In this code block, we create the model, according to the parameters and the topology we want to achieve. \n",
    "We then compile it specifying the optimizer, the loss and the metrics we want outputted.\n",
    "\n",
    "Add customization here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               8448      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 140,289\n",
      "Trainable params: 140,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Â Type of model\n",
    "neural_network = Sequential()\n",
    "\n",
    "# Input layer\n",
    "neural_network.add(Input(shape=input_shape))\n",
    "\n",
    "# Hidden layers\n",
    "#neural_network.add(BatchNormalization())\n",
    "neural_network.add(Dense(units=units, activation='relu'))\n",
    "neural_network.add(Dense(units=units, activation='relu'))\n",
    "neural_network.add(Dense(units=units, activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "neural_network.add(Dense(units=dim, activation='sigmoid'))\n",
    "\n",
    "# Summary\n",
    "neural_network.summary()\n",
    "\n",
    "# Compile model\n",
    "neural_network.compile(optimizer=optimizer, loss=loss_bce, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "In this code block, we train the model. It outputs, for each epoch, the loss and metrics.\n",
    "\n",
    "This block mostly stays the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2314/2314 [==============================] - 63s 26ms/step - loss: 0.6932 - binary_accuracy: 0.5018\n",
      "Epoch 2/50\n",
      "2314/2314 [==============================] - 60s 26ms/step - loss: 0.6931 - binary_accuracy: 0.5036\n",
      "Epoch 3/50\n",
      "2314/2314 [==============================] - 59s 26ms/step - loss: 0.6930 - binary_accuracy: 0.5062\n",
      "Epoch 4/50\n",
      "2314/2314 [==============================] - 56s 24ms/step - loss: 0.6927 - binary_accuracy: 0.5094\n",
      "Epoch 5/50\n",
      "2314/2314 [==============================] - 56s 24ms/step - loss: 0.6921 - binary_accuracy: 0.5139\n",
      "Epoch 6/50\n",
      "2314/2314 [==============================] - 57s 25ms/step - loss: 0.6910 - binary_accuracy: 0.5193\n",
      "Epoch 7/50\n",
      "2314/2314 [==============================] - 58s 25ms/step - loss: 0.6894 - binary_accuracy: 0.5252\n",
      "Epoch 8/50\n",
      "2314/2314 [==============================] - 57s 25ms/step - loss: 0.6873 - binary_accuracy: 0.5309\n",
      "Epoch 9/50\n",
      "2314/2314 [==============================] - 58s 25ms/step - loss: 0.6850 - binary_accuracy: 0.5362\n",
      "Epoch 10/50\n",
      "2314/2314 [==============================] - 59s 26ms/step - loss: 0.6827 - binary_accuracy: 0.5407\n",
      "Epoch 11/50\n",
      "2314/2314 [==============================] - 58s 25ms/step - loss: 0.6806 - binary_accuracy: 0.5448\n",
      "Epoch 12/50\n",
      "2314/2314 [==============================] - 59s 26ms/step - loss: 0.6787 - binary_accuracy: 0.5479\n",
      "Epoch 13/50\n",
      "2314/2314 [==============================] - 59s 25ms/step - loss: 0.6770 - binary_accuracy: 0.5504\n",
      "Epoch 14/50\n",
      "2314/2314 [==============================] - 59s 25ms/step - loss: 0.6754 - binary_accuracy: 0.5529\n",
      "Epoch 15/50\n",
      "2314/2314 [==============================] - 59s 26ms/step - loss: 0.6740 - binary_accuracy: 0.5549\n",
      "Epoch 16/50\n",
      "2314/2314 [==============================] - 60s 26ms/step - loss: 0.6728 - binary_accuracy: 0.5564\n",
      "Epoch 17/50\n",
      "2314/2314 [==============================] - 60s 26ms/step - loss: 0.6717 - binary_accuracy: 0.5580\n",
      "Epoch 18/50\n",
      "2314/2314 [==============================] - 60s 26ms/step - loss: 0.6706 - binary_accuracy: 0.5592\n",
      "Epoch 19/50\n",
      "2314/2314 [==============================] - 60s 26ms/step - loss: 0.6697 - binary_accuracy: 0.5602\n",
      "Epoch 20/50\n",
      "2314/2314 [==============================] - 61s 26ms/step - loss: 0.6688 - binary_accuracy: 0.5615\n",
      "Epoch 21/50\n",
      "2314/2314 [==============================] - 62s 27ms/step - loss: 0.6680 - binary_accuracy: 0.5621\n",
      "Epoch 22/50\n",
      "2314/2314 [==============================] - 60s 26ms/step - loss: 0.6673 - binary_accuracy: 0.5631\n",
      "Epoch 23/50\n",
      "2314/2314 [==============================] - 60s 26ms/step - loss: 0.6667 - binary_accuracy: 0.5640\n",
      "Epoch 24/50\n",
      "2314/2314 [==============================] - 60s 26ms/step - loss: 0.6660 - binary_accuracy: 0.5646\n",
      "Epoch 25/50\n",
      "2314/2314 [==============================] - 60s 26ms/step - loss: 0.6654 - binary_accuracy: 0.5652\n",
      "Epoch 26/50\n",
      "2314/2314 [==============================] - 59s 26ms/step - loss: 0.6649 - binary_accuracy: 0.5658\n",
      "Epoch 27/50\n",
      "2314/2314 [==============================] - 60s 26ms/step - loss: 0.6643 - binary_accuracy: 0.5663\n",
      "Epoch 28/50\n",
      "2314/2314 [==============================] - 59s 26ms/step - loss: 0.6639 - binary_accuracy: 0.5668\n",
      "Epoch 29/50\n",
      "2314/2314 [==============================] - 60s 26ms/step - loss: 0.6634 - binary_accuracy: 0.5673\n",
      "Epoch 30/50\n",
      "2314/2314 [==============================] - 60s 26ms/step - loss: 0.6630 - binary_accuracy: 0.5677\n",
      "Epoch 31/50\n",
      "2314/2314 [==============================] - 60s 26ms/step - loss: 0.6626 - binary_accuracy: 0.5681\n",
      "Epoch 32/50\n",
      "2314/2314 [==============================] - 63s 27ms/step - loss: 0.6622 - binary_accuracy: 0.5686\n",
      "Epoch 33/50\n",
      "2314/2314 [==============================] - 61s 26ms/step - loss: 0.6618 - binary_accuracy: 0.5689\n",
      "Epoch 34/50\n",
      "2314/2314 [==============================] - 60s 26ms/step - loss: 0.6615 - binary_accuracy: 0.5690\n",
      "Epoch 35/50\n",
      "2314/2314 [==============================] - 59s 26ms/step - loss: 0.6611 - binary_accuracy: 0.5694\n",
      "Epoch 36/50\n",
      "2314/2314 [==============================] - 59s 26ms/step - loss: 0.6608 - binary_accuracy: 0.5697\n",
      "Epoch 37/50\n",
      "2314/2314 [==============================] - 60s 26ms/step - loss: 0.6605 - binary_accuracy: 0.5700\n",
      "Epoch 38/50\n",
      "2314/2314 [==============================] - 59s 26ms/step - loss: 0.6602 - binary_accuracy: 0.5704\n",
      "Epoch 39/50\n",
      "2314/2314 [==============================] - 60s 26ms/step - loss: 0.6599 - binary_accuracy: 0.5708\n",
      "Epoch 40/50\n",
      "2314/2314 [==============================] - 60s 26ms/step - loss: 0.6596 - binary_accuracy: 0.5709\n",
      "Epoch 41/50\n",
      "2314/2314 [==============================] - 59s 25ms/step - loss: 0.6593 - binary_accuracy: 0.5710\n",
      "Epoch 42/50\n",
      "2314/2314 [==============================] - 59s 26ms/step - loss: 0.6590 - binary_accuracy: 0.5713\n",
      "Epoch 43/50\n",
      "2314/2314 [==============================] - 60s 26ms/step - loss: 0.6588 - binary_accuracy: 0.5718\n",
      "Epoch 44/50\n",
      "2314/2314 [==============================] - 59s 25ms/step - loss: 0.6585 - binary_accuracy: 0.5721\n",
      "Epoch 45/50\n",
      "2314/2314 [==============================] - 60s 26ms/step - loss: 0.6583 - binary_accuracy: 0.5721\n",
      "Epoch 46/50\n",
      "2314/2314 [==============================] - 60s 26ms/step - loss: 0.6581 - binary_accuracy: 0.5724\n",
      "Epoch 47/50\n",
      "2314/2314 [==============================] - 59s 26ms/step - loss: 0.6578 - binary_accuracy: 0.5725\n",
      "Epoch 48/50\n",
      "2314/2314 [==============================] - 60s 26ms/step - loss: 0.6576 - binary_accuracy: 0.5727\n",
      "Epoch 49/50\n",
      "2314/2314 [==============================] - 60s 26ms/step - loss: 0.6574 - binary_accuracy: 0.5729\n",
      "Epoch 50/50\n",
      "2314/2314 [==============================] - 60s 26ms/step - loss: 0.6572 - binary_accuracy: 0.5730\n"
     ]
    }
   ],
   "source": [
    "history = train_model(neural_network, train_samples, train_labels_1st_bit, \n",
    "                      batch_size=batch_size, \n",
    "                      epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "Here, we evaluate the neural network with the test data.\n",
    "\n",
    "This block stays the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "992/992 [==============================] - 8s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "results = test_model_binary(neural_network, test_samples, test_labels_1st_bit, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct predictions: 333625\n",
      "Accuracy: 0.5133110853654221\n"
     ]
    }
   ],
   "source": [
    "print(\"Correct predictions: \" + str(results[\"correct_predictions\"]))\n",
    "print(\"Accuracy: \" + str(results[\"accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'1' first bit distribution: 0.5022962913945764\n",
      "'0' first bit distribution: 0.49770370860542357\n"
     ]
    }
   ],
   "source": [
    "total_1_bits = sum(test_labels_1st_bit)\n",
    "distr = total_1_bits / len(test_labels_1st_bit)\n",
    "print(\"'1' first bit distribution: \" + str(distr))\n",
    "print(\"'0' first bit distribution: \"+ str(1-distr))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(neural_network, \"s_aes_1st_bit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
