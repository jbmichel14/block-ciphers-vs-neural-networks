{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from dataset.datasets import AESDatasetCiphertextPlaintext\n",
    "from pipeline import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset\n",
    "\n",
    "_Choose and import the dataset adapted for the attack. Here, we choose a small AES-128 dataset for plaintext recovery attack._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = AESDatasetCiphertextPlaintext(128, 'small')\n",
    "\n",
    "train_labels, train_samples, test_labels, test_samples = data.get_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Print the dimension information about the dataset. I the dataset size is too big, it is possible to shorten it._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Training Labels Shape: (189568, 128)\n",
      "===== Label Shape: (128,)\n",
      "===== Training Samples Shape: (189568, 128)\n",
      "===== Sample Shape: (128,)\n",
      "===== Testing Labels Shape: (81243, 128)\n",
      "===== Testing Samples Shape: (81243, 128)\n"
     ]
    }
   ],
   "source": [
    "get_dataset_info(train_labels, train_samples, test_labels, test_samples)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model\n",
    "\n",
    "_Imports will depend on the needs for the desired model architecture._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from keras import Sequential\n",
    "from keras.layers import Input, Dense\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model hyperparameters\n",
    "In this code block, we specify most parameters and hyperparameters that will be used in the training of the neural network.\n",
    "\n",
    "_Add customization here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = np.shape(train_samples[0])\n",
    "\n",
    "# output dimension\n",
    "dim = len(train_labels[0])\n",
    "\n",
    "# units per hidden layer\n",
    "units = dim*8\n",
    "\n",
    "# loss functions\n",
    "loss_scc = 'sparse_categorical_crossentropy'\n",
    "loss_mse = 'mse'\n",
    "loss_bce = 'binary_crossentropy'\n",
    "# learning rates\n",
    "learning_rate = 0.1\n",
    "\n",
    "# can be a scheduled learning rate\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.1,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.01)\n",
    "\n",
    "# other hyper-parameters\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "metrics = ['accuracy', 'binary_accuracy']\n",
    "epochs = 3\n",
    "batch_size = 5000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "In this code block, we create the model, according to the parameters and the topology we want to achieve. \n",
    "We then compile it specifying the optimizer, the loss and the metrics we want outputted.\n",
    "\n",
    "_Add customization here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 1024)              132096    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               131200    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,312,896\n",
      "Trainable params: 1,312,896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Â Type of model\n",
    "neural_network = Sequential()\n",
    "\n",
    "# Input layer\n",
    "neural_network.add(Input(shape=input_shape))\n",
    "\n",
    "# Hidden layers\n",
    "#neural_network.add(BatchNormalization())\n",
    "neural_network.add(Dense(units=units, activation='relu'))\n",
    "neural_network.add(Dense(units=units, activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "neural_network.add(Dense(units=dim, activation='sigmoid'))\n",
    "\n",
    "# Summary\n",
    "neural_network.summary()\n",
    "\n",
    "# Compile model\n",
    "neural_network.compile(optimizer=optimizer, loss=loss_mse, metrics=metrics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "In this code block, we train the model. It outputs, for each epoch, the loss and metrics.\n",
    "\n",
    "_This block mostly stays the same._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "35/35 [==============================] - 5s 147ms/step - loss: 0.2654 - accuracy: 0.7219 - binary_accuracy: 0.7278 - val_loss: 0.2641 - val_accuracy: 0.7440 - val_binary_accuracy: 0.7359\n",
      "Epoch 2/3\n",
      "35/35 [==============================] - 5s 140ms/step - loss: 0.2659 - accuracy: 0.7439 - binary_accuracy: 0.7341 - val_loss: 0.2641 - val_accuracy: 0.7440 - val_binary_accuracy: 0.7359\n",
      "Epoch 3/3\n",
      "35/35 [==============================] - 5s 139ms/step - loss: 0.2659 - accuracy: 0.7439 - binary_accuracy: 0.7341 - val_loss: 0.2641 - val_accuracy: 0.7440 - val_binary_accuracy: 0.7359\n"
     ]
    }
   ],
   "source": [
    "history = train_model(neural_network, train_samples, train_labels, \n",
    "                      batch_size=batch_size, \n",
    "                      epochs=epochs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "Here, we evaluate the neural network with the test data.\n",
    "\n",
    "_Some customization is possible here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 56ms/step - loss: 0.2671 - accuracy: 0.7455 - binary_accuracy: 0.7329\n",
      "Test loss: 0.26705867052078247\n",
      "Test accuracy: 0.7455288171768188\n"
     ]
    }
   ],
   "source": [
    "results = neural_network.evaluate(test_samples, test_labels, batch_size=batch_size)\n",
    "print(\"Test loss: {}\".format(results[0]))\n",
    "print(\"Test accuracy: {}\".format(results[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Several ways to test the model._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 45ms/step\n"
     ]
    }
   ],
   "source": [
    "results, predictions = test_model(neural_network, test_samples, test_labels, batch_size, ascii_correction=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct bytes: 5542\n",
      "Byte accuracy: 0.004263444235195648\n",
      "Correct predictions: 0\n",
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Correct bytes: \" + str(results[\"correct_bytes\"]))\n",
    "print(\"Byte accuracy: \" + str(results[\"byte_accuracy\"]))\n",
    "\n",
    "print(\"Correct predictions: \" + str(results[\"correct_predictions\"]))\n",
    "print(\"Accuracy: \" + str(results[\"accuracy\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "Here is where we use the network as an attack. We could skip the testing phase and use this as our own testing phase. Here, we can also evaluate some result and compute other metrics.\n",
    "\n",
    "_Some customization can be necessary._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = [predict_sample(neural_network, test_samples[i]) for i in range(size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [correct_and_metrics((predictions[i], test_labels[i])) for i in range(size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct bytes: 76\n",
      "Byte accuracy: 0.038\n",
      "Correct predictions: 0\n",
      "Prediction accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "correct_bytes = 0\n",
    "correct_predictions = 0\n",
    "for m in metrics:\n",
    "    correct_bytes += m[0]\n",
    "    correct_predictions += m[1]\n",
    "                             \n",
    "print(\"Correct bytes: {}\".format(correct_bytes))\n",
    "print(\"Byte accuracy: {}\".format(correct_bytes/(2*size)))\n",
    "print(\"Correct predictions: {}\".format(correct_predictions))\n",
    "print(\"Prediction accuracy: {}\".format(correct_predictions/size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct-> :33 And when thi | ````dd`````````` <-predicted\n",
      "correct-> s cometh to pass | ````dd`````````` <-predicted\n",
      "correct-> , (lo, it will c | ````dd`````````` <-predicted\n"
     ]
    }
   ],
   "source": [
    "for i in range(size):\n",
    "    correct = prediction_to_string(test_labels[i])\n",
    "    predicted = prediction_to_string(predictions[i])\n",
    "    print(\"correct-> \" + correct + \" | \" + predicted + \" <-predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
