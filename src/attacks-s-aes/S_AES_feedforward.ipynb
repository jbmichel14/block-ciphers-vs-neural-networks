{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplified AES Plaintext Recovery (FNN)\n",
    "In this experiment, the network tries to guess the plaintext from the ciphertext, helped with ascii per-byte correction. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 09:33:52.084685: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from dataset.datasets import SimplifiedAESDatasetCiphertextPlaintext\n",
    "from pipeline import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = SimplifiedAESDatasetCiphertextPlaintext('small')\n",
    "\n",
    "train_labels, train_samples, test_labels, test_samples = data.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_labels[:500]\n",
    "train_samples = train_samples[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Training Labels Shape: (500, 16)\n",
      "===== Label Shape: (16,)\n",
      "===== Training Samples Shape: (500, 16)\n",
      "===== Sample Shape: (16,)\n",
      "===== Testing Labels Shape: (649947, 16)\n",
      "===== Testing Samples Shape: (649947, 16)\n"
     ]
    }
   ],
   "source": [
    "get_dataset_info(train_labels, train_samples, test_labels, test_samples)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from keras import Sequential\n",
    "from keras.layers import Input, Dense, BatchNormalization, LayerNormalization\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model hyperparameters\n",
    "In this code block, we specify most parameters and hyperparameters that will be used in the training of the neural network.\n",
    "\n",
    "Add customization here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output dimension: 16\n",
      "Units per hidden layer: 256\n"
     ]
    }
   ],
   "source": [
    "input_shape = np.shape(train_samples[0])\n",
    "\n",
    "# output dimension\n",
    "dim = len(train_labels[0])\n",
    "print(\"Output dimension: {}\".format(dim))\n",
    "\n",
    "# units per hidden layer\n",
    "units = dim*16\n",
    "print(\"Units per hidden layer: {}\".format(units))\n",
    "\n",
    "loss_scc = 'sparse_categorical_crossentropy'\n",
    "loss_mse = 'mse'\n",
    "loss_bce = 'binary_crossentropy'\n",
    "# 0.1 to 0.001\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.1,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.01)\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "metrics = ['accuracy', 'binary_accuracy']\n",
    "epochs = 1000\n",
    "batch_size = 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "In this code block, we create the model, according to the parameters and the topology we want to achieve. \n",
    "We then compile it specifying the optimizer, the loss and the metrics we want outputted.\n",
    "\n",
    "Add customization here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               4352      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                4112      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 205,840\n",
      "Trainable params: 205,840\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Â Type of model\n",
    "neural_network = Sequential()\n",
    "\n",
    "# Input layer\n",
    "neural_network.add(Input(shape=input_shape))\n",
    "\n",
    "# Hidden layers\n",
    "#neural_network.add(BatchNormalization())\n",
    "neural_network.add(Dense(units=units, activation='relu'))\n",
    "neural_network.add(Dense(units=units, activation='relu'))\n",
    "neural_network.add(Dense(units=units, activation='relu'))\n",
    "neural_network.add(Dense(units=units, activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "neural_network.add(Dense(units=dim, activation='sigmoid'))\n",
    "\n",
    "# Summary\n",
    "neural_network.summary()\n",
    "\n",
    "# Compile model\n",
    "neural_network.compile(optimizer=optimizer, loss=loss_mse, metrics=metrics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "In this code block, we train the model. It outputs, for each epoch, the loss and metrics.\n",
    "\n",
    "This block mostly stays the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "5/5 [==============================] - 1s 55ms/step - loss: 0.2327 - accuracy: 0.1467 - binary_accuracy: 0.6417 - val_loss: 0.1936 - val_accuracy: 0.2600 - val_binary_accuracy: 0.7475\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1800 - accuracy: 0.2111 - binary_accuracy: 0.7415 - val_loss: 0.1694 - val_accuracy: 0.2600 - val_binary_accuracy: 0.7387\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1710 - accuracy: 0.2133 - binary_accuracy: 0.7447 - val_loss: 0.1623 - val_accuracy: 0.2600 - val_binary_accuracy: 0.7588\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1600 - accuracy: 0.1578 - binary_accuracy: 0.7700 - val_loss: 0.1532 - val_accuracy: 0.0200 - val_binary_accuracy: 0.7675\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1516 - accuracy: 0.0267 - binary_accuracy: 0.7782 - val_loss: 0.1428 - val_accuracy: 0.1200 - val_binary_accuracy: 0.7937\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1390 - accuracy: 0.1089 - binary_accuracy: 0.7967 - val_loss: 0.1321 - val_accuracy: 0.1600 - val_binary_accuracy: 0.8112\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1270 - accuracy: 0.0578 - binary_accuracy: 0.8299 - val_loss: 0.1193 - val_accuracy: 0.0200 - val_binary_accuracy: 0.8475\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1163 - accuracy: 0.0267 - binary_accuracy: 0.8490 - val_loss: 0.1093 - val_accuracy: 0.0200 - val_binary_accuracy: 0.8612\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1064 - accuracy: 0.0244 - binary_accuracy: 0.8636 - val_loss: 0.1008 - val_accuracy: 0.0200 - val_binary_accuracy: 0.8725\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0988 - accuracy: 0.0644 - binary_accuracy: 0.8715 - val_loss: 0.0936 - val_accuracy: 0.0200 - val_binary_accuracy: 0.8825\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0907 - accuracy: 0.0533 - binary_accuracy: 0.8832 - val_loss: 0.0895 - val_accuracy: 0.0400 - val_binary_accuracy: 0.8863\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0844 - accuracy: 0.1311 - binary_accuracy: 0.8921 - val_loss: 0.0871 - val_accuracy: 0.0400 - val_binary_accuracy: 0.8925\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0792 - accuracy: 0.1222 - binary_accuracy: 0.9029 - val_loss: 0.0822 - val_accuracy: 0.0400 - val_binary_accuracy: 0.8963\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0740 - accuracy: 0.1733 - binary_accuracy: 0.9104 - val_loss: 0.0796 - val_accuracy: 0.0600 - val_binary_accuracy: 0.9000\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0688 - accuracy: 0.1800 - binary_accuracy: 0.9158 - val_loss: 0.0763 - val_accuracy: 0.0600 - val_binary_accuracy: 0.9025\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0644 - accuracy: 0.1422 - binary_accuracy: 0.9221 - val_loss: 0.0767 - val_accuracy: 0.3200 - val_binary_accuracy: 0.8975\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0613 - accuracy: 0.2644 - binary_accuracy: 0.9251 - val_loss: 0.0714 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9137\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0560 - accuracy: 0.3111 - binary_accuracy: 0.9324 - val_loss: 0.0686 - val_accuracy: 0.2000 - val_binary_accuracy: 0.9112\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0533 - accuracy: 0.2333 - binary_accuracy: 0.9368 - val_loss: 0.0680 - val_accuracy: 0.3600 - val_binary_accuracy: 0.9125\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0494 - accuracy: 0.2756 - binary_accuracy: 0.9449 - val_loss: 0.0636 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9212\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0450 - accuracy: 0.3289 - binary_accuracy: 0.9531 - val_loss: 0.0613 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9212\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0425 - accuracy: 0.2467 - binary_accuracy: 0.9547 - val_loss: 0.0597 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9225\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0394 - accuracy: 0.2956 - binary_accuracy: 0.9572 - val_loss: 0.0571 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9287\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0371 - accuracy: 0.2711 - binary_accuracy: 0.9624 - val_loss: 0.0545 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9337\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0346 - accuracy: 0.2667 - binary_accuracy: 0.9646 - val_loss: 0.0524 - val_accuracy: 0.2000 - val_binary_accuracy: 0.9413\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0326 - accuracy: 0.2422 - binary_accuracy: 0.9675 - val_loss: 0.0515 - val_accuracy: 0.2800 - val_binary_accuracy: 0.9400\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0306 - accuracy: 0.2600 - binary_accuracy: 0.9704 - val_loss: 0.0485 - val_accuracy: 0.2800 - val_binary_accuracy: 0.9488\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0286 - accuracy: 0.2378 - binary_accuracy: 0.9724 - val_loss: 0.0481 - val_accuracy: 0.2800 - val_binary_accuracy: 0.9475\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0272 - accuracy: 0.2689 - binary_accuracy: 0.9742 - val_loss: 0.0492 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9438\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0253 - accuracy: 0.2644 - binary_accuracy: 0.9761 - val_loss: 0.0479 - val_accuracy: 0.2800 - val_binary_accuracy: 0.9475\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0251 - accuracy: 0.2733 - binary_accuracy: 0.9771 - val_loss: 0.0464 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9463\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0243 - accuracy: 0.3044 - binary_accuracy: 0.9757 - val_loss: 0.0458 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9475\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0217 - accuracy: 0.3533 - binary_accuracy: 0.9790 - val_loss: 0.0445 - val_accuracy: 0.3600 - val_binary_accuracy: 0.9438\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0205 - accuracy: 0.3022 - binary_accuracy: 0.9800 - val_loss: 0.0433 - val_accuracy: 0.3600 - val_binary_accuracy: 0.9513\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0189 - accuracy: 0.3422 - binary_accuracy: 0.9822 - val_loss: 0.0425 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9463\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0181 - accuracy: 0.3200 - binary_accuracy: 0.9839 - val_loss: 0.0411 - val_accuracy: 0.3600 - val_binary_accuracy: 0.9538\n",
      "Epoch 37/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0168 - accuracy: 0.2978 - binary_accuracy: 0.9851 - val_loss: 0.0403 - val_accuracy: 0.2800 - val_binary_accuracy: 0.9513\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0156 - accuracy: 0.3067 - binary_accuracy: 0.9862 - val_loss: 0.0393 - val_accuracy: 0.3600 - val_binary_accuracy: 0.9538\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0145 - accuracy: 0.2889 - binary_accuracy: 0.9872 - val_loss: 0.0394 - val_accuracy: 0.2800 - val_binary_accuracy: 0.9538\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0140 - accuracy: 0.2778 - binary_accuracy: 0.9875 - val_loss: 0.0388 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9550\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0130 - accuracy: 0.2844 - binary_accuracy: 0.9892 - val_loss: 0.0388 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9538\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0122 - accuracy: 0.2600 - binary_accuracy: 0.9903 - val_loss: 0.0388 - val_accuracy: 0.2000 - val_binary_accuracy: 0.9525\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0118 - accuracy: 0.2533 - binary_accuracy: 0.9903 - val_loss: 0.0367 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9575\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0109 - accuracy: 0.2600 - binary_accuracy: 0.9912 - val_loss: 0.0364 - val_accuracy: 0.2800 - val_binary_accuracy: 0.9538\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0106 - accuracy: 0.2689 - binary_accuracy: 0.9914 - val_loss: 0.0363 - val_accuracy: 0.2000 - val_binary_accuracy: 0.9588\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0101 - accuracy: 0.2578 - binary_accuracy: 0.9921 - val_loss: 0.0362 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9550\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0095 - accuracy: 0.2400 - binary_accuracy: 0.9922 - val_loss: 0.0357 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9575\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0090 - accuracy: 0.2511 - binary_accuracy: 0.9925 - val_loss: 0.0352 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9588\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0087 - accuracy: 0.2444 - binary_accuracy: 0.9931 - val_loss: 0.0354 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9588\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0083 - accuracy: 0.2444 - binary_accuracy: 0.9936 - val_loss: 0.0348 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9588\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0079 - accuracy: 0.2511 - binary_accuracy: 0.9936 - val_loss: 0.0348 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9600\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0075 - accuracy: 0.2489 - binary_accuracy: 0.9944 - val_loss: 0.0337 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9575\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0072 - accuracy: 0.2356 - binary_accuracy: 0.9946 - val_loss: 0.0344 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9613\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0069 - accuracy: 0.2600 - binary_accuracy: 0.9949 - val_loss: 0.0342 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9588\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0065 - accuracy: 0.2356 - binary_accuracy: 0.9953 - val_loss: 0.0344 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9625\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0062 - accuracy: 0.2511 - binary_accuracy: 0.9954 - val_loss: 0.0334 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9600\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0059 - accuracy: 0.2378 - binary_accuracy: 0.9954 - val_loss: 0.0336 - val_accuracy: 0.2000 - val_binary_accuracy: 0.9625\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0057 - accuracy: 0.2511 - binary_accuracy: 0.9954 - val_loss: 0.0335 - val_accuracy: 0.2000 - val_binary_accuracy: 0.9625\n",
      "Epoch 59/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0055 - accuracy: 0.2400 - binary_accuracy: 0.9954 - val_loss: 0.0335 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9600\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0053 - accuracy: 0.2511 - binary_accuracy: 0.9956 - val_loss: 0.0335 - val_accuracy: 0.2000 - val_binary_accuracy: 0.9600\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0051 - accuracy: 0.2489 - binary_accuracy: 0.9956 - val_loss: 0.0337 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9588\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0049 - accuracy: 0.2511 - binary_accuracy: 0.9960 - val_loss: 0.0333 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9600\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0048 - accuracy: 0.2556 - binary_accuracy: 0.9961 - val_loss: 0.0332 - val_accuracy: 0.2000 - val_binary_accuracy: 0.9575\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0046 - accuracy: 0.2467 - binary_accuracy: 0.9961 - val_loss: 0.0326 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9625\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0045 - accuracy: 0.2489 - binary_accuracy: 0.9961 - val_loss: 0.0329 - val_accuracy: 0.2000 - val_binary_accuracy: 0.9613\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0043 - accuracy: 0.2444 - binary_accuracy: 0.9964 - val_loss: 0.0326 - val_accuracy: 0.2000 - val_binary_accuracy: 0.9600\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0042 - accuracy: 0.2422 - binary_accuracy: 0.9967 - val_loss: 0.0328 - val_accuracy: 0.2000 - val_binary_accuracy: 0.9600\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0041 - accuracy: 0.2400 - binary_accuracy: 0.9967 - val_loss: 0.0325 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0040 - accuracy: 0.2533 - binary_accuracy: 0.9967 - val_loss: 0.0329 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9600\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0039 - accuracy: 0.2556 - binary_accuracy: 0.9967 - val_loss: 0.0328 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9588\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0038 - accuracy: 0.2578 - binary_accuracy: 0.9967 - val_loss: 0.0326 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 72/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0038 - accuracy: 0.2356 - binary_accuracy: 0.9968 - val_loss: 0.0327 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9600\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0037 - accuracy: 0.2622 - binary_accuracy: 0.9968 - val_loss: 0.0326 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9600\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0037 - accuracy: 0.2467 - binary_accuracy: 0.9968 - val_loss: 0.0324 - val_accuracy: 0.2000 - val_binary_accuracy: 0.9625\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0036 - accuracy: 0.2489 - binary_accuracy: 0.9968 - val_loss: 0.0326 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0036 - accuracy: 0.2489 - binary_accuracy: 0.9968 - val_loss: 0.0324 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9638\n",
      "Epoch 77/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0035 - accuracy: 0.2489 - binary_accuracy: 0.9968 - val_loss: 0.0326 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9588\n",
      "Epoch 78/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0034 - accuracy: 0.2511 - binary_accuracy: 0.9969 - val_loss: 0.0323 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9613\n",
      "Epoch 79/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0034 - accuracy: 0.2444 - binary_accuracy: 0.9969 - val_loss: 0.0325 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9638\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0033 - accuracy: 0.2556 - binary_accuracy: 0.9971 - val_loss: 0.0323 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 81/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0033 - accuracy: 0.2533 - binary_accuracy: 0.9971 - val_loss: 0.0323 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0032 - accuracy: 0.2556 - binary_accuracy: 0.9971 - val_loss: 0.0325 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0032 - accuracy: 0.2467 - binary_accuracy: 0.9971 - val_loss: 0.0324 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 84/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0032 - accuracy: 0.2600 - binary_accuracy: 0.9971 - val_loss: 0.0327 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9600\n",
      "Epoch 85/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0032 - accuracy: 0.2644 - binary_accuracy: 0.9969 - val_loss: 0.0327 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 86/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0031 - accuracy: 0.2644 - binary_accuracy: 0.9972 - val_loss: 0.0327 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9638\n",
      "Epoch 87/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0031 - accuracy: 0.2644 - binary_accuracy: 0.9972 - val_loss: 0.0326 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9588\n",
      "Epoch 88/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0030 - accuracy: 0.2556 - binary_accuracy: 0.9972 - val_loss: 0.0323 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 89/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0030 - accuracy: 0.2511 - binary_accuracy: 0.9972 - val_loss: 0.0319 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 90/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0030 - accuracy: 0.2622 - binary_accuracy: 0.9972 - val_loss: 0.0319 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 91/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0030 - accuracy: 0.2356 - binary_accuracy: 0.9974 - val_loss: 0.0318 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9638\n",
      "Epoch 92/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0029 - accuracy: 0.2644 - binary_accuracy: 0.9974 - val_loss: 0.0318 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 93/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0028 - accuracy: 0.2156 - binary_accuracy: 0.9974 - val_loss: 0.0319 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9625\n",
      "Epoch 94/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0028 - accuracy: 0.2578 - binary_accuracy: 0.9975 - val_loss: 0.0320 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9638\n",
      "Epoch 95/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0027 - accuracy: 0.2422 - binary_accuracy: 0.9975 - val_loss: 0.0320 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9638\n",
      "Epoch 96/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0027 - accuracy: 0.2444 - binary_accuracy: 0.9975 - val_loss: 0.0324 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 97/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0026 - accuracy: 0.2311 - binary_accuracy: 0.9976 - val_loss: 0.0326 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9625\n",
      "Epoch 98/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0026 - accuracy: 0.2222 - binary_accuracy: 0.9976 - val_loss: 0.0325 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9600\n",
      "Epoch 99/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0026 - accuracy: 0.2200 - binary_accuracy: 0.9976 - val_loss: 0.0323 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9625\n",
      "Epoch 100/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0025 - accuracy: 0.2133 - binary_accuracy: 0.9976 - val_loss: 0.0322 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9625\n",
      "Epoch 101/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0025 - accuracy: 0.2222 - binary_accuracy: 0.9976 - val_loss: 0.0323 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9625\n",
      "Epoch 102/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0025 - accuracy: 0.2222 - binary_accuracy: 0.9976 - val_loss: 0.0323 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9613\n",
      "Epoch 103/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0025 - accuracy: 0.2133 - binary_accuracy: 0.9976 - val_loss: 0.0321 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9625\n",
      "Epoch 104/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0025 - accuracy: 0.2133 - binary_accuracy: 0.9976 - val_loss: 0.0321 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9625\n",
      "Epoch 105/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0025 - accuracy: 0.2133 - binary_accuracy: 0.9976 - val_loss: 0.0322 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9625\n",
      "Epoch 106/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0025 - accuracy: 0.2133 - binary_accuracy: 0.9976 - val_loss: 0.0322 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9625\n",
      "Epoch 107/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0025 - accuracy: 0.2133 - binary_accuracy: 0.9976 - val_loss: 0.0321 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9625\n",
      "Epoch 108/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0025 - accuracy: 0.2133 - binary_accuracy: 0.9976 - val_loss: 0.0322 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9625\n",
      "Epoch 109/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0025 - accuracy: 0.2133 - binary_accuracy: 0.9976 - val_loss: 0.0322 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9625\n",
      "Epoch 110/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0025 - accuracy: 0.2133 - binary_accuracy: 0.9976 - val_loss: 0.0322 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9625\n",
      "Epoch 111/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0025 - accuracy: 0.2178 - binary_accuracy: 0.9976 - val_loss: 0.0321 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9625\n",
      "Epoch 112/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0025 - accuracy: 0.2156 - binary_accuracy: 0.9976 - val_loss: 0.0322 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9625\n",
      "Epoch 113/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0025 - accuracy: 0.2156 - binary_accuracy: 0.9976 - val_loss: 0.0321 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9625\n",
      "Epoch 114/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0025 - accuracy: 0.2156 - binary_accuracy: 0.9976 - val_loss: 0.0321 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9625\n",
      "Epoch 115/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0025 - accuracy: 0.2178 - binary_accuracy: 0.9976 - val_loss: 0.0321 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9625\n",
      "Epoch 116/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0025 - accuracy: 0.2156 - binary_accuracy: 0.9976 - val_loss: 0.0321 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9625\n",
      "Epoch 117/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0025 - accuracy: 0.2133 - binary_accuracy: 0.9976 - val_loss: 0.0321 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9625\n",
      "Epoch 118/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0025 - accuracy: 0.2156 - binary_accuracy: 0.9976 - val_loss: 0.0322 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9625\n",
      "Epoch 119/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0025 - accuracy: 0.2156 - binary_accuracy: 0.9976 - val_loss: 0.0322 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9625\n",
      "Epoch 120/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0024 - accuracy: 0.2133 - binary_accuracy: 0.9976 - val_loss: 0.0321 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9625\n",
      "Epoch 121/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0024 - accuracy: 0.2133 - binary_accuracy: 0.9976 - val_loss: 0.0320 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9625\n",
      "Epoch 122/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0024 - accuracy: 0.2156 - binary_accuracy: 0.9976 - val_loss: 0.0321 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9625\n",
      "Epoch 123/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0024 - accuracy: 0.2156 - binary_accuracy: 0.9976 - val_loss: 0.0322 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9625\n",
      "Epoch 124/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0024 - accuracy: 0.2156 - binary_accuracy: 0.9976 - val_loss: 0.0322 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9625\n",
      "Epoch 125/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0024 - accuracy: 0.2178 - binary_accuracy: 0.9976 - val_loss: 0.0321 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9625\n",
      "Epoch 126/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0024 - accuracy: 0.2133 - binary_accuracy: 0.9976 - val_loss: 0.0321 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9625\n",
      "Epoch 127/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0024 - accuracy: 0.2156 - binary_accuracy: 0.9976 - val_loss: 0.0321 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9625\n",
      "Epoch 128/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0024 - accuracy: 0.2133 - binary_accuracy: 0.9976 - val_loss: 0.0321 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9625\n",
      "Epoch 129/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0024 - accuracy: 0.2133 - binary_accuracy: 0.9976 - val_loss: 0.0321 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9625\n",
      "Epoch 130/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0024 - accuracy: 0.2133 - binary_accuracy: 0.9976 - val_loss: 0.0321 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9625\n",
      "Epoch 131/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0024 - accuracy: 0.2178 - binary_accuracy: 0.9976 - val_loss: 0.0320 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9625\n",
      "Epoch 132/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0024 - accuracy: 0.2133 - binary_accuracy: 0.9976 - val_loss: 0.0320 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 133/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0024 - accuracy: 0.2111 - binary_accuracy: 0.9976 - val_loss: 0.0321 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9625\n",
      "Epoch 134/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0024 - accuracy: 0.2156 - binary_accuracy: 0.9976 - val_loss: 0.0321 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 135/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0024 - accuracy: 0.2156 - binary_accuracy: 0.9976 - val_loss: 0.0321 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 136/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0024 - accuracy: 0.2178 - binary_accuracy: 0.9976 - val_loss: 0.0321 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 137/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0024 - accuracy: 0.2156 - binary_accuracy: 0.9976 - val_loss: 0.0320 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 138/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0024 - accuracy: 0.2156 - binary_accuracy: 0.9976 - val_loss: 0.0321 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 139/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0024 - accuracy: 0.2156 - binary_accuracy: 0.9976 - val_loss: 0.0321 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 140/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0024 - accuracy: 0.2156 - binary_accuracy: 0.9976 - val_loss: 0.0321 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 141/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0024 - accuracy: 0.2156 - binary_accuracy: 0.9976 - val_loss: 0.0321 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 142/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0024 - accuracy: 0.2156 - binary_accuracy: 0.9976 - val_loss: 0.0321 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 143/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0024 - accuracy: 0.2156 - binary_accuracy: 0.9976 - val_loss: 0.0321 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 144/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0024 - accuracy: 0.2156 - binary_accuracy: 0.9976 - val_loss: 0.0321 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 145/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0024 - accuracy: 0.2133 - binary_accuracy: 0.9976 - val_loss: 0.0321 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 146/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0024 - accuracy: 0.2133 - binary_accuracy: 0.9976 - val_loss: 0.0321 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 147/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0024 - accuracy: 0.2156 - binary_accuracy: 0.9976 - val_loss: 0.0321 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 148/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0024 - accuracy: 0.2133 - binary_accuracy: 0.9976 - val_loss: 0.0321 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 149/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0024 - accuracy: 0.2133 - binary_accuracy: 0.9976 - val_loss: 0.0321 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 150/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0024 - accuracy: 0.2133 - binary_accuracy: 0.9976 - val_loss: 0.0321 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 151/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0024 - accuracy: 0.2111 - binary_accuracy: 0.9976 - val_loss: 0.0321 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 152/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0024 - accuracy: 0.2067 - binary_accuracy: 0.9976 - val_loss: 0.0320 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 153/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0024 - accuracy: 0.2067 - binary_accuracy: 0.9976 - val_loss: 0.0321 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 154/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0024 - accuracy: 0.2067 - binary_accuracy: 0.9976 - val_loss: 0.0320 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 155/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0024 - accuracy: 0.2067 - binary_accuracy: 0.9976 - val_loss: 0.0320 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 156/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0024 - accuracy: 0.2000 - binary_accuracy: 0.9976 - val_loss: 0.0319 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9638\n",
      "Epoch 157/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 0.1911 - binary_accuracy: 0.9976 - val_loss: 0.0319 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9638\n",
      "Epoch 158/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 0.1867 - binary_accuracy: 0.9978 - val_loss: 0.0323 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 159/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 0.1956 - binary_accuracy: 0.9978 - val_loss: 0.0321 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 160/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 0.1711 - binary_accuracy: 0.9978 - val_loss: 0.0322 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 161/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 0.1889 - binary_accuracy: 0.9978 - val_loss: 0.0323 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 162/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 0.2022 - binary_accuracy: 0.9978 - val_loss: 0.0322 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 163/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0023 - accuracy: 0.1956 - binary_accuracy: 0.9978 - val_loss: 0.0321 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 164/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0023 - accuracy: 0.1911 - binary_accuracy: 0.9978 - val_loss: 0.0321 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 165/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0023 - accuracy: 0.1956 - binary_accuracy: 0.9978 - val_loss: 0.0321 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 166/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 0.2022 - binary_accuracy: 0.9978 - val_loss: 0.0321 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 167/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 0.2000 - binary_accuracy: 0.9978 - val_loss: 0.0321 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 168/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 0.2022 - binary_accuracy: 0.9978 - val_loss: 0.0321 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 169/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 0.1933 - binary_accuracy: 0.9978 - val_loss: 0.0321 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 170/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 0.2111 - binary_accuracy: 0.9978 - val_loss: 0.0322 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 171/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0023 - accuracy: 0.2089 - binary_accuracy: 0.9978 - val_loss: 0.0321 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 172/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0023 - accuracy: 0.2044 - binary_accuracy: 0.9978 - val_loss: 0.0321 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 173/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 0.1978 - binary_accuracy: 0.9978 - val_loss: 0.0321 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 174/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 0.1956 - binary_accuracy: 0.9978 - val_loss: 0.0322 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 175/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 0.2044 - binary_accuracy: 0.9978 - val_loss: 0.0322 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 176/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 0.2067 - binary_accuracy: 0.9978 - val_loss: 0.0322 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 177/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 0.2067 - binary_accuracy: 0.9978 - val_loss: 0.0322 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 178/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 0.2089 - binary_accuracy: 0.9978 - val_loss: 0.0322 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 179/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0023 - accuracy: 0.2089 - binary_accuracy: 0.9978 - val_loss: 0.0322 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 180/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 0.2133 - binary_accuracy: 0.9978 - val_loss: 0.0323 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 181/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 0.2089 - binary_accuracy: 0.9978 - val_loss: 0.0322 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 182/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0023 - accuracy: 0.2111 - binary_accuracy: 0.9978 - val_loss: 0.0323 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 183/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 0.2089 - binary_accuracy: 0.9978 - val_loss: 0.0323 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 184/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 0.2111 - binary_accuracy: 0.9978 - val_loss: 0.0323 - val_accuracy: 0.1400 - val_binary_accuracy: 0.9625\n",
      "Epoch 185/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0022 - accuracy: 0.2156 - binary_accuracy: 0.9978 - val_loss: 0.0322 - val_accuracy: 0.1400 - val_binary_accuracy: 0.9625\n",
      "Epoch 186/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0022 - accuracy: 0.2178 - binary_accuracy: 0.9978 - val_loss: 0.0322 - val_accuracy: 0.1400 - val_binary_accuracy: 0.9625\n",
      "Epoch 187/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0022 - accuracy: 0.2111 - binary_accuracy: 0.9978 - val_loss: 0.0319 - val_accuracy: 0.1400 - val_binary_accuracy: 0.9625\n",
      "Epoch 188/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0022 - accuracy: 0.2178 - binary_accuracy: 0.9978 - val_loss: 0.0314 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 189/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0022 - accuracy: 0.2178 - binary_accuracy: 0.9978 - val_loss: 0.0313 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9638\n",
      "Epoch 190/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0022 - accuracy: 0.2089 - binary_accuracy: 0.9979 - val_loss: 0.0311 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9638\n",
      "Epoch 191/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - accuracy: 0.2111 - binary_accuracy: 0.9979 - val_loss: 0.0310 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 192/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0021 - accuracy: 0.2156 - binary_accuracy: 0.9979 - val_loss: 0.0311 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 193/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - accuracy: 0.2200 - binary_accuracy: 0.9979 - val_loss: 0.0313 - val_accuracy: 0.1400 - val_binary_accuracy: 0.9638\n",
      "Epoch 194/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - accuracy: 0.2178 - binary_accuracy: 0.9979 - val_loss: 0.0313 - val_accuracy: 0.1400 - val_binary_accuracy: 0.9625\n",
      "Epoch 195/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - accuracy: 0.2044 - binary_accuracy: 0.9979 - val_loss: 0.0312 - val_accuracy: 0.1400 - val_binary_accuracy: 0.9625\n",
      "Epoch 196/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - accuracy: 0.2156 - binary_accuracy: 0.9979 - val_loss: 0.0312 - val_accuracy: 0.1400 - val_binary_accuracy: 0.9625\n",
      "Epoch 197/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - accuracy: 0.2178 - binary_accuracy: 0.9979 - val_loss: 0.0311 - val_accuracy: 0.1400 - val_binary_accuracy: 0.9638\n",
      "Epoch 198/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - accuracy: 0.2133 - binary_accuracy: 0.9979 - val_loss: 0.0311 - val_accuracy: 0.1400 - val_binary_accuracy: 0.9638\n",
      "Epoch 199/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - accuracy: 0.2133 - binary_accuracy: 0.9979 - val_loss: 0.0311 - val_accuracy: 0.1400 - val_binary_accuracy: 0.9625\n",
      "Epoch 200/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0021 - accuracy: 0.2067 - binary_accuracy: 0.9979 - val_loss: 0.0312 - val_accuracy: 0.1400 - val_binary_accuracy: 0.9625\n",
      "Epoch 201/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0021 - accuracy: 0.2089 - binary_accuracy: 0.9979 - val_loss: 0.0312 - val_accuracy: 0.1400 - val_binary_accuracy: 0.9625\n",
      "Epoch 202/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - accuracy: 0.2133 - binary_accuracy: 0.9979 - val_loss: 0.0313 - val_accuracy: 0.1400 - val_binary_accuracy: 0.9638\n",
      "Epoch 203/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - accuracy: 0.2089 - binary_accuracy: 0.9979 - val_loss: 0.0313 - val_accuracy: 0.1400 - val_binary_accuracy: 0.9638\n",
      "Epoch 204/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - accuracy: 0.2089 - binary_accuracy: 0.9979 - val_loss: 0.0313 - val_accuracy: 0.1400 - val_binary_accuracy: 0.9625\n",
      "Epoch 205/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - accuracy: 0.2200 - binary_accuracy: 0.9979 - val_loss: 0.0313 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 206/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - accuracy: 0.2244 - binary_accuracy: 0.9979 - val_loss: 0.0313 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 207/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0021 - accuracy: 0.2244 - binary_accuracy: 0.9979 - val_loss: 0.0314 - val_accuracy: 0.1400 - val_binary_accuracy: 0.9638\n",
      "Epoch 208/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0021 - accuracy: 0.2244 - binary_accuracy: 0.9979 - val_loss: 0.0313 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 209/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - accuracy: 0.2200 - binary_accuracy: 0.9979 - val_loss: 0.0314 - val_accuracy: 0.1400 - val_binary_accuracy: 0.9625\n",
      "Epoch 210/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - accuracy: 0.2289 - binary_accuracy: 0.9979 - val_loss: 0.0314 - val_accuracy: 0.1400 - val_binary_accuracy: 0.9625\n",
      "Epoch 211/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - accuracy: 0.2267 - binary_accuracy: 0.9979 - val_loss: 0.0314 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 212/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - accuracy: 0.2267 - binary_accuracy: 0.9979 - val_loss: 0.0314 - val_accuracy: 0.1400 - val_binary_accuracy: 0.9638\n",
      "Epoch 213/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - accuracy: 0.2333 - binary_accuracy: 0.9979 - val_loss: 0.0314 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 214/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - accuracy: 0.2311 - binary_accuracy: 0.9979 - val_loss: 0.0314 - val_accuracy: 0.1200 - val_binary_accuracy: 0.9625\n",
      "Epoch 215/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0021 - accuracy: 0.2244 - binary_accuracy: 0.9979 - val_loss: 0.0314 - val_accuracy: 0.1200 - val_binary_accuracy: 0.9625\n",
      "Epoch 216/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0021 - accuracy: 0.2289 - binary_accuracy: 0.9979 - val_loss: 0.0314 - val_accuracy: 0.1400 - val_binary_accuracy: 0.9625\n",
      "Epoch 217/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - accuracy: 0.2289 - binary_accuracy: 0.9979 - val_loss: 0.0314 - val_accuracy: 0.1200 - val_binary_accuracy: 0.9625\n",
      "Epoch 218/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0021 - accuracy: 0.2289 - binary_accuracy: 0.9979 - val_loss: 0.0314 - val_accuracy: 0.1400 - val_binary_accuracy: 0.9625\n",
      "Epoch 219/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0021 - accuracy: 0.2244 - binary_accuracy: 0.9979 - val_loss: 0.0314 - val_accuracy: 0.1200 - val_binary_accuracy: 0.9625\n",
      "Epoch 220/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0021 - accuracy: 0.2311 - binary_accuracy: 0.9979 - val_loss: 0.0315 - val_accuracy: 0.1400 - val_binary_accuracy: 0.9638\n",
      "Epoch 221/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0021 - accuracy: 0.2267 - binary_accuracy: 0.9979 - val_loss: 0.0315 - val_accuracy: 0.1400 - val_binary_accuracy: 0.9638\n",
      "Epoch 222/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0021 - accuracy: 0.2289 - binary_accuracy: 0.9979 - val_loss: 0.0314 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 223/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - accuracy: 0.2311 - binary_accuracy: 0.9979 - val_loss: 0.0314 - val_accuracy: 0.1400 - val_binary_accuracy: 0.9625\n",
      "Epoch 224/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0021 - accuracy: 0.2244 - binary_accuracy: 0.9979 - val_loss: 0.0315 - val_accuracy: 0.1400 - val_binary_accuracy: 0.9638\n",
      "Epoch 225/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - accuracy: 0.2200 - binary_accuracy: 0.9979 - val_loss: 0.0315 - val_accuracy: 0.1200 - val_binary_accuracy: 0.9638\n",
      "Epoch 226/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0021 - accuracy: 0.2222 - binary_accuracy: 0.9979 - val_loss: 0.0315 - val_accuracy: 0.1400 - val_binary_accuracy: 0.9638\n",
      "Epoch 227/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0021 - accuracy: 0.2156 - binary_accuracy: 0.9979 - val_loss: 0.0315 - val_accuracy: 0.1400 - val_binary_accuracy: 0.9625\n",
      "Epoch 228/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0021 - accuracy: 0.2244 - binary_accuracy: 0.9979 - val_loss: 0.0315 - val_accuracy: 0.1200 - val_binary_accuracy: 0.9638\n",
      "Epoch 229/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0021 - accuracy: 0.2222 - binary_accuracy: 0.9979 - val_loss: 0.0316 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9638\n",
      "Epoch 230/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0021 - accuracy: 0.2267 - binary_accuracy: 0.9979 - val_loss: 0.0316 - val_accuracy: 0.1400 - val_binary_accuracy: 0.9638\n",
      "Epoch 231/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0020 - accuracy: 0.2200 - binary_accuracy: 0.9979 - val_loss: 0.0321 - val_accuracy: 0.1200 - val_binary_accuracy: 0.9625\n",
      "Epoch 232/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0021 - accuracy: 0.2444 - binary_accuracy: 0.9979 - val_loss: 0.0325 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9638\n",
      "Epoch 233/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0021 - accuracy: 0.2489 - binary_accuracy: 0.9979 - val_loss: 0.0327 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9625\n",
      "Epoch 234/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2400 - binary_accuracy: 0.9981 - val_loss: 0.0323 - val_accuracy: 0.2000 - val_binary_accuracy: 0.9613\n",
      "Epoch 235/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0020 - accuracy: 0.2444 - binary_accuracy: 0.9981 - val_loss: 0.0324 - val_accuracy: 0.2000 - val_binary_accuracy: 0.9625\n",
      "Epoch 236/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.2089 - binary_accuracy: 0.9981 - val_loss: 0.0326 - val_accuracy: 0.1400 - val_binary_accuracy: 0.9600\n",
      "Epoch 237/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 0.2289 - binary_accuracy: 0.9981 - val_loss: 0.0328 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9638\n",
      "Epoch 238/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0021 - accuracy: 0.2200 - binary_accuracy: 0.9979 - val_loss: 0.0327 - val_accuracy: 0.1400 - val_binary_accuracy: 0.9613\n",
      "Epoch 239/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2111 - binary_accuracy: 0.9981 - val_loss: 0.0325 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9600\n",
      "Epoch 240/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2667 - binary_accuracy: 0.9981 - val_loss: 0.0323 - val_accuracy: 0.2000 - val_binary_accuracy: 0.9600\n",
      "Epoch 241/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2444 - binary_accuracy: 0.9981 - val_loss: 0.0322 - val_accuracy: 0.1400 - val_binary_accuracy: 0.9613\n",
      "Epoch 242/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2222 - binary_accuracy: 0.9981 - val_loss: 0.0326 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 243/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.2422 - binary_accuracy: 0.9981 - val_loss: 0.0326 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 244/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2533 - binary_accuracy: 0.9981 - val_loss: 0.0321 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 245/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2378 - binary_accuracy: 0.9981 - val_loss: 0.0320 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 246/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0020 - accuracy: 0.2311 - binary_accuracy: 0.9981 - val_loss: 0.0321 - val_accuracy: 0.1400 - val_binary_accuracy: 0.9613\n",
      "Epoch 247/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 0.2333 - binary_accuracy: 0.9981 - val_loss: 0.0321 - val_accuracy: 0.1400 - val_binary_accuracy: 0.9613\n",
      "Epoch 248/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2400 - binary_accuracy: 0.9981 - val_loss: 0.0321 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 249/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.2356 - binary_accuracy: 0.9981 - val_loss: 0.0320 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 250/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2356 - binary_accuracy: 0.9981 - val_loss: 0.0319 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 251/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2311 - binary_accuracy: 0.9981 - val_loss: 0.0319 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 252/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2333 - binary_accuracy: 0.9981 - val_loss: 0.0319 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 253/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.2333 - binary_accuracy: 0.9981 - val_loss: 0.0319 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 254/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.2333 - binary_accuracy: 0.9981 - val_loss: 0.0319 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 255/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2356 - binary_accuracy: 0.9981 - val_loss: 0.0318 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 256/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.2356 - binary_accuracy: 0.9981 - val_loss: 0.0318 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 257/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.2333 - binary_accuracy: 0.9981 - val_loss: 0.0317 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 258/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2333 - binary_accuracy: 0.9981 - val_loss: 0.0318 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 259/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 0.2333 - binary_accuracy: 0.9981 - val_loss: 0.0317 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 260/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0020 - accuracy: 0.2333 - binary_accuracy: 0.9981 - val_loss: 0.0317 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 261/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.2378 - binary_accuracy: 0.9981 - val_loss: 0.0317 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 262/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2333 - binary_accuracy: 0.9981 - val_loss: 0.0317 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 263/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2356 - binary_accuracy: 0.9981 - val_loss: 0.0317 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 264/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2356 - binary_accuracy: 0.9981 - val_loss: 0.0317 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 265/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.2333 - binary_accuracy: 0.9981 - val_loss: 0.0317 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 266/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2356 - binary_accuracy: 0.9981 - val_loss: 0.0317 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 267/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2356 - binary_accuracy: 0.9981 - val_loss: 0.0317 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 268/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2378 - binary_accuracy: 0.9981 - val_loss: 0.0317 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 269/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2356 - binary_accuracy: 0.9981 - val_loss: 0.0317 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 270/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2356 - binary_accuracy: 0.9981 - val_loss: 0.0317 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 271/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.2356 - binary_accuracy: 0.9981 - val_loss: 0.0317 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 272/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 0.2378 - binary_accuracy: 0.9981 - val_loss: 0.0317 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 273/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2356 - binary_accuracy: 0.9981 - val_loss: 0.0317 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 274/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2356 - binary_accuracy: 0.9981 - val_loss: 0.0317 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 275/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.2356 - binary_accuracy: 0.9981 - val_loss: 0.0317 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 276/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2356 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 277/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.2333 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 278/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2356 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 279/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.2333 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 280/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.2378 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 281/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.2356 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 282/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.2333 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 283/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.2356 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 284/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0020 - accuracy: 0.2333 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 285/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.2333 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 286/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2356 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 287/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2356 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 288/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.2444 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 289/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2489 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 290/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2356 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 291/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.2533 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 292/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.2400 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 293/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.2444 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 294/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2444 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 295/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2489 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 296/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0020 - accuracy: 0.2489 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 297/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.2422 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 298/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.2378 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 299/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.2467 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 300/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2511 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 301/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2467 - binary_accuracy: 0.9981 - val_loss: 0.0315 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 302/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.2511 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 303/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.2511 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 304/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2400 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 305/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0020 - accuracy: 0.2444 - binary_accuracy: 0.9981 - val_loss: 0.0315 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 306/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.2378 - binary_accuracy: 0.9981 - val_loss: 0.0315 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 307/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 0.2489 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 308/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.2422 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 309/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.2511 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 310/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2333 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 311/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.2444 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 312/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.2356 - binary_accuracy: 0.9981 - val_loss: 0.0315 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 313/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2444 - binary_accuracy: 0.9981 - val_loss: 0.0315 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 314/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2444 - binary_accuracy: 0.9981 - val_loss: 0.0315 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 315/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2400 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 316/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.2400 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 317/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.2467 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 318/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2489 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 319/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 0.2356 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 320/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.2489 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 321/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2444 - binary_accuracy: 0.9981 - val_loss: 0.0315 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 322/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.2533 - binary_accuracy: 0.9981 - val_loss: 0.0315 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 323/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2489 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 324/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2444 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 325/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.2378 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 326/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2533 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 327/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2511 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 328/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.2489 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 329/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 0.2467 - binary_accuracy: 0.9981 - val_loss: 0.0315 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 330/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2467 - binary_accuracy: 0.9981 - val_loss: 0.0315 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 331/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0020 - accuracy: 0.2422 - binary_accuracy: 0.9981 - val_loss: 0.0315 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 332/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2356 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 333/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2400 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 334/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.2400 - binary_accuracy: 0.9981 - val_loss: 0.0316 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 335/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2378 - binary_accuracy: 0.9981 - val_loss: 0.0315 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 336/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2444 - binary_accuracy: 0.9981 - val_loss: 0.0315 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 337/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.2467 - binary_accuracy: 0.9981 - val_loss: 0.0315 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 338/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0019 - accuracy: 0.2444 - binary_accuracy: 0.9981 - val_loss: 0.0315 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 339/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 0.2422 - binary_accuracy: 0.9981 - val_loss: 0.0315 - val_accuracy: 0.1600 - val_binary_accuracy: 0.9613\n",
      "Epoch 340/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0019 - accuracy: 0.2489 - binary_accuracy: 0.9981 - val_loss: 0.0314 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 341/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.2356 - binary_accuracy: 0.9981 - val_loss: 0.0310 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 342/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0019 - accuracy: 0.2467 - binary_accuracy: 0.9981 - val_loss: 0.0311 - val_accuracy: 0.2800 - val_binary_accuracy: 0.9613\n",
      "Epoch 343/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0019 - accuracy: 0.2467 - binary_accuracy: 0.9982 - val_loss: 0.0307 - val_accuracy: 0.1800 - val_binary_accuracy: 0.9613\n",
      "Epoch 344/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.2222 - binary_accuracy: 0.9979 - val_loss: 0.0307 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9650\n",
      "Epoch 345/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2222 - binary_accuracy: 0.9982 - val_loss: 0.0315 - val_accuracy: 0.2000 - val_binary_accuracy: 0.9600\n",
      "Epoch 346/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0019 - accuracy: 0.2444 - binary_accuracy: 0.9982 - val_loss: 0.0312 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 347/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0019 - accuracy: 0.2622 - binary_accuracy: 0.9982 - val_loss: 0.0311 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9600\n",
      "Epoch 348/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2422 - binary_accuracy: 0.9982 - val_loss: 0.0318 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9613\n",
      "Epoch 349/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.2556 - binary_accuracy: 0.9982 - val_loss: 0.0313 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9600\n",
      "Epoch 350/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2667 - binary_accuracy: 0.9982 - val_loss: 0.0311 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 351/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2622 - binary_accuracy: 0.9982 - val_loss: 0.0311 - val_accuracy: 0.2000 - val_binary_accuracy: 0.9588\n",
      "Epoch 352/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2467 - binary_accuracy: 0.9982 - val_loss: 0.0313 - val_accuracy: 0.2000 - val_binary_accuracy: 0.9588\n",
      "Epoch 353/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0018 - accuracy: 0.2467 - binary_accuracy: 0.9982 - val_loss: 0.0313 - val_accuracy: 0.2000 - val_binary_accuracy: 0.9588\n",
      "Epoch 354/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2467 - binary_accuracy: 0.9982 - val_loss: 0.0312 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9588\n",
      "Epoch 355/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2533 - binary_accuracy: 0.9982 - val_loss: 0.0311 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9600\n",
      "Epoch 356/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2511 - binary_accuracy: 0.9982 - val_loss: 0.0310 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9600\n",
      "Epoch 357/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2578 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9588\n",
      "Epoch 358/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.2556 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9588\n",
      "Epoch 359/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2556 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9588\n",
      "Epoch 360/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2489 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9588\n",
      "Epoch 361/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2533 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9600\n",
      "Epoch 362/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2533 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9600\n",
      "Epoch 363/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2533 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9600\n",
      "Epoch 364/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2533 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9600\n",
      "Epoch 365/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2600 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9600\n",
      "Epoch 366/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2511 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9600\n",
      "Epoch 367/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.2511 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9600\n",
      "Epoch 368/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2556 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9600\n",
      "Epoch 369/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2556 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9600\n",
      "Epoch 370/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2511 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9600\n",
      "Epoch 371/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2556 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9600\n",
      "Epoch 372/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2511 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 373/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0018 - accuracy: 0.2556 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9600\n",
      "Epoch 374/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 0.2533 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9600\n",
      "Epoch 375/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2511 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9600\n",
      "Epoch 376/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.2533 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9600\n",
      "Epoch 377/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2533 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9600\n",
      "Epoch 378/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2511 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9600\n",
      "Epoch 379/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2511 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9600\n",
      "Epoch 380/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2533 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 381/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2556 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9600\n",
      "Epoch 382/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2511 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 383/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2511 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 384/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2511 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 385/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.2533 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 386/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2578 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 387/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2578 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9613\n",
      "Epoch 388/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2556 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 389/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2600 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 390/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2600 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 391/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2578 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 392/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0018 - accuracy: 0.2556 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 393/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.2600 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 394/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2600 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 395/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2578 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 396/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2578 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 397/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2578 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 398/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2533 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 399/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2578 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 400/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2556 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 401/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.2600 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 402/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2578 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 403/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2556 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 404/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2578 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 405/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2578 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 406/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2600 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 407/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2578 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 408/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2578 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 409/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 0.2556 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 410/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0018 - accuracy: 0.2533 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 411/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.2578 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 412/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2556 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 413/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2689 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 414/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2622 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 415/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2622 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 416/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2578 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 417/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2578 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 418/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.2556 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 419/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2578 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 420/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2600 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 421/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.2578 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 422/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.2578 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 423/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.2578 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 424/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.2600 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 425/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2689 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 426/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0018 - accuracy: 0.2756 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 427/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2733 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 428/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2644 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 429/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2667 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 430/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2711 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 431/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2667 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 432/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2667 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 433/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2689 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 434/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 0.2689 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 435/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2689 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 436/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2756 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 437/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2644 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 438/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.2600 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 439/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 0.2622 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 440/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2689 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 441/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2644 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 442/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.2600 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 443/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0018 - accuracy: 0.2644 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 444/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.2733 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 445/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2778 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 446/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2733 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 447/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2689 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 448/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2800 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 449/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.2756 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 450/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2689 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 451/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2778 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 452/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2711 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 453/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2756 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 454/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2733 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 455/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2822 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 456/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2733 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 457/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.2711 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 458/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2667 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 459/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2844 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 460/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0018 - accuracy: 0.2756 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 461/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2844 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 462/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2844 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 463/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2822 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 464/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.2756 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 465/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2822 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 466/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2711 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 467/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2867 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 468/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2844 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 469/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2867 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 470/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2756 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 471/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 0.2800 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 472/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2733 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 473/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2800 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 474/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2756 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 475/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0018 - accuracy: 0.2844 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 476/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.2911 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 477/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2800 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 478/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.2889 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 479/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2822 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 480/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2889 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 481/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2867 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 482/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2756 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 483/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2889 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 484/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2822 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 485/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.2844 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 486/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2778 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 487/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2889 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 488/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2867 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 489/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0018 - accuracy: 0.2911 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 490/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2689 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 491/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2800 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 492/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2822 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 493/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.2778 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 494/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2867 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 495/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2844 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 496/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2911 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 497/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2889 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 498/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2800 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 499/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2778 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 500/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.2844 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 501/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2800 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 502/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2733 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 503/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.2800 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 504/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2667 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 505/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.2956 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 506/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2756 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 507/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.2689 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 508/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2778 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 509/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2800 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 510/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2889 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 511/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2689 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 512/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2711 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 513/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2622 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 514/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.2733 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 515/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2756 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 516/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0018 - accuracy: 0.2711 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 517/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2867 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 518/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2711 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 519/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2622 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 520/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2667 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 521/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 0.2711 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 522/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2733 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 523/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2733 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 524/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2756 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 525/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2778 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 526/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2844 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 527/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2778 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 528/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.2978 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 529/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2956 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 530/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0018 - accuracy: 0.2844 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 531/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2933 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2200 - val_binary_accuracy: 0.9625\n",
      "Epoch 532/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2867 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 533/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3000 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 534/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2956 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 535/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.2933 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 536/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2867 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 537/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2844 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 538/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2911 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 539/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2889 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 540/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2911 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 541/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2956 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 542/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.2933 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 543/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0018 - accuracy: 0.2867 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 544/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3000 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 545/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2889 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 546/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2889 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 547/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2933 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 548/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 0.2844 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 549/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2956 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 550/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2844 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 551/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2889 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 552/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 0.2911 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 553/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2933 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 554/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.2933 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 555/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2867 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2400 - val_binary_accuracy: 0.9625\n",
      "Epoch 556/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2933 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 557/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0018 - accuracy: 0.2889 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 558/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3000 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 559/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3022 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 560/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.2911 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 561/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2956 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 562/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 0.2956 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 563/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2933 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 564/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2933 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 565/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2933 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 566/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.2867 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 567/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3000 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 568/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2911 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 569/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3000 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 570/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2956 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 571/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2956 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 572/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.2978 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 573/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0018 - accuracy: 0.3000 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 574/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3022 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 575/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3044 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 576/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2933 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 577/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2978 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 578/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.2978 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 579/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2978 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 580/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2911 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 581/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.2978 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 582/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.2978 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 583/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3000 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 584/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3178 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 585/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3178 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 586/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3400 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 587/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0018 - accuracy: 0.3289 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 588/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3067 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 589/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3111 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 590/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.2956 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 591/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3089 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 592/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3267 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 593/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3044 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 594/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3311 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 595/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3067 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 596/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3311 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 597/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3178 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 598/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3156 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 599/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0018 - accuracy: 0.3333 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 600/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3244 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 601/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3022 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 602/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3178 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 603/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.3111 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 604/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3244 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 605/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0018 - accuracy: 0.3222 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 606/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3400 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 607/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3222 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 608/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3178 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 609/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.3222 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 610/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3089 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 611/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0018 - accuracy: 0.3244 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 612/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3222 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 613/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3311 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 614/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3133 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 615/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.3111 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 616/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3000 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 617/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3089 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 618/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3178 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 619/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3289 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 620/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.3200 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 621/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3178 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 622/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3089 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 623/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3289 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 624/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0018 - accuracy: 0.3156 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 625/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0018 - accuracy: 0.3356 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 626/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0018 - accuracy: 0.3156 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 627/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0018 - accuracy: 0.3044 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 628/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3222 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 629/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3156 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 630/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3022 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 631/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3289 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 632/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3111 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 633/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3222 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 634/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3133 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 635/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0018 - accuracy: 0.3267 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 636/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3244 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 637/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3356 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 638/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3178 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 639/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.3489 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 640/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3378 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 641/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3178 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 642/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3244 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 643/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3133 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 644/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3400 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 645/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.3022 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 646/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0018 - accuracy: 0.3356 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 647/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3222 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 648/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3156 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 649/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3400 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 650/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3333 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 651/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 0.3111 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 652/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3200 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2800 - val_binary_accuracy: 0.9625\n",
      "Epoch 653/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3244 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 654/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3067 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 655/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3156 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 656/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0018 - accuracy: 0.3311 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2800 - val_binary_accuracy: 0.9625\n",
      "Epoch 657/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 0.3333 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 658/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3178 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2800 - val_binary_accuracy: 0.9625\n",
      "Epoch 659/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3333 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 660/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3156 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 661/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3444 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 662/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.3356 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 663/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3222 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2800 - val_binary_accuracy: 0.9625\n",
      "Epoch 664/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3289 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 665/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0018 - accuracy: 0.3267 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 666/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3333 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 667/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.3289 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2800 - val_binary_accuracy: 0.9625\n",
      "Epoch 668/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3467 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 669/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3267 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 670/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3333 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 671/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3489 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2800 - val_binary_accuracy: 0.9625\n",
      "Epoch 672/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3267 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 673/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3333 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 674/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0018 - accuracy: 0.3511 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 675/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3267 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 676/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3311 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 677/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 0.3356 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 678/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3178 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 679/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3378 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 680/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3311 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2800 - val_binary_accuracy: 0.9625\n",
      "Epoch 681/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3156 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 682/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.3333 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2800 - val_binary_accuracy: 0.9625\n",
      "Epoch 683/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3378 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 684/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3222 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 685/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3333 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 686/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0018 - accuracy: 0.3422 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 687/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0018 - accuracy: 0.3444 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 688/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0018 - accuracy: 0.3156 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 689/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.3178 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 690/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3378 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 691/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3267 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 692/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3244 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 693/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3222 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 694/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3133 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 695/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3400 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 696/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3489 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 697/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0018 - accuracy: 0.3111 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 698/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3489 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 699/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 0.3111 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 700/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3289 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 701/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3200 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2800 - val_binary_accuracy: 0.9625\n",
      "Epoch 702/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3178 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 703/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3200 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 704/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.3467 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 705/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.3089 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 706/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0018 - accuracy: 0.3378 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 707/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3489 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 708/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3400 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 709/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 0.3333 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2800 - val_binary_accuracy: 0.9625\n",
      "Epoch 710/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3200 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 711/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3267 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 712/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3067 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2800 - val_binary_accuracy: 0.9625\n",
      "Epoch 713/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3333 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2800 - val_binary_accuracy: 0.9625\n",
      "Epoch 714/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3244 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 715/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0018 - accuracy: 0.3178 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2800 - val_binary_accuracy: 0.9625\n",
      "Epoch 716/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3444 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 717/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3311 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 718/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3289 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 719/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3289 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2800 - val_binary_accuracy: 0.9625\n",
      "Epoch 720/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3444 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 721/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3044 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 722/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3489 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 723/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3178 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2800 - val_binary_accuracy: 0.9625\n",
      "Epoch 724/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 0.3289 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2800 - val_binary_accuracy: 0.9625\n",
      "Epoch 725/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3244 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 726/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3356 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 727/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0018 - accuracy: 0.3333 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2800 - val_binary_accuracy: 0.9625\n",
      "Epoch 728/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3200 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 729/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3200 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 730/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3356 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 731/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3156 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 732/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3178 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 733/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3422 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 734/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3356 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 735/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3244 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 736/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3311 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 737/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3178 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2800 - val_binary_accuracy: 0.9625\n",
      "Epoch 738/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3156 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 739/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0018 - accuracy: 0.3533 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2800 - val_binary_accuracy: 0.9625\n",
      "Epoch 740/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3222 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 741/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3422 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 742/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3311 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2800 - val_binary_accuracy: 0.9625\n",
      "Epoch 743/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3267 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 744/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3400 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2800 - val_binary_accuracy: 0.9625\n",
      "Epoch 745/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3133 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 746/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3311 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2800 - val_binary_accuracy: 0.9625\n",
      "Epoch 747/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3289 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2800 - val_binary_accuracy: 0.9625\n",
      "Epoch 748/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3178 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 749/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0018 - accuracy: 0.3244 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2800 - val_binary_accuracy: 0.9625\n",
      "Epoch 750/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3067 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 751/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3333 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2800 - val_binary_accuracy: 0.9625\n",
      "Epoch 752/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3156 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 753/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3400 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2800 - val_binary_accuracy: 0.9625\n",
      "Epoch 754/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3222 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2600 - val_binary_accuracy: 0.9625\n",
      "Epoch 755/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3467 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 756/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3222 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 757/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3333 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 758/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0018 - accuracy: 0.3222 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 759/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 0.3533 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2800 - val_binary_accuracy: 0.9625\n",
      "Epoch 760/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3244 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 761/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3422 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 762/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3222 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 763/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3400 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 764/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 0.3556 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 765/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3378 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 766/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3089 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.2800 - val_binary_accuracy: 0.9625\n",
      "Epoch 767/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3244 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 768/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3511 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 769/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0018 - accuracy: 0.3533 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 770/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3578 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 771/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3578 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 772/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3533 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 773/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 0.3289 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 774/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.3533 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 775/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3489 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 776/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3556 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 777/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3556 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 778/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3467 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 779/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 0.3533 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 780/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3511 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 781/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3511 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 782/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0018 - accuracy: 0.3511 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 783/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3533 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 784/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3578 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 785/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3533 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 786/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3556 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 787/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3556 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 788/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3511 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 789/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 0.3578 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 790/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3533 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 791/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0018 - accuracy: 0.3578 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 792/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3467 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 793/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3489 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 794/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0018 - accuracy: 0.3489 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 795/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3533 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 796/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3533 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 797/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3489 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 798/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3533 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 799/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3489 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 800/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0018 - accuracy: 0.3511 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 801/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3578 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 802/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3511 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 803/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.3511 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 804/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3556 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 805/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3556 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 806/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 0.3600 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 807/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3556 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 808/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0018 - accuracy: 0.3511 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 809/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3533 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 810/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3622 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 811/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3533 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 812/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3533 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 813/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3600 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 814/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3556 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 815/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3444 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 816/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3489 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 817/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.3578 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 818/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3578 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 819/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0018 - accuracy: 0.3556 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 820/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3578 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 821/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3533 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3000 - val_binary_accuracy: 0.9625\n",
      "Epoch 822/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3578 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 823/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3578 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 824/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3533 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 825/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3533 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 826/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 0.3533 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 827/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3489 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 828/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3644 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 829/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0018 - accuracy: 0.3622 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 830/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0018 - accuracy: 0.3578 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 831/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 0.3533 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 832/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3622 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 833/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3556 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 834/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3578 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 835/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3600 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 836/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0018 - accuracy: 0.3533 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 837/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3511 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 838/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3644 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 839/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3533 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 840/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3556 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 841/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3556 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 842/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3578 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 843/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0018 - accuracy: 0.3533 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 844/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.3600 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 845/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3578 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 846/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3556 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 847/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3622 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 848/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 0.3600 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 849/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3533 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 850/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3556 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 851/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3600 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 852/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0018 - accuracy: 0.3578 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 853/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3578 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 854/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3556 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 855/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3600 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 856/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3689 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 857/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3622 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 858/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3556 - binary_accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 859/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3600 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 860/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.3644 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 861/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3622 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 862/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3578 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 863/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3533 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 864/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0018 - accuracy: 0.3622 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 865/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3533 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 866/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3511 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 867/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3533 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 868/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3556 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 869/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3644 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 870/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 0.3556 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 871/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3644 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 872/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3556 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 873/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3622 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 874/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 0.3578 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 875/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3600 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 876/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.3578 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 877/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3644 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 878/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3600 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 879/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3667 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 880/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 0.3622 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 881/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3644 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 882/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3622 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 883/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3533 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 884/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0018 - accuracy: 0.3533 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 885/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0018 - accuracy: 0.3600 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 886/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3622 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 887/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3622 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 888/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 0.3622 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 889/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3578 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 890/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3578 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 891/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3622 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 892/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0018 - accuracy: 0.3600 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 893/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3622 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 894/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3556 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 895/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3622 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 896/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 0.3667 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 897/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3578 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 898/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3689 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 899/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3667 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 900/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0018 - accuracy: 0.3689 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 901/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3667 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 902/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3578 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 903/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3644 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 904/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3644 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 905/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3711 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 906/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3689 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 907/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0018 - accuracy: 0.3689 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 908/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 0.3689 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 909/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3711 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 910/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3644 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 911/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3622 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 912/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3667 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 913/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3667 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 914/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3711 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 915/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3644 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9625\n",
      "Epoch 916/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3689 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 917/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0018 - accuracy: 0.3667 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 918/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3689 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9625\n",
      "Epoch 919/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3667 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 920/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3667 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 921/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3667 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 922/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3711 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 923/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3689 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 924/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3667 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 925/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.3689 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 926/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3644 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 927/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0018 - accuracy: 0.3711 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 928/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3644 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 929/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.3733 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 930/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3711 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 931/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3667 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 932/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3689 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 933/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.3689 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 934/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3689 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 935/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3667 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 936/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0018 - accuracy: 0.3689 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 937/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 0.3689 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 938/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3756 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 939/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3689 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 940/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3689 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 941/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3689 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 942/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3689 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 943/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3667 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 944/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0018 - accuracy: 0.3756 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 945/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 0.3667 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 946/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3733 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 947/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3689 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 948/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3733 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 949/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3689 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 950/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.3778 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 951/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3689 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 952/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.3644 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 953/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3733 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 954/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.3711 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 955/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3711 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 956/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3667 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 957/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3667 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 958/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3756 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 959/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3733 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 960/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0018 - accuracy: 0.3756 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 961/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 0.3711 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 962/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 0.3711 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 963/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3667 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 964/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3667 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 965/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3756 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 966/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3689 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 967/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0018 - accuracy: 0.3711 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 968/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3733 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 969/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3689 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 970/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3667 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 971/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3667 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 972/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3733 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 973/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 0.3756 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 974/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3756 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 975/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0018 - accuracy: 0.3711 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 976/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 0.3667 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 977/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3689 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 978/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3756 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 979/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3711 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 980/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3711 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 981/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0018 - accuracy: 0.3711 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 982/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0018 - accuracy: 0.3711 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 983/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3733 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 984/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3733 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 985/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3778 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 986/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3756 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 987/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3711 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 988/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3733 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 989/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3689 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 990/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3711 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 991/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0018 - accuracy: 0.3667 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 992/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.3689 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 993/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3711 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 994/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.3689 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 995/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3711 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 996/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3689 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 997/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.3667 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3400 - val_binary_accuracy: 0.9638\n",
      "Epoch 998/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.3733 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 999/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.3733 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n",
      "Epoch 1000/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0018 - accuracy: 0.3644 - binary_accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.3200 - val_binary_accuracy: 0.9638\n"
     ]
    }
   ],
   "source": [
    "history = train_model(neural_network, train_samples, train_labels, \n",
    "                      batch_size=batch_size, \n",
    "                      epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23270000517368317, 0.17999380826950073, 0.1710319072008133, 0.1600344479084015, 0.1516106277704239, 0.13904531300067902, 0.12700146436691284, 0.1163424700498581, 0.10639842599630356, 0.0988161563873291, 0.09070663154125214, 0.08443915843963623, 0.07915252447128296, 0.07398084551095963, 0.0688399001955986, 0.06435774266719818, 0.06125595048069954, 0.05603983253240585, 0.05331557244062424, 0.0493965670466423, 0.04501345381140709, 0.04248121753334999, 0.039410460740327835, 0.03709980472922325, 0.03460447117686272, 0.03263312578201294, 0.030630582943558693, 0.02864670194685459, 0.027184903621673584, 0.025326408445835114, 0.025075552985072136, 0.02425752766430378, 0.021700717508792877, 0.02045292966067791, 0.018865790218114853, 0.0181280504912138, 0.01677386462688446, 0.01558989379554987, 0.014466234482824802, 0.013972287066280842, 0.013039893470704556, 0.012156488373875618, 0.011803263798356056, 0.010862383991479874, 0.010598442517220974, 0.010106401517987251, 0.009482254274189472, 0.00902839470654726, 0.008692346513271332, 0.00834378320723772, 0.007899941876530647, 0.007470597047358751, 0.007152310572564602, 0.006875279359519482, 0.006522328592836857, 0.00622941181063652, 0.005948736798018217, 0.005742918234318495, 0.00551086338236928, 0.005312447436153889, 0.005145504139363766, 0.004949122667312622, 0.00478944880887866, 0.004614569246768951, 0.0044791544787585735, 0.004283381160348654, 0.004203210584819317, 0.004096439108252525, 0.0039922380819916725, 0.003928257152438164, 0.0038460034411400557, 0.0038100462406873703, 0.0037361886352300644, 0.0036797779612243176, 0.0036471239291131496, 0.0035822284407913685, 0.0035086306743323803, 0.0034336289390921593, 0.003364728996530175, 0.003306213766336441, 0.0032528548035770655, 0.003226382890716195, 0.0031957414466887712, 0.00315480655990541, 0.0031899348832666874, 0.003107798984274268, 0.003055105684325099, 0.0030363707337528467, 0.0030004566069692373, 0.0029599606059491634, 0.0029612795915454626, 0.0028933058492839336, 0.002833695849403739, 0.00275011220946908, 0.0027149775996804237, 0.00269707222469151, 0.002620147308334708, 0.0025802284944802523, 0.002557219471782446, 0.0025497949682176113, 0.0025290800258517265, 0.0025203670375049114, 0.0025121343787759542, 0.0025049124378710985, 0.002498979913070798, 0.0024941032752394676, 0.002488952362909913, 0.0024843798018991947, 0.0024801890831440687, 0.0024764458648860455, 0.0024731371086090803, 0.0024701126385480165, 0.0024669605772942305, 0.0024635784793645144, 0.0024612906854599714, 0.0024582569021731615, 0.00245541799813509, 0.002453456399962306, 0.002450765809044242, 0.0024489830248057842, 0.002446599304676056, 0.0024443238507956266, 0.002442900789901614, 0.0024403969291597605, 0.0024383605923503637, 0.0024368364829570055, 0.0024350176099687815, 0.0024334557820111513, 0.002431944478303194, 0.0024304441176354885, 0.002428904641419649, 0.0024276436306536198, 0.002426126739010215, 0.0024248945992439985, 0.002423664554953575, 0.00242242100648582, 0.002421149518340826, 0.0024201213382184505, 0.0024187627714127302, 0.002417599782347679, 0.0024167972151190042, 0.0024156011641025543, 0.0024144367780536413, 0.002413421170786023, 0.0024124227929860353, 0.0024113748222589493, 0.002410301472991705, 0.002409408800303936, 0.0024083165917545557, 0.0024072439409792423, 0.002405828330665827, 0.002404693281278014, 0.0024025775492191315, 0.0024001258425414562, 0.0023948014713823795, 0.0023827480617910624, 0.002345623914152384, 0.002284650458022952, 0.0022811528760939837, 0.0022779761347919703, 0.0022739728447049856, 0.0022714261431246996, 0.002267981879413128, 0.002266307594254613, 0.002264773240312934, 0.002263581147417426, 0.0022625457495450974, 0.0022615997586399317, 0.0022605941630899906, 0.002259829081594944, 0.002258991589769721, 0.002258466323837638, 0.002257827203720808, 0.002257193438708782, 0.0022564914543181658, 0.002255911473184824, 0.0022552385926246643, 0.0022546423133462667, 0.0022541587240993977, 0.002253506099805236, 0.0022529475390911102, 0.0022522357758134604, 0.0022514944430440664, 0.0022510711569339037, 0.0022494837176054716, 0.002247865777462721, 0.0022494809236377478, 0.0022461572661995888, 0.002172966720536351, 0.0021506124176084995, 0.002145597478374839, 0.0021276918705552816, 0.0021245907992124557, 0.002120319055393338, 0.0021184738725423813, 0.0021161441691219807, 0.0021143448539078236, 0.002112842630594969, 0.0021121196914464235, 0.0021111697424203157, 0.00211058440618217, 0.002109858440235257, 0.0021094472613185644, 0.002108920132741332, 0.0021084719337522984, 0.0021079881116747856, 0.0021077515557408333, 0.0021072584204375744, 0.0021068414207547903, 0.002106453524902463, 0.0021061100997030735, 0.0021057676058262587, 0.0021054171957075596, 0.0021051603835076094, 0.0021048195194453, 0.002104494720697403, 0.0021041680593043566, 0.0021038681734353304, 0.002103496342897415, 0.0021032532677054405, 0.0021029466297477484, 0.0021025515161454678, 0.0021022732835263014, 0.0021019685082137585, 0.002101507969200611, 0.002100961748510599, 0.0021002930589020252, 0.002099260687828064, 0.0020992327481508255, 0.0020906878635287285, 0.0020230740774422884, 0.0020588489715009928, 0.0020599709823727608, 0.002014793222770095, 0.00200945558026433, 0.002020803513005376, 0.0020224133040755987, 0.0020677680149674416, 0.0020261146128177643, 0.0019920282065868378, 0.0019903916399925947, 0.0019884915091097355, 0.0019746506586670876, 0.0019707470200955868, 0.0019676578231155872, 0.001965980278328061, 0.0019638773519545794, 0.0019631253089755774, 0.0019624228589236736, 0.001961508532986045, 0.0019610566087067127, 0.0019606961868703365, 0.0019602770917117596, 0.001959929708391428, 0.0019596361089497805, 0.0019593616016209126, 0.001959118526428938, 0.001958873588591814, 0.001958644948899746, 0.001958423526957631, 0.00195821700617671, 0.0019580386579036713, 0.0019578489009290934, 0.0019576544873416424, 0.0019574747420847416, 0.0019573220051825047, 0.0019571534357964993, 0.0019570146687328815, 0.001956862397491932, 0.001956707099452615, 0.0019565874245017767, 0.001956482417881489, 0.001956330146640539, 0.0019561785738915205, 0.001956057967618108, 0.0019559271167963743, 0.0019558058120310307, 0.001955702668055892, 0.0019555811304599047, 0.001955456333234906, 0.001955348299816251, 0.001955245155841112, 0.0019551459699869156, 0.0019550512079149485, 0.001954940613359213, 0.0019548493437469006, 0.001954731997102499, 0.0019546349067240953, 0.001954546431079507, 0.0019544532988220453, 0.0019543543457984924, 0.0019542581867426634, 0.00195416365750134, 0.00195407890714705, 0.0019540060311555862, 0.001953914063051343, 0.0019538295455276966, 0.0019537529442459345, 0.0019536702893674374, 0.001953580416738987, 0.0019535021856427193, 0.0019534302409738302, 0.0019533534068614244, 0.001953285885974765, 0.0019531906582415104, 0.0019531199941411614, 0.0019530481658875942, 0.001952972961589694, 0.0019529061391949654, 0.0019528394332155585, 0.0019527607364580035, 0.0019526883261278272, 0.0019526277901604772, 0.0019525560783222318, 0.0019524923991411924, 0.0019524357048794627, 0.001952355494722724, 0.0019522930961102247, 0.0019522301154211164, 0.001952164457179606, 0.0019521111389622092, 0.0019520317437127233, 0.0019519656198099256, 0.0019518998451530933, 0.001951847574673593, 0.001951772253960371, 0.001951700891368091, 0.0019516434986144304, 0.001951561658643186, 0.0019514819141477346, 0.001951399608515203, 0.0019512971630319953, 0.0019511848222464323, 0.0019510240526869893, 0.0019509802805259824, 0.0019506339449435472, 0.0019502926152199507, 0.0019496340537443757, 0.0019471808336675167, 0.0019362318562343717, 0.0019736015237867832, 0.001924772746860981, 0.001880386844277382, 0.0019901120103895664, 0.0018357621738687158, 0.0018570821266621351, 0.001853712135925889, 0.001830710913054645, 0.0018310066079720855, 0.0018234176095575094, 0.0018197118770331144, 0.0018178396858274937, 0.0018173657590523362, 0.0018161182524636388, 0.0018155043944716454, 0.0018151424592360854, 0.0018147171940654516, 0.0018144426867365837, 0.0018141834298148751, 0.0018139943713322282, 0.0018137579318135977, 0.0018135936697944999, 0.001813405891880393, 0.001813240465708077, 0.0018131162505596876, 0.0018129933159798384, 0.0018128514057025313, 0.0018127226503565907, 0.0018126103095710278, 0.001812503207474947, 0.0018123863264918327, 0.001812300062738359, 0.0018121920293197036, 0.00181210704613477, 0.0018120135646313429, 0.0018119282322004437, 0.00181184196844697, 0.0018117604777216911, 0.0018116873688995838, 0.0018116033170372248, 0.001811531255953014, 0.0018114595441147685, 0.0018113934202119708, 0.0018113222904503345, 0.0018112541874870658, 0.0018111863173544407, 0.001811126247048378, 0.0018110708333551884, 0.0018110123928636312, 0.0018109612865373492, 0.0018109045922756195, 0.0018108503427356482, 0.001810797373764217, 0.0018107501091435552, 0.0018107012147083879, 0.0018106532515957952, 0.0018106057541444898, 0.001810558489523828, 0.0018105172784999013, 0.0018104711780324578, 0.0018104249611496925, 0.0018103807233273983, 0.0018103413749486208, 0.001810298184864223, 0.001810261164791882, 0.0018102198373526335, 0.0018101840978488326, 0.0018101424211636186, 0.0018101095920428634, 0.001810069428756833, 0.0018100327579304576, 0.001809997484087944, 0.001809960580430925, 0.0018099261214956641, 0.0018098929431289434, 0.0018098584841936827, 0.0018098254222422838, 0.0018097958527505398, 0.0018097592983394861, 0.0018097292631864548, 0.0018096991116181016, 0.0018096682615578175, 0.0018096375279128551, 0.0018096088897436857, 0.0018095786217600107, 0.0018095477716997266, 0.0018095197156071663, 0.0018094937549903989, 0.0018094650004059076, 0.0018094388069584966, 0.0018094098195433617, 0.0018093845574185252, 0.0018093568505719304, 0.001809334265999496, 0.0018093069083988667, 0.0018092799000442028, 0.0018092556856572628, 0.0018092297250404954, 0.001809204462915659, 0.0018091816455125809, 0.0018091569654643536, 0.0018091328674927354, 0.001809112261980772, 0.0018090875819325447, 0.0018090651137754321, 0.001809042994864285, 0.001809019478969276, 0.0018089973600581288, 0.0018089775694534183, 0.0018089587101712823, 0.0018089346121996641, 0.0018089152872562408, 0.0018088945653289557, 0.0018088739598169923, 0.0018088531214743853, 0.001808833796530962, 0.001808812958188355, 0.0018087963107973337, 0.0018087753560394049, 0.001808756496757269, 0.0018087397329509258, 0.0018087199423462152, 0.001808700617402792, 0.0018086829222738743, 0.0018086646450683475, 0.0018086464842781425, 0.0018086296040564775, 0.0018086116760969162, 0.0018085965421050787, 0.0018085780320689082, 0.001808559405617416, 0.001808541244827211, 0.0018085248302668333, 0.001808508182875812, 0.0018084896728396416, 0.0018084743060171604, 0.0018084583571180701, 0.001808441593311727, 0.001808425411581993, 0.001808409346267581, 0.0018083935137838125, 0.0018083793111145496, 0.0018083638278767467, 0.0018083469476550817, 0.0018083334434777498, 0.0018083184259012341, 0.0018083021277561784, 0.0018082878086715937, 0.0018082736060023308, 0.001808259985409677, 0.0018082454334944487, 0.0018082302995026112, 0.001808216329663992, 0.0018082024762406945, 0.0018081885064020753, 0.0018081747693940997, 0.001808161148801446, 0.0018081484595313668, 0.0018081339076161385, 0.0018081206362694502, 0.0018081068992614746, 0.0018080946756526828, 0.0018080828012898564, 0.0018080695299431682, 0.0018080569570884109, 0.001808042754419148, 0.0018080301815643907, 0.0018080166773870587, 0.001808005734346807, 0.0018079937435686588, 0.001807980821467936, 0.0018079702276736498, 0.0018079569563269615, 0.0018079453147947788, 0.0018079336732625961, 0.0018079235451295972, 0.0018079117871820927, 0.0018078992143273354, 0.0018078889697790146, 0.0018078763969242573, 0.0018078647553920746, 0.0018078534631058574, 0.0018078427528962493, 0.0018078319262713194, 0.0018078205175697803, 0.0018078112043440342, 0.0018077981658279896, 0.0018077883869409561, 0.0018077782588079572, 0.0018077677814289927, 0.001807757536880672, 0.001807747408747673, 0.0018077364657074213, 0.0018077273853123188, 0.0018077183049172163, 0.0018077063141390681, 0.0018076961860060692, 0.0018076857086271048, 0.001807676162570715, 0.0018076659180223942, 0.001807656604796648, 0.00180764717515558, 0.0018076373962685466, 0.0018076269188895822, 0.0018076172564178705, 0.0018076086416840553, 0.0018075990956276655, 0.0018075896659865975, 0.0018075802363455296, 0.0018075702246278524, 0.00180756242480129, 0.0018075521802529693, 0.0018075437983497977, 0.001807534135878086, 0.0018075258703902364, 0.0018075169064104557, 0.0018075087573379278, 0.0018074994441121817, 0.0018074894323945045, 0.001807483145967126, 0.001807475695386529, 0.0018074667314067483, 0.001807458116672933, 0.0018074492691084743, 0.0018074391409754753, 0.0018074329709634185, 0.0018074234249070287, 0.0018074153922498226, 0.0018074066611006856, 0.0018073987448588014, 0.0018073907122015953, 0.001807382213883102, 0.0018073742976412177, 0.001807366730645299, 0.0018073591636493802, 0.0018073515966534615, 0.00180734321475029, 0.001807334367185831, 0.0018073280807584524, 0.0018073212122544646, 0.0018073121318593621, 0.0018073050305247307, 0.00180729734711349, 0.0018072895472869277, 0.0018072820967063308, 0.0018072751117870212, 0.0018072682432830334, 0.0018072598613798618, 0.0018072528764605522, 0.0018072464736178517, 0.0018072387902066112, 0.0018072311067953706, 0.0018072244711220264, 0.0018072176026180387, 0.0018072105012834072, 0.0018072029342874885, 0.0018071966478601098, 0.0018071903614327312, 0.0018071829108521342, 0.00180717627517879, 0.001807168941013515, 0.0018071626545861363, 0.0018071567174047232, 0.0018071492668241262, 0.0018071437953040004, 0.001807135995477438, 0.0018071294762194157, 0.0018071233062073588, 0.001807116437703371, 0.001807109685614705, 0.0018071025842800736, 0.0018070974620059133, 0.0018070905935019255, 0.0018070837249979377, 0.0018070780206471682, 0.0018070721998810768, 0.0018070654477924109, 0.0018070591613650322, 0.0018070526421070099, 0.0018070470541715622, 0.0018070406513288617, 0.0018070349469780922, 0.0018070284277200699, 0.0018070221412926912, 0.0018070166697725654, 0.0018070103833451867, 0.001807004795409739, 0.001806998741813004, 0.0018069930374622345, 0.0018069872166961432, 0.0018069815123453736, 0.001806974527426064, 0.0018069702200591564, 0.0018069639336317778, 0.0018069581128656864, 0.0018069519428536296, 0.0018069468205794692, 0.0018069416983053088, 0.001806936808861792, 0.001806930871680379, 0.0018069251673296094, 0.0018069195793941617, 0.001806914689950645, 0.001806909334845841, 0.0018069035140797496, 0.0018068983918055892, 0.001806892454624176, 0.001806887798011303, 0.001806882442906499, 0.0018068770878016949, 0.0018068718491122127, 0.0018068663775920868, 0.0018068618373945355, 0.0018068563658744097, 0.001806850777938962, 0.0018068458884954453, 0.001806840649805963, 0.0018068358767777681, 0.0018068307545036077, 0.0018068257486447692, 0.0018068207427859306, 0.001806815853342414, 0.0018068111967295408, 0.0018068060744553804, 0.00180680095218122, 0.0018067967612296343, 0.0018067924538627267, 0.0018067859346047044, 0.0018067818600684404, 0.0018067773198708892, 0.0018067725468426943, 0.0018067677738144994, 0.0018067634664475918, 0.0018067586934193969, 0.001806753920391202, 0.0018067493801936507, 0.0018067447235807776, 0.0018067400669679046, 0.0018067365745082498, 0.001806730986572802, 0.0018067271448671818, 0.0018067228375002742, 0.001806718297302723, 0.0018067137571051717, 0.001806709449738264, 0.0018067049095407128, 0.0018067011842504144, 0.0018066966440528631, 0.0018066923366859555, 0.001806687912903726, 0.0018066834891214967, 0.0018066796474158764, 0.001806675223633647, 0.0018066706834360957, 0.0018066667253151536, 0.0018066626507788897, 0.0018066584598273039, 0.0018066546181216836, 0.001806650310754776, 0.0018066460033878684, 0.0018066416960209608, 0.0018066377379000187, 0.001806633430533111, 0.0018066299380734563, 0.0018066255142912269, 0.0018066216725856066, 0.0018066179472953081, 0.0018066136399284005, 0.0018066102638840675, 0.0018066063057631254, 0.0018066022312268615, 0.0018065979238599539, 0.0018065948970615864, 0.0018065905896946788, 0.0018065862823277712, 0.00180658302269876, 0.0018065787153318524, 0.0018065751064568758, 0.0018065712647512555, 0.0018065680051222444, 0.0018065640470013022, 0.0018065606709569693, 0.0018065570620819926, 0.0018065529875457287, 0.0018065494950860739, 0.0018065457697957754, 0.0018065419280901551, 0.0018065389012917876, 0.0018065348267555237, 0.0018065322656184435, 0.0018065277254208922, 0.0018065242329612374, 0.0018065208569169044, 0.0018065168987959623, 0.0018065139884129167, 0.0018065100302919745, 0.0018065068870782852, 0.001806502928957343, 0.001806499669328332, 0.0018064965261146426, 0.001806492917239666, 0.0018064891919493675, 0.0018064863979816437, 0.0018064825562760234, 0.0018064792966470122, 0.0018064763862639666, 0.0018064731266349554, 0.0018064696341753006, 0.0018064662581309676, 0.0018064629985019565, 0.001806459971703589, 0.0018064562464132905, 0.0018064534524455667, 0.0018064497271552682, 0.0018064467003569007, 0.0018064439063891768, 0.0018064405303448439, 0.0018064373871311545, 0.0018064344767481089, 0.0018064312171190977, 0.0018064280739054084, 0.001806424930691719, 0.0018064213218167424, 0.001806418178603053, 0.0018064152682200074, 0.0018064130563288927, 0.0018064093310385942, 0.0018064064206555486, 0.0018064030446112156, 0.001806400716304779, 0.001806397340260446, 0.0018063947791233659, 0.0018063911702483892, 0.001806388609111309, 0.0018063854658976197, 0.0018063823226839304, 0.0018063795287162066, 0.001806376501917839, 0.0018063734751194715, 0.0018063709139823914, 0.0018063681200146675, 0.0018063653260469437, 0.0018063627649098635, 0.0018063595052808523, 0.0018063565948978066, 0.0018063540337607265, 0.0018063513562083244, 0.001806348212994635, 0.001806345535442233, 0.0018063430907204747, 0.0018063400639221072, 0.0018063372699543834, 0.0018063347088173032, 0.0018063320312649012, 0.0018063299357891083, 0.0018063266761600971, 0.001806324115023017, 0.001806321437470615, 0.0018063185270875692, 0.001806315965950489, 0.0018063130555674434, 0.0018063110765069723, 0.0018063081661239266, 0.0018063053721562028, 0.0018063028110191226, 0.0018063003662973642, 0.001806297805160284, 0.0018062955932691693, 0.0018062926828861237, 0.0018062901217490435, 0.001806287793442607, 0.001806285115890205, 0.0018062824383378029, 0.00180628034286201, 0.0018062774324789643, 0.0018062748713418841, 0.0018062724266201258, 0.0018062700983136892, 0.0018062670715153217, 0.0018062649760395288, 0.0018062626477330923, 0.001806260203011334, 0.0018062579911202192, 0.0018062553135678172, 0.0018062531016767025, 0.0018062506569549441, 0.0018062479794025421, 0.0018062458839267492, 0.0018062435556203127, 0.0018062409944832325, 0.0018062387825921178, 0.001806236687116325, 0.0018062341259792447, 0.0018062321469187737, 0.0018062294693663716, 0.0018062273738905787, 0.0018062249291688204, 0.0018062232993543148, 0.0018062206218019128, 0.001806218409910798, 0.0018062161980196834, 0.0018062141025438905, 0.0018062122398987412, 0.0018062094459310174, 0.0018062073504552245, 0.0018062051385641098, 0.001806203043088317, 0.0018062008311972022, 0.0018061986193060875, 0.0018061964074149728, 0.001806194195523858, 0.0018061918672174215, 0.0018061898881569505, 0.0018061877926811576, 0.0018061856972053647, 0.00180618348531425, 0.0018061816226691008, 0.0018061795271933079, 0.001806177431717515, 0.0018061752198264003, 0.001806173357181251, 0.0018061712617054582, 0.0018061690498143435, 0.0018061670707538724, 0.0018061650916934013, 0.0018061631126329303, 0.0018061611335724592, 0.0018061595037579536, 0.001806157291866839, 0.0018061549635604024, 0.0018061531009152532, 0.001806151121854782, 0.0018061492592096329, 0.0018061473965644836, 0.0018061453010886908, 0.0018061434384435415, 0.001806141110137105, 0.0018061395967379212, 0.0018061373848468065, 0.0018061351729556918, 0.0018061334267258644, 0.0018061315640807152, 0.0018061299342662096, 0.0018061278387904167, 0.0018061260925605893, 0.0018061239970847964, 0.0018061223672702909, 0.0018061201553791761, 0.0018061186419799924, 0.0018061165465041995, 0.0018061146838590503, 0.001806112821213901, 0.0018061110749840736, 0.0018061092123389244, 0.001806107466109097, 0.0018061057198792696, 0.0018061039736494422, 0.0018061023438349366, 0.0018061005976051092, 0.0018060986185446382, 0.001806096755899489, 0.0018060951260849833, 0.0018060931470245123, 0.0018060917500406504, 0.0018060898873955011, 0.001806088024750352, 0.0018060861621052027, 0.0018060844158753753, 0.0018060826696455479, 0.0018060811562463641, 0.0018060792936012149, 0.0018060775473713875, 0.0018060761503875256, 0.0018060742877423763, 0.0018060727743431926, 0.0018060707952827215, 0.0018060690490528941, 0.0018060676520690322, 0.0018060660222545266, 0.001806064392440021, 0.0018060626462101936, 0.0018060607835650444, 0.0018060592701658607, 0.001806057640351355, 0.0018060560105368495, 0.001806054380722344, 0.0018060532165691257, 0.0018060511210933328, 0.0018060493748635054, 0.0018060477450489998, 0.0018060464644804597, 0.0018060448346659541, 0.0018060429720208049, 0.0018060416914522648, 0.0018060399452224374, 0.0018060384318232536, 0.0018060371512547135, 0.0018060352886095643, 0.0018060337752103806, 0.0018060322618111968, 0.001806030748412013, 0.0018060292350128293, 0.0018060276051983237, 0.0018060258589684963, 0.001806024694815278, 0.0018060232978314161, 0.0018060217844322324, 0.0018060201546177268, 0.001806018641218543, 0.0018060174770653248, 0.0018060157308354974, 0.0018060145666822791, 0.0018060129368677735, 0.0018060114234685898, 0.0018060101429000497, 0.0018060081638395786, 0.001806007232517004, 0.0018060056027024984, 0.0018060043221339583, 0.0018060026923194528, 0.0018060015281662345, 0.0018060001311823726, 0.0018059987341985106, 0.001805997104384005, 0.0018059955909848213, 0.0018059940775856376, 0.001805993146263063, 0.0018059916328638792, 0.0018059902358800173, 0.0018059888388961554, 0.0018059873254969716, 0.0018059858120977879, 0.0018059845315292478, 0.0018059834837913513, 0.0018059820868074894, 0.0018059806898236275, 0.0018059791764244437, 0.0018059778958559036, 0.0018059766152873635, 0.0018059753347188234, 0.001805974286980927, 0.0018059727735817432, 0.0018059714930132031, 0.0018059700960293412, 0.0018059688154608011, 0.001805967534892261, 0.001805966254323721, 0.001805964857339859, 0.0018059638096019626, 0.0018059626454487443, 0.0018059612484648824, 0.0018059598514810205, 0.001805958803743124, 0.0018059572903439403, 0.0018059562426060438, 0.0018059549620375037, 0.0018059536814689636, 0.0018059524009004235, 0.001805951353162527, 0.0018059498397633433]\n",
      "[0.19362352788448334, 0.16941669583320618, 0.16229084134101868, 0.15323786437511444, 0.14277401566505432, 0.13207706809043884, 0.11926634609699249, 0.10929623246192932, 0.10080578923225403, 0.09364423900842667, 0.0895259827375412, 0.08714298158884048, 0.0822196677327156, 0.07956884056329727, 0.07627644389867783, 0.07672913372516632, 0.07141264528036118, 0.06856062263250351, 0.06795050203800201, 0.06364219635725021, 0.06134141981601715, 0.05965994670987129, 0.05708474665880203, 0.054500218480825424, 0.0523654967546463, 0.051503606140613556, 0.04852243885397911, 0.04810987412929535, 0.04918574169278145, 0.047867026180028915, 0.046397529542446136, 0.04580327123403549, 0.044504210352897644, 0.04326518625020981, 0.04248974472284317, 0.041081905364990234, 0.04028761386871338, 0.039275266230106354, 0.039377011358737946, 0.03884114325046539, 0.038774121552705765, 0.038789063692092896, 0.03674621134996414, 0.03644658625125885, 0.03633527457714081, 0.03617551177740097, 0.03573232144117355, 0.03523948788642883, 0.03539740666747093, 0.03482833877205849, 0.03477323427796364, 0.033746350556612015, 0.03444414213299751, 0.03423421084880829, 0.03441093489527702, 0.033392030745744705, 0.03362151235342026, 0.033481474965810776, 0.033472031354904175, 0.03354892134666443, 0.03365093469619751, 0.033343926072120667, 0.03321866691112518, 0.032614566385746, 0.032890867441892624, 0.03261978551745415, 0.0328327938914299, 0.03252924606204033, 0.0328865610063076, 0.03275609761476517, 0.032580550760030746, 0.032687291502952576, 0.03258076682686806, 0.03244587033987045, 0.03255615383386612, 0.03243880346417427, 0.03260740265250206, 0.032251182943582535, 0.032479818910360336, 0.03232922405004501, 0.03230499103665352, 0.03245890885591507, 0.032396260648965836, 0.03269553557038307, 0.03270694613456726, 0.03266728296875954, 0.03257857263088226, 0.03231491893529892, 0.03188127651810646, 0.031925905495882034, 0.03176061064004898, 0.03182756528258324, 0.031932033598423004, 0.03201337903738022, 0.032022129744291306, 0.032424479722976685, 0.03258335962891579, 0.032453082501888275, 0.03234348073601723, 0.03220729902386665, 0.03231064975261688, 0.03227696195244789, 0.0321158729493618, 0.03212100267410278, 0.03219684213399887, 0.032177187502384186, 0.032074086368083954, 0.032181210815906525, 0.032228030264377594, 0.03217519074678421, 0.03214684873819351, 0.032195787876844406, 0.03214075416326523, 0.03209973871707916, 0.032086119055747986, 0.032112766057252884, 0.032146889716386795, 0.03216584026813507, 0.0321892611682415, 0.03207593411207199, 0.03203122690320015, 0.03214440122246742, 0.03215572610497475, 0.032161418348550797, 0.032134633511304855, 0.03211013600230217, 0.03207780420780182, 0.03207848593592644, 0.032077591866254807, 0.03210790827870369, 0.03204481303691864, 0.03204209357500076, 0.032080747187137604, 0.03209661692380905, 0.03205759450793266, 0.03208783268928528, 0.03203434497117996, 0.03208991140127182, 0.03213214501738548, 0.03212062269449234, 0.03210342302918434, 0.03213800489902496, 0.03214219957590103, 0.032087672501802444, 0.032078761607408524, 0.03209977596998215, 0.03211437538266182, 0.032092224806547165, 0.03206324949860573, 0.03206928074359894, 0.03205256909132004, 0.032038990408182144, 0.03206319734454155, 0.031985294073820114, 0.03195001929998398, 0.03193251043558121, 0.03187553957104683, 0.032306745648384094, 0.03207157924771309, 0.03221064433455467, 0.032293565571308136, 0.03219223767518997, 0.03207896649837494, 0.03205248713493347, 0.03205057978630066, 0.03208378702402115, 0.032100874930620193, 0.0321090929210186, 0.03213869407773018, 0.032152753323316574, 0.03214646503329277, 0.03211835026741028, 0.03210541605949402, 0.03215577080845833, 0.032196421176195145, 0.03220991790294647, 0.032228950411081314, 0.032211583107709885, 0.032242316752672195, 0.032250162214040756, 0.03222612291574478, 0.032251376658678055, 0.03228187933564186, 0.03225136920809746, 0.03224846348166466, 0.032212380319833755, 0.031930405646562576, 0.0314125157892704, 0.03129434958100319, 0.03114531747996807, 0.030978549271821976, 0.03110242821276188, 0.03126286342740059, 0.03129937872290611, 0.031151097267866135, 0.031158095225691795, 0.031125390902161598, 0.031117115169763565, 0.03111172653734684, 0.0311600249260664, 0.03124426119029522, 0.031265899538993835, 0.0312558114528656, 0.03127995505928993, 0.03131840005517006, 0.03134779632091522, 0.03135719522833824, 0.03133019804954529, 0.03135467320680618, 0.03136756643652916, 0.03137848526239395, 0.031377531588077545, 0.0313744843006134, 0.031381092965602875, 0.03140053525567055, 0.03144156187772751, 0.03143514692783356, 0.031426358968019485, 0.031415876001119614, 0.031451303511857986, 0.031453508883714676, 0.031443916261196136, 0.031428489834070206, 0.03145342320203781, 0.0314587727189064, 0.03146769851446152, 0.03147931024432182, 0.031502388417720795, 0.03156644478440285, 0.03162221983075142, 0.03212500736117363, 0.03249521180987358, 0.03267958387732506, 0.03234007954597473, 0.0323580764234066, 0.03260189667344093, 0.03275739774107933, 0.03266938030719757, 0.03254033625125885, 0.032340049743652344, 0.03222137317061424, 0.032622214406728745, 0.032587967813014984, 0.032094765454530716, 0.03195212408900261, 0.03207361325621605, 0.03214374929666519, 0.032077837735414505, 0.0319538451731205, 0.031880952417850494, 0.03186141699552536, 0.031883977353572845, 0.031905174255371094, 0.03187214583158493, 0.031818412244319916, 0.03177095949649811, 0.03174460679292679, 0.031750213354825974, 0.03173802047967911, 0.03173030912876129, 0.03173050284385681, 0.03172643855214119, 0.03172396123409271, 0.031721752136945724, 0.031698402017354965, 0.03167477995157242, 0.031660452485084534, 0.03165454417467117, 0.031657010316848755, 0.03167038783431053, 0.03167285770177841, 0.031660296022892, 0.03165491297841072, 0.0316641591489315, 0.03166002035140991, 0.03163844347000122, 0.03161385655403137, 0.03160203620791435, 0.03160838782787323, 0.031609173864126205, 0.03162764757871628, 0.031619004905223846, 0.03163404017686844, 0.03161802515387535, 0.03159959986805916, 0.031614117324352264, 0.031635865569114685, 0.03161698952317238, 0.03158514201641083, 0.03156318515539169, 0.031550243496894836, 0.031557656824588776, 0.031571127474308014, 0.03158392384648323, 0.031585078686475754, 0.031573038548231125, 0.03157510235905647, 0.03158320114016533, 0.03157989680767059, 0.03156160190701485, 0.031546518206596375, 0.031550824642181396, 0.031569186598062515, 0.03156273066997528, 0.03154940530657768, 0.031547676771879196, 0.03155018389225006, 0.0315612331032753, 0.031564775854349136, 0.0315687470138073, 0.03155090659856796, 0.03154374659061432, 0.031543243676424026, 0.03154265508055687, 0.03155592083930969, 0.03155440092086792, 0.03156246989965439, 0.03156756982207298, 0.03156549856066704, 0.03156588599085808, 0.03154131770133972, 0.031543437391519547, 0.03156144917011261, 0.031564246863126755, 0.03156337887048721, 0.03155917301774025, 0.031550969928503036, 0.03155135735869408, 0.03154539316892624, 0.03154584392905235, 0.03154869005084038, 0.03155146911740303, 0.03155091032385826, 0.031551554799079895, 0.031539417803287506, 0.031515270471572876, 0.03150532394647598, 0.031487155705690384, 0.03145634010434151, 0.03137318417429924, 0.030970502644777298, 0.031117606908082962, 0.030744634568691254, 0.030681977048516273, 0.03148173913359642, 0.031198495998978615, 0.031075969338417053, 0.03181713819503784, 0.03126050531864166, 0.031076978892087936, 0.031120523810386658, 0.031298693269491196, 0.03129193186759949, 0.031215379014611244, 0.031113963574171066, 0.030996698886156082, 0.03090870939195156, 0.030855605378746986, 0.03085322678089142, 0.030892664566636086, 0.030892616137862206, 0.03086603619158268, 0.03082762472331524, 0.03080289624631405, 0.030804891139268875, 0.030813688412308693, 0.03083701804280281, 0.030873103067278862, 0.030871205031871796, 0.030854567885398865, 0.030845005065202713, 0.030832860618829727, 0.030821390450000763, 0.030811894685029984, 0.030827391892671585, 0.030836196616292, 0.030843045562505722, 0.03085475042462349, 0.03086221218109131, 0.030842510983347893, 0.030819712206721306, 0.030812082812190056, 0.03082175925374031, 0.030846526846289635, 0.030865803360939026, 0.030876608565449715, 0.03086245246231556, 0.030851824209094048, 0.03086048923432827, 0.030875392258167267, 0.030881382524967194, 0.03087354451417923, 0.030857834964990616, 0.030856788158416748, 0.030845720320940018, 0.030845293775200844, 0.03084905445575714, 0.03085542842745781, 0.030844831839203835, 0.030852477997541428, 0.030863100662827492, 0.03085961751639843, 0.030857747420668602, 0.030832510441541672, 0.030822040513157845, 0.03081994131207466, 0.030830897390842438, 0.03082403354346752, 0.030821824446320534, 0.030812835320830345, 0.030818931758403778, 0.030820224434137344, 0.030816325917840004, 0.030830001458525658, 0.03083534725010395, 0.030826540663838387, 0.030823197215795517, 0.030810732394456863, 0.030815308913588524, 0.03081909380853176, 0.030819669365882874, 0.03083539940416813, 0.030840463936328888, 0.030840454623103142, 0.030846746638417244, 0.030839823186397552, 0.03082781471312046, 0.030823171138763428, 0.030829640105366707, 0.03083512932062149, 0.03084401786327362, 0.030857080593705177, 0.030854223296046257, 0.030853422358632088, 0.03085784614086151, 0.030857037752866745, 0.03086511604487896, 0.030859816819429398, 0.030856499448418617, 0.030852077528834343, 0.030842408537864685, 0.03084196336567402, 0.030849136412143707, 0.030863313004374504, 0.030868709087371826, 0.030858974903821945, 0.03085082583129406, 0.03085111826658249, 0.030849194154143333, 0.03086022287607193, 0.030860986560583115, 0.030863473191857338, 0.03086595982313156, 0.030870037153363228, 0.030865531414747238, 0.030865637585520744, 0.03087349236011505, 0.030880432575941086, 0.03087541088461876, 0.030871568247675896, 0.030865870416164398, 0.030871083959937096, 0.030879056081175804, 0.030886242166161537, 0.030891234055161476, 0.03088499791920185, 0.03088751621544361, 0.030886519700288773, 0.03089009039103985, 0.030880825594067574, 0.030877165496349335, 0.03088402934372425, 0.030888665467500687, 0.030904244631528854, 0.03090265952050686, 0.03090047277510166, 0.030899429693818092, 0.030901867896318436, 0.030905013903975487, 0.030901389196515083, 0.030909178778529167, 0.030899669975042343, 0.030900420621037483, 0.03090387023985386, 0.0308937206864357, 0.03088732436299324, 0.030890297144651413, 0.030895089730620384, 0.030903486534953117, 0.03088975138962269, 0.030883051455020905, 0.03089728392660618, 0.030907008796930313, 0.03090624138712883, 0.030905427411198616, 0.030904581770300865, 0.03090435080230236, 0.03090418316423893, 0.03090149350464344, 0.030903542414307594, 0.030896728858351707, 0.030898042023181915, 0.03089623525738716, 0.030905256047844887, 0.03090403974056244, 0.03090151958167553, 0.03089996799826622, 0.030903110280632973, 0.030899150297045708, 0.030899330973625183, 0.030899913981556892, 0.030903562903404236, 0.0309100691229105, 0.030911536887288094, 0.03090943768620491, 0.030906297266483307, 0.03091377019882202, 0.030922021716833115, 0.030923474580049515, 0.030917048454284668, 0.030911052599549294, 0.03090539388358593, 0.030902275815606117, 0.03090442344546318, 0.03090616501867771, 0.030902527272701263, 0.030908310785889626, 0.03091626800596714, 0.03092191368341446, 0.030916457995772362, 0.030915480107069016, 0.03091401979327202, 0.030910994857549667, 0.03090091049671173, 0.030893374234437943, 0.030892224982380867, 0.0309046171605587, 0.030906617641448975, 0.030911169946193695, 0.0309147946536541, 0.03091128170490265, 0.030910374596714973, 0.03090685047209263, 0.030902113765478134, 0.03090895712375641, 0.030909964814782143, 0.030909735709428787, 0.030909987166523933, 0.0309167318046093, 0.030916616320610046, 0.03091072477400303, 0.030904002487659454, 0.030904076993465424, 0.030906813219189644, 0.030904624611139297, 0.030908362939953804, 0.030918514356017113, 0.030918586999177933, 0.03092045709490776, 0.030920149758458138, 0.03091455064713955, 0.030911440029740334, 0.03091397136449814, 0.03092176839709282, 0.03092467226088047, 0.030925622209906578, 0.03091903030872345, 0.03091505542397499, 0.030914897099137306, 0.03090997226536274, 0.030909672379493713, 0.030922062695026398, 0.030917473137378693, 0.030923273414373398, 0.03091239184141159, 0.030906274914741516, 0.030906150117516518, 0.030907858163118362, 0.030905896797776222, 0.030908500775694847, 0.03090999834239483, 0.030915483832359314, 0.030917424708604813, 0.030919943004846573, 0.030927207320928574, 0.030932161957025528, 0.03093564510345459, 0.030932852998375893, 0.030929991975426674, 0.030923858284950256, 0.03091060370206833, 0.03091101162135601, 0.030907411128282547, 0.030903473496437073, 0.03090188279747963, 0.030911307781934738, 0.030920200049877167, 0.030921312049031258, 0.030922845005989075, 0.030920162796974182, 0.03091428056359291, 0.030908063054084778, 0.030910568311810493, 0.03091725893318653, 0.03091689758002758, 0.030916279181838036, 0.030922142788767815, 0.03091403655707836, 0.030907845124602318, 0.030909333378076553, 0.030914392322301865, 0.030908135697245598, 0.03091207891702652, 0.03091346099972725, 0.03091397136449814, 0.030907263979315758, 0.030904924497008324, 0.03090694174170494, 0.030914122238755226, 0.03091471828520298, 0.030905282124876976, 0.030897559598088264, 0.030897431075572968, 0.03090580180287361, 0.030908558517694473, 0.030907658860087395, 0.030904090031981468, 0.03089798055589199, 0.030901825055480003, 0.03090287744998932, 0.030899059027433395, 0.03089953027665615, 0.030901089310646057, 0.030894098803400993, 0.030897393822669983, 0.03089815564453602, 0.0308974701911211, 0.03089054860174656, 0.030890004709362984, 0.030894339084625244, 0.0308972354978323, 0.03089471533894539, 0.030889011919498444, 0.03089502640068531, 0.030897539108991623, 0.030899882316589355, 0.03090575523674488, 0.03091372735798359, 0.03091501258313656, 0.03090778738260269, 0.03090299293398857, 0.030897103250026703, 0.030898960307240486, 0.030898258090019226, 0.030912484973669052, 0.030914364382624626, 0.030907368287444115, 0.03089735470712185, 0.030895141884684563, 0.0309034064412117, 0.030907997861504555, 0.03090466745197773, 0.03090435452759266, 0.03090500831604004, 0.030911726877093315, 0.030912578105926514, 0.030909784138202667, 0.030908046290278435, 0.030909139662981033, 0.030912023037672043, 0.030911410227417946, 0.030908241868019104, 0.03090452402830124, 0.03090278059244156, 0.030903344973921776, 0.03090164251625538, 0.03089802712202072, 0.030900858342647552, 0.030901696532964706, 0.030900247395038605, 0.030905304476618767, 0.030901513993740082, 0.030894609168171883, 0.030893215909600258, 0.030892200767993927, 0.030891580507159233, 0.030888471752405167, 0.03089282102882862, 0.030896775424480438, 0.030901294201612473, 0.03089793212711811, 0.030902674421668053, 0.030903510749340057, 0.03090580180287361, 0.030892739072442055, 0.030888142064213753, 0.030888661742210388, 0.030894972383975983, 0.030890509486198425, 0.030890708789229393, 0.030891042202711105, 0.030890589579939842, 0.03089117258787155, 0.030892228707671165, 0.030896535143256187, 0.030894026160240173, 0.03089309297502041, 0.030894499272108078, 0.03090183436870575, 0.030904436483979225, 0.030902622267603874, 0.030900873243808746, 0.030901378020644188, 0.030897745862603188, 0.030899569392204285, 0.030899029225111008, 0.030898207798600197, 0.030896609649062157, 0.030894966796040535, 0.030890151858329773, 0.030891943722963333, 0.030891690403223038, 0.030901985242962837, 0.030905338004231453, 0.030901752412319183, 0.030902359634637833, 0.030904019251465797, 0.030902191996574402, 0.030898787081241608, 0.03089834190905094, 0.030899930745363235, 0.030897116288542747, 0.030895285308361053, 0.030890045687556267, 0.0308856088668108, 0.03088602051138878, 0.030880892649292946, 0.03087552636861801, 0.030882088467478752, 0.030886810272932053, 0.030890237540006638, 0.03088681772351265, 0.030883636325597763, 0.03088466450572014, 0.030878834426403046, 0.030879482626914978, 0.03088044375181198, 0.03088022954761982, 0.030883513391017914, 0.0308845154941082, 0.030886191874742508, 0.030889933928847313, 0.03088805451989174, 0.030887797474861145, 0.03089277073740959, 0.03089469112455845, 0.030890805646777153, 0.030897097662091255, 0.030897466465830803, 0.03089657612144947, 0.03089044615626335, 0.03089030086994171, 0.030888959765434265, 0.03089097887277603, 0.03089957684278488, 0.030904894694685936, 0.030900271609425545, 0.03089771792292595, 0.03089698776602745, 0.030899424105882645, 0.030896030366420746, 0.030898289754986763, 0.030891263857483864, 0.03088359907269478, 0.0308813638985157, 0.03088100627064705, 0.0308828204870224, 0.03088200092315674, 0.030881866812705994, 0.030885064974427223, 0.030888840556144714, 0.030887415632605553, 0.030887797474861145, 0.03088539093732834, 0.030879177153110504, 0.0308785792440176, 0.03087608516216278, 0.030877694487571716, 0.03087816946208477, 0.030876489356160164, 0.030877238139510155, 0.03087249957025051, 0.03087341971695423, 0.030872903764247894, 0.030869558453559875, 0.03088071383535862, 0.030886327847838402, 0.030890820547938347, 0.030890198424458504, 0.030889704823493958, 0.030888184905052185, 0.03088482655584812, 0.03088684380054474, 0.030882615596055984, 0.03088492900133133, 0.03087753988802433, 0.03087497688829899, 0.030871937051415443, 0.03086896426975727, 0.030869711190462112, 0.030871260911226273, 0.03086366131901741, 0.03086770512163639, 0.030871141701936722, 0.03087419457733631, 0.030877387151122093, 0.030874652788043022, 0.030870456248521805, 0.030868221074342728, 0.03086625598371029, 0.030867094174027443, 0.030864998698234558, 0.030866343528032303, 0.030869511887431145, 0.03086794912815094, 0.030874235555529594, 0.030875682830810547, 0.030878784134984016, 0.030878644436597824, 0.03087948076426983, 0.03087913990020752, 0.030875297263264656, 0.030873052775859833, 0.03086991049349308, 0.030870232731103897, 0.03086843527853489, 0.030864588916301727, 0.030866147950291634, 0.03086213581264019, 0.030857373028993607, 0.030862100422382355, 0.030864156782627106, 0.030859308317303658, 0.030858535319566727, 0.030860617756843567, 0.03085707686841488, 0.030854836106300354, 0.030854977667331696, 0.030850203707814217, 0.03084798902273178, 0.030847713351249695, 0.03084528259932995, 0.030843190848827362, 0.030845409259200096, 0.03084477409720421, 0.030847154557704926, 0.030852438881993294, 0.030851498246192932, 0.030847880989313126, 0.030844157561659813, 0.03084576316177845, 0.030841762199997902, 0.03084024041891098, 0.03084314800798893, 0.030848903581500053, 0.03084603324532509, 0.030842697247862816, 0.030839502811431885, 0.03084099106490612, 0.030843300744891167, 0.030848639085888863, 0.030845755711197853, 0.030842874199151993, 0.030842408537864685, 0.03084704466164112, 0.03084845095872879, 0.030848361551761627, 0.030848855152726173, 0.030847778543829918, 0.030840234830975533, 0.030838659033179283, 0.03084041178226471, 0.030841903761029243, 0.030837133526802063, 0.030840251594781876, 0.03083418309688568, 0.03083626739680767, 0.03083636611700058, 0.030842207372188568, 0.030841035768389702, 0.03083466738462448, 0.030833475291728973, 0.0308365561068058, 0.030840756371617317, 0.030834998935461044, 0.030830316245555878, 0.0308278426527977, 0.030823279172182083, 0.030825570225715637, 0.030825719237327576, 0.030828183516860008, 0.0308365598320961, 0.03083866834640503, 0.03084181249141693, 0.03084370121359825, 0.030841205269098282, 0.030832046642899513, 0.030829768627882004, 0.030819788575172424, 0.030816828832030296, 0.030823731794953346, 0.030825290828943253, 0.030831508338451385, 0.030836105346679688, 0.0308326855301857, 0.030833033844828606, 0.03082728199660778, 0.03082757629454136, 0.030827930197119713, 0.03083067201077938, 0.03083522617816925, 0.03084256872534752, 0.030838225036859512, 0.03083682619035244, 0.030835160985589027, 0.03083132766187191, 0.03083365596830845, 0.030834736302495003, 0.030832288786768913, 0.03083311766386032, 0.03082982823252678, 0.030828068032860756, 0.03082394413650036, 0.03082621842622757, 0.03082253783941269, 0.03081551566720009, 0.030818233266472816, 0.030822694301605225, 0.030823903158307076, 0.03082088939845562, 0.030821384862065315, 0.030818277969956398, 0.030821213498711586, 0.030819540843367577, 0.03081846982240677, 0.0308168176561594, 0.030813846737146378, 0.03081597574055195, 0.030813997611403465, 0.03081396594643593, 0.03081010840833187, 0.030812935903668404, 0.0308125838637352, 0.030806533992290497, 0.030802657827734947, 0.03080270066857338, 0.030807113274931908, 0.03080945461988449, 0.030808446928858757, 0.030806193128228188, 0.030802665278315544, 0.03080356866121292, 0.030803490430116653, 0.030802268534898758, 0.030802523717284203, 0.030805880203843117, 0.030801961198449135, 0.030804244801402092, 0.030807100236415863, 0.030805625021457672, 0.03080587089061737, 0.030804600566625595, 0.030802439898252487, 0.030803963541984558, 0.030809616670012474, 0.030808817595243454, 0.030809972435235977, 0.030815489590168, 0.030816907063126564, 0.030813677236437798, 0.03080926649272442, 0.030810248106718063, 0.030808908864855766, 0.03080723248422146, 0.030804703012108803, 0.030803516507148743, 0.03080587647855282, 0.030807148665189743, 0.030802758410573006, 0.03080146387219429, 0.030799804255366325, 0.030799083411693573, 0.030801303684711456, 0.030797595158219337, 0.030794043093919754, 0.03079664707183838, 0.03080012835562229, 0.030800197273492813, 0.03080124780535698, 0.030800966545939445]\n",
      "[0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.019999999552965164, 0.11999999731779099, 0.1599999964237213, 0.019999999552965164, 0.019999999552965164, 0.019999999552965164, 0.019999999552965164, 0.03999999910593033, 0.03999999910593033, 0.03999999910593033, 0.05999999865889549, 0.05999999865889549, 0.3199999928474426, 0.1599999964237213, 0.20000000298023224, 0.36000001430511475, 0.25999999046325684, 0.23999999463558197, 0.30000001192092896, 0.3199999928474426, 0.25999999046325684, 0.20000000298023224, 0.2800000011920929, 0.2800000011920929, 0.2800000011920929, 0.30000001192092896, 0.2800000011920929, 0.3199999928474426, 0.3199999928474426, 0.36000001430511475, 0.36000001430511475, 0.2199999988079071, 0.36000001430511475, 0.2800000011920929, 0.36000001430511475, 0.2800000011920929, 0.30000001192092896, 0.25999999046325684, 0.20000000298023224, 0.18000000715255737, 0.2800000011920929, 0.20000000298023224, 0.25999999046325684, 0.25999999046325684, 0.18000000715255737, 0.23999999463558197, 0.18000000715255737, 0.23999999463558197, 0.18000000715255737, 0.18000000715255737, 0.18000000715255737, 0.18000000715255737, 0.18000000715255737, 0.20000000298023224, 0.20000000298023224, 0.18000000715255737, 0.20000000298023224, 0.18000000715255737, 0.2199999988079071, 0.20000000298023224, 0.18000000715255737, 0.20000000298023224, 0.20000000298023224, 0.20000000298023224, 0.2199999988079071, 0.23999999463558197, 0.23999999463558197, 0.23999999463558197, 0.23999999463558197, 0.2199999988079071, 0.20000000298023224, 0.2199999988079071, 0.2199999988079071, 0.23999999463558197, 0.23999999463558197, 0.23999999463558197, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.23999999463558197, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.18000000715255737, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.18000000715255737, 0.18000000715255737, 0.18000000715255737, 0.18000000715255737, 0.18000000715255737, 0.18000000715255737, 0.18000000715255737, 0.18000000715255737, 0.18000000715255737, 0.18000000715255737, 0.18000000715255737, 0.18000000715255737, 0.18000000715255737, 0.18000000715255737, 0.18000000715255737, 0.18000000715255737, 0.18000000715255737, 0.18000000715255737, 0.18000000715255737, 0.18000000715255737, 0.18000000715255737, 0.18000000715255737, 0.18000000715255737, 0.18000000715255737, 0.18000000715255737, 0.18000000715255737, 0.18000000715255737, 0.18000000715255737, 0.18000000715255737, 0.18000000715255737, 0.18000000715255737, 0.18000000715255737, 0.18000000715255737, 0.18000000715255737, 0.18000000715255737, 0.1599999964237213, 0.18000000715255737, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.14000000059604645, 0.14000000059604645, 0.14000000059604645, 0.14000000059604645, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.14000000059604645, 0.14000000059604645, 0.14000000059604645, 0.14000000059604645, 0.14000000059604645, 0.14000000059604645, 0.14000000059604645, 0.14000000059604645, 0.14000000059604645, 0.14000000059604645, 0.14000000059604645, 0.14000000059604645, 0.1599999964237213, 0.1599999964237213, 0.14000000059604645, 0.1599999964237213, 0.14000000059604645, 0.14000000059604645, 0.1599999964237213, 0.14000000059604645, 0.1599999964237213, 0.11999999731779099, 0.11999999731779099, 0.14000000059604645, 0.11999999731779099, 0.14000000059604645, 0.11999999731779099, 0.14000000059604645, 0.14000000059604645, 0.1599999964237213, 0.14000000059604645, 0.14000000059604645, 0.11999999731779099, 0.14000000059604645, 0.14000000059604645, 0.11999999731779099, 0.1599999964237213, 0.14000000059604645, 0.11999999731779099, 0.1599999964237213, 0.1599999964237213, 0.20000000298023224, 0.20000000298023224, 0.14000000059604645, 0.23999999463558197, 0.14000000059604645, 0.2199999988079071, 0.20000000298023224, 0.14000000059604645, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.14000000059604645, 0.14000000059604645, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.1599999964237213, 0.2199999988079071, 0.2199999988079071, 0.1599999964237213, 0.1599999964237213, 0.2199999988079071, 0.2199999988079071, 0.1599999964237213, 0.2199999988079071, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.2199999988079071, 0.1599999964237213, 0.2199999988079071, 0.2199999988079071, 0.1599999964237213, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.1599999964237213, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.1599999964237213, 0.2199999988079071, 0.2199999988079071, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.1599999964237213, 0.2199999988079071, 0.1599999964237213, 0.2199999988079071, 0.1599999964237213, 0.1599999964237213, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.1599999964237213, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.1599999964237213, 0.2199999988079071, 0.23999999463558197, 0.2800000011920929, 0.18000000715255737, 0.2199999988079071, 0.20000000298023224, 0.23999999463558197, 0.2199999988079071, 0.23999999463558197, 0.2199999988079071, 0.2199999988079071, 0.20000000298023224, 0.20000000298023224, 0.20000000298023224, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.23999999463558197, 0.23999999463558197, 0.2199999988079071, 0.23999999463558197, 0.23999999463558197, 0.2199999988079071, 0.23999999463558197, 0.2199999988079071, 0.2199999988079071, 0.23999999463558197, 0.2199999988079071, 0.2199999988079071, 0.23999999463558197, 0.23999999463558197, 0.2199999988079071, 0.23999999463558197, 0.23999999463558197, 0.23999999463558197, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.23999999463558197, 0.2199999988079071, 0.23999999463558197, 0.23999999463558197, 0.23999999463558197, 0.23999999463558197, 0.2199999988079071, 0.23999999463558197, 0.23999999463558197, 0.2199999988079071, 0.2199999988079071, 0.23999999463558197, 0.2199999988079071, 0.23999999463558197, 0.23999999463558197, 0.23999999463558197, 0.23999999463558197, 0.2199999988079071, 0.2199999988079071, 0.2199999988079071, 0.23999999463558197, 0.2199999988079071, 0.23999999463558197, 0.23999999463558197, 0.25999999046325684, 0.25999999046325684, 0.23999999463558197, 0.25999999046325684, 0.23999999463558197, 0.2199999988079071, 0.23999999463558197, 0.23999999463558197, 0.25999999046325684, 0.25999999046325684, 0.23999999463558197, 0.25999999046325684, 0.2199999988079071, 0.2199999988079071, 0.23999999463558197, 0.2199999988079071, 0.25999999046325684, 0.25999999046325684, 0.23999999463558197, 0.23999999463558197, 0.23999999463558197, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.23999999463558197, 0.23999999463558197, 0.23999999463558197, 0.23999999463558197, 0.2199999988079071, 0.23999999463558197, 0.2199999988079071, 0.23999999463558197, 0.23999999463558197, 0.23999999463558197, 0.23999999463558197, 0.23999999463558197, 0.23999999463558197, 0.23999999463558197, 0.23999999463558197, 0.23999999463558197, 0.2199999988079071, 0.23999999463558197, 0.23999999463558197, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.23999999463558197, 0.25999999046325684, 0.25999999046325684, 0.23999999463558197, 0.25999999046325684, 0.2199999988079071, 0.2199999988079071, 0.23999999463558197, 0.23999999463558197, 0.2199999988079071, 0.2199999988079071, 0.23999999463558197, 0.25999999046325684, 0.2199999988079071, 0.23999999463558197, 0.23999999463558197, 0.23999999463558197, 0.25999999046325684, 0.23999999463558197, 0.23999999463558197, 0.25999999046325684, 0.23999999463558197, 0.23999999463558197, 0.23999999463558197, 0.25999999046325684, 0.23999999463558197, 0.2199999988079071, 0.25999999046325684, 0.23999999463558197, 0.25999999046325684, 0.23999999463558197, 0.23999999463558197, 0.25999999046325684, 0.25999999046325684, 0.23999999463558197, 0.25999999046325684, 0.25999999046325684, 0.23999999463558197, 0.23999999463558197, 0.25999999046325684, 0.23999999463558197, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.23999999463558197, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.23999999463558197, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.30000001192092896, 0.25999999046325684, 0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.30000001192092896, 0.25999999046325684, 0.30000001192092896, 0.30000001192092896, 0.25999999046325684, 0.30000001192092896, 0.30000001192092896, 0.25999999046325684, 0.25999999046325684, 0.30000001192092896, 0.30000001192092896, 0.25999999046325684, 0.25999999046325684, 0.30000001192092896, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.25999999046325684, 0.25999999046325684, 0.30000001192092896, 0.30000001192092896, 0.25999999046325684, 0.30000001192092896, 0.30000001192092896, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.30000001192092896, 0.25999999046325684, 0.30000001192092896, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.30000001192092896, 0.25999999046325684, 0.25999999046325684, 0.30000001192092896, 0.30000001192092896, 0.25999999046325684, 0.30000001192092896, 0.25999999046325684, 0.25999999046325684, 0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.25999999046325684, 0.25999999046325684, 0.2800000011920929, 0.30000001192092896, 0.25999999046325684, 0.30000001192092896, 0.2800000011920929, 0.30000001192092896, 0.2800000011920929, 0.25999999046325684, 0.3199999928474426, 0.3199999928474426, 0.25999999046325684, 0.2800000011920929, 0.25999999046325684, 0.3199999928474426, 0.25999999046325684, 0.2800000011920929, 0.3199999928474426, 0.25999999046325684, 0.3199999928474426, 0.2800000011920929, 0.3199999928474426, 0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.25999999046325684, 0.30000001192092896, 0.3199999928474426, 0.3199999928474426, 0.2800000011920929, 0.30000001192092896, 0.2800000011920929, 0.30000001192092896, 0.3199999928474426, 0.30000001192092896, 0.3199999928474426, 0.3199999928474426, 0.25999999046325684, 0.30000001192092896, 0.3199999928474426, 0.25999999046325684, 0.3199999928474426, 0.25999999046325684, 0.3199999928474426, 0.25999999046325684, 0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.3199999928474426, 0.25999999046325684, 0.2800000011920929, 0.3199999928474426, 0.3199999928474426, 0.25999999046325684, 0.3199999928474426, 0.30000001192092896, 0.3199999928474426, 0.3199999928474426, 0.2800000011920929, 0.25999999046325684, 0.25999999046325684, 0.2800000011920929, 0.2800000011920929, 0.3199999928474426, 0.2800000011920929, 0.3400000035762787, 0.3400000035762787, 0.3400000035762787, 0.2800000011920929, 0.3199999928474426, 0.25999999046325684, 0.3199999928474426, 0.2800000011920929, 0.2800000011920929, 0.30000001192092896, 0.30000001192092896, 0.2800000011920929, 0.25999999046325684, 0.25999999046325684, 0.25999999046325684, 0.3400000035762787, 0.3400000035762787, 0.3199999928474426, 0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.2800000011920929, 0.3199999928474426, 0.2800000011920929, 0.25999999046325684, 0.30000001192092896, 0.2800000011920929, 0.3199999928474426, 0.2800000011920929, 0.30000001192092896, 0.2800000011920929, 0.2800000011920929, 0.3199999928474426, 0.2800000011920929, 0.3400000035762787, 0.2800000011920929, 0.30000001192092896, 0.2800000011920929, 0.25999999046325684, 0.3400000035762787, 0.3199999928474426, 0.3400000035762787, 0.3199999928474426, 0.2800000011920929, 0.30000001192092896, 0.3400000035762787, 0.3400000035762787, 0.3400000035762787, 0.3199999928474426, 0.3199999928474426, 0.2800000011920929, 0.3400000035762787, 0.3199999928474426, 0.3400000035762787, 0.3400000035762787, 0.3400000035762787, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.30000001192092896, 0.3199999928474426, 0.30000001192092896, 0.30000001192092896, 0.3400000035762787, 0.3400000035762787, 0.3199999928474426, 0.3400000035762787, 0.3400000035762787, 0.3199999928474426, 0.3199999928474426, 0.30000001192092896, 0.30000001192092896, 0.3400000035762787, 0.3400000035762787, 0.3199999928474426, 0.30000001192092896, 0.30000001192092896, 0.3400000035762787, 0.3199999928474426, 0.30000001192092896, 0.3400000035762787, 0.30000001192092896, 0.3199999928474426, 0.3199999928474426, 0.30000001192092896, 0.30000001192092896, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3400000035762787, 0.30000001192092896, 0.3199999928474426, 0.30000001192092896, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.30000001192092896, 0.30000001192092896, 0.3199999928474426, 0.30000001192092896, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3400000035762787, 0.3400000035762787, 0.3199999928474426, 0.3199999928474426, 0.3400000035762787, 0.3400000035762787, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3400000035762787, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3400000035762787, 0.3400000035762787, 0.3199999928474426, 0.3400000035762787, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3400000035762787, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3400000035762787, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3400000035762787, 0.3400000035762787, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3400000035762787, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3400000035762787, 0.3199999928474426, 0.3400000035762787, 0.3400000035762787, 0.3400000035762787, 0.3400000035762787, 0.3400000035762787, 0.3199999928474426, 0.3400000035762787, 0.3199999928474426, 0.3400000035762787, 0.3400000035762787, 0.3400000035762787, 0.3400000035762787, 0.3199999928474426, 0.3400000035762787, 0.3400000035762787, 0.3400000035762787, 0.3199999928474426, 0.3400000035762787, 0.3199999928474426, 0.3400000035762787, 0.3400000035762787, 0.3400000035762787, 0.3400000035762787, 0.3400000035762787, 0.3400000035762787, 0.3400000035762787, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3400000035762787, 0.3400000035762787, 0.3400000035762787, 0.3199999928474426, 0.3400000035762787, 0.3400000035762787, 0.3400000035762787, 0.3400000035762787, 0.3400000035762787, 0.3400000035762787, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3400000035762787, 0.3400000035762787, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3400000035762787, 0.3400000035762787, 0.3199999928474426, 0.3199999928474426, 0.3400000035762787, 0.3199999928474426, 0.3400000035762787, 0.3400000035762787, 0.3400000035762787, 0.3400000035762787, 0.3199999928474426, 0.3199999928474426, 0.3400000035762787, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3400000035762787, 0.3400000035762787, 0.3400000035762787, 0.3400000035762787, 0.3400000035762787, 0.3199999928474426, 0.3400000035762787, 0.3400000035762787, 0.3400000035762787, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3400000035762787, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3400000035762787, 0.3400000035762787, 0.3400000035762787, 0.3199999928474426, 0.3400000035762787, 0.3199999928474426, 0.3400000035762787, 0.3400000035762787, 0.3199999928474426, 0.3400000035762787, 0.3199999928474426, 0.3400000035762787, 0.3199999928474426, 0.3400000035762787, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426, 0.3400000035762787, 0.3400000035762787, 0.3199999928474426, 0.3199999928474426, 0.3400000035762787, 0.3199999928474426, 0.3199999928474426, 0.3400000035762787, 0.3199999928474426, 0.3199999928474426, 0.3400000035762787, 0.3400000035762787, 0.3199999928474426, 0.3400000035762787, 0.3199999928474426, 0.3199999928474426, 0.3199999928474426]\n"
     ]
    }
   ],
   "source": [
    "print(history.history['loss'])\n",
    "print(history.history['val_loss'])\n",
    "print(history.history['val_accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "Here, we evaluate the neural network with the test data.\n",
    "\n",
    "This block stays the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels2 = []\n",
    "test_samples2 = []\n",
    "index = 0\n",
    "\n",
    "for t in test_labels:\n",
    "    contains = False\n",
    "    for tt in train_labels:\n",
    "        if np.array_equal(t, tt):\n",
    "            contains = True\n",
    "            break\n",
    "    if not contains:\n",
    "        test_labels2.append(t)\n",
    "        test_samples2.append(test_samples[index])\n",
    "    index += 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "649947\n",
      "195679\n"
     ]
    }
   ],
   "source": [
    "print(len(test_labels))\n",
    "print(len(test_labels2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 11s 2ms/step - loss: 0.0511 - accuracy: 0.3570 - binary_accuracy: 0.9417\n",
      "Test loss: 0.05113872513175011\n",
      "Test accuracy: 0.35704296827316284\n"
     ]
    }
   ],
   "source": [
    "results = neural_network.evaluate(test_samples, test_labels, batch_size=batch_size)\n",
    "print(\"Test loss: {}\".format(results[0]))\n",
    "print(\"Test accuracy: {}\".format(results[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1957/1957 [==============================] - 4s 2ms/step - loss: 0.1604 - accuracy: 0.3218 - binary_accuracy: 0.8174\n",
      "Test loss: 0.16042689979076385\n",
      "Test accuracy: 0.3218485414981842\n"
     ]
    }
   ],
   "source": [
    "results = neural_network.evaluate(np.array(test_samples2), np.array(test_labels2), batch_size=batch_size)\n",
    "print(\"Test loss: {}\".format(results[0]))\n",
    "print(\"Test accuracy: {}\".format(results[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plaintext Recovery in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = [predict_sample(neural_network, test_samples2[i]) for i in range(size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [correct_and_metrics((predictions[i], test_labels2[i])) for i in range(size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct bytes: 431\n",
      "Byte accuracy: 0.2155\n",
      "Correct predictions: 77\n",
      "Prediction accuracy: 0.077\n"
     ]
    }
   ],
   "source": [
    "correct_bytes = 0\n",
    "correct_predictions = 0\n",
    "for m in metrics:\n",
    "    correct_bytes += m[0]\n",
    "    correct_predictions += m[1]\n",
    "                             \n",
    "print(\"Correct bytes: {}\".format(correct_bytes))\n",
    "print(\"Byte accuracy: {}\".format(correct_bytes/(2*size)))\n",
    "print(\"Correct predictions: {}\".format(correct_predictions))\n",
    "print(\"Prediction accuracy: {}\".format(correct_predictions/size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct-> do | dm <-actual\n",
      "correct-> no | no <-actual\n",
      "correct-> 33 | nf <-actual\n",
      "correct-> :3 | rg <-actual\n",
      "correct-> o  | n  <-actual\n",
      "correct-> pa |  e <-actual\n",
      "correct-> (l | \n",
      "q <-actual\n",
      "correct-> o, | ni <-actual\n",
      "correct-> e, | cl <-actual\n",
      "correct-> )  | 9( <-actual\n",
      "correct-> \n",
      "t | Be <-actual\n",
      "correct-> y  | x` <-actual\n",
      "correct-> ow | Oe <-actual\n",
      "correct-> a  | m  <-actual\n",
      "correct-> pr |  w <-actual\n",
      "correct-> op | n  <-actual\n",
      "correct-> ee | ee <-actual\n",
      "correct-> em | um <-actual\n",
      "correct-> \n",
      "3 | he <-actual\n",
      "correct-> 4: | v( <-actual\n",
      "correct-> wo | go <-actual\n",
      "correct-> rd | ri <-actual\n",
      "correct-> LO | Go <-actual\n",
      "correct-> RD | ~` <-actual\n",
      "correct-> to | dn <-actual\n",
      "correct-> e, | cl <-actual\n",
      "correct-> g, | gl <-actual\n",
      "correct->  3 | \n",
      "a <-actual\n",
      "correct-> 4: | v( <-actual\n",
      "correct-> So | cj <-actual\n",
      "correct-> ,\n",
      " | ra <-actual\n",
      "correct-> pr |  w <-actual\n",
      "correct-> op | n  <-actual\n",
      "correct-> sy |  <-actual\n",
      "correct-> ph |  i <-actual\n",
      "correct-> Is | ip <-actual\n",
      "correct-> ra | rm <-actual\n",
      "correct-> el | un <-actual\n",
      "correct-> pr |  w <-actual\n",
      "correct-> op | n  <-actual\n",
      "correct-> sy |  <-actual\n",
      "correct-> y  | x` <-actual\n",
      "correct-> to | dn <-actual\n",
      "correct-> m, | on <-actual\n",
      "correct-> hu | je <-actual\n",
      "correct-> Lo | on <-actual\n",
      "correct-> rd | ri <-actual\n",
      "correct-> OD | g` <-actual\n",
      "correct-> o  | n  <-actual\n",
      "correct-> sh | c` <-actual\n",
      "correct-> rd | ri <-actual\n",
      "correct-> s; | ob <-actual\n",
      "correct->  W | bg <-actual\n",
      "correct-> oe | Oe <-actual\n",
      "correct-> to | dn <-actual\n",
      "correct-> ph |  i <-actual\n",
      "correct-> f\n",
      " | G* <-actual\n",
      "correct-> Is | ip <-actual\n",
      "correct-> ra | rm <-actual\n",
      "correct-> el | un <-actual\n",
      "correct-> do | dm <-actual\n",
      "correct-> ee | ee <-actual\n",
      "correct-> em | um <-actual\n",
      "correct-> lv | :a <-actual\n",
      "correct-> !  | (  <-actual\n",
      "correct-> sh | c` <-actual\n",
      "correct-> ld | mt <-actual\n",
      "correct->  n | `m <-actual\n",
      "correct-> ot | mt <-actual\n",
      "correct-> ph |  i <-actual\n",
      "correct-> ee | ee <-actual\n",
      "correct-> fl | fi <-actual\n",
      "correct-> oc | oc <-actual\n",
      "correct-> ks | oc <-actual\n",
      "correct-> ?  | .  <-actual\n",
      "correct->  3 | \n",
      "a <-actual\n",
      "correct-> 4: | v( <-actual\n",
      "correct-> Ye | se <-actual\n",
      "correct-> ye | yd <-actual\n",
      "correct-> lo | oo <-actual\n",
      "correct-> yo | if <-actual\n",
      "correct-> u  | w  <-actual\n",
      "correct-> l, | kl <-actual\n",
      "correct->  y | 0` <-actual\n",
      "correct-> ki | me <-actual\n",
      "correct-> \n",
      "t | Be <-actual\n",
      "correct-> bu | aq <-actual\n",
      "correct-> ye | yd <-actual\n",
      "correct-> ee | ee <-actual\n",
      "correct-> no | no <-actual\n",
      "correct-> fl | fi <-actual\n",
      "correct-> oc | oc <-actual\n",
      "correct-> k. | in <-actual\n",
      "correct-> 34 | no <-actual\n",
      "correct-> :4 | ru <-actual\n",
      "correct->  T | r$ <-actual\n",
      "correct-> is | is <-actual\n",
      "correct->  y | 0` <-actual\n",
      "correct-> no | no <-actual\n",
      "correct->  y | 0` <-actual\n",
      "correct-> \n",
      "t | Be <-actual\n",
      "correct-> ck | a` <-actual\n",
      "correct->  y | 0` <-actual\n",
      "correct-> br | sr <-actual\n",
      "correct-> ok | ob <-actual\n",
      "correct-> ,\n",
      " | ra <-actual\n",
      "correct->  y | 0` <-actual\n",
      "correct-> br | sr <-actual\n",
      "correct-> ag | ag <-actual\n",
      "correct-> ri | ri <-actual\n",
      "correct-> aw | ce <-actual\n",
      "correct-> \n",
      "y | f` <-actual\n",
      "correct-> so | cj <-actual\n",
      "correct-> ug | ec <-actual\n",
      "correct-> lo | oo <-actual\n",
      "correct-> bu | aq <-actual\n",
      "correct-> cr | qr <-actual\n",
      "correct-> ue | uc <-actual\n",
      "correct-> lt | hd <-actual\n",
      "correct-> y  | x` <-actual\n",
      "correct->  y | 0` <-actual\n",
      "correct-> ru | p` <-actual\n",
      "correct-> em | um <-actual\n",
      "correct-> \n",
      "3 | he <-actual\n",
      "correct-> 4: | v( <-actual\n",
      "correct-> 5  | 3  <-actual\n",
      "correct-> ey | di <-actual\n",
      "correct-> sc | sc <-actual\n",
      "correct-> ec | ek <-actual\n",
      "correct-> au | cu <-actual\n",
      "correct-> no | no <-actual\n",
      "correct-> ph |  i <-actual\n",
      "correct-> y\n",
      " | :( <-actual\n",
      "correct-> to | dn <-actual\n",
      "correct-> ie | ie <-actual\n",
      "correct-> ld | mt <-actual\n",
      "correct-> y  | x` <-actual\n",
      "correct-> tt | ah <-actual\n",
      "correct-> \n",
      "3 | he <-actual\n",
      "correct-> 4: | v( <-actual\n",
      "correct-> My | zd <-actual\n",
      "correct-> ug | ec <-actual\n",
      "correct-> l  | m  <-actual\n",
      "correct-> ta | de <-actual\n",
      "correct-> ev | ea <-actual\n",
      "correct-> y  | x` <-actual\n",
      "correct-> \n",
      "h | jm <-actual\n",
      "correct-> il | in <-actual\n",
      "correct-> l: | Nn <-actual\n",
      "correct->  y | 0` <-actual\n",
      "correct-> my | li <-actual\n",
      "correct-> lo | oo <-actual\n",
      "correct-> ck | a` <-actual\n",
      "correct-> tt | ah <-actual\n",
      "correct-> l  | m  <-actual\n",
      "correct-> h, | `m <-actual\n",
      "correct-> \n",
      "n | hd <-actual\n",
      "correct-> ek | e` <-actual\n",
      "correct-> ft | it <-actual\n",
      "correct-> m. | gn <-actual\n",
      "correct-> 34 | no <-actual\n",
      "correct-> :7 | z. <-actual\n",
      "correct->  T | r$ <-actual\n",
      "correct-> ye | yd <-actual\n",
      "correct-> ph |  i <-actual\n",
      "correct-> OR | uh <-actual\n",
      "correct-> D; | nl <-actual\n",
      "correct->  3 | \n",
      "a <-actual\n",
      "correct-> 4: | v( <-actual\n",
      "correct-> As | ap <-actual\n",
      "correct->  I | 0p <-actual\n",
      "correct-> \n",
      "l | h. <-actual\n",
      "correct-> e, | cl <-actual\n",
      "correct-> GO | nn <-actual\n",
      "correct-> D, | r  <-actual\n",
      "correct-> ur | eg <-actual\n",
      "correct-> el | un <-actual\n",
      "correct-> y  | x` <-actual\n",
      "correct-> us | fc <-actual\n",
      "correct-> my | li <-actual\n",
      "correct-> lo | oo <-actual\n",
      "correct-> ck | a` <-actual\n",
      "correct-> ec | ek <-actual\n",
      "correct-> a  | m  <-actual\n",
      "correct-> pr |  w <-actual\n",
      "correct-> ey | di <-actual\n",
      "correct-> d\n",
      " | J( <-actual\n",
      "correct-> my | li <-actual\n",
      "correct-> lo | oo <-actual\n",
      "correct-> ck | a` <-actual\n",
      "correct-> ec | ek <-actual\n",
      "correct-> o  | n  <-actual\n",
      "correct-> ev | ea <-actual\n",
      "correct-> y  | x` <-actual\n",
      "correct-> ie | ie <-actual\n",
      "correct-> ld | mt <-actual\n",
      "correct-> us | fc <-actual\n",
      "correct-> no | no <-actual\n",
      "correct-> \n",
      "s | oo <-actual\n",
      "correct-> ph |  i <-actual\n",
      "correct->  n | `m <-actual\n",
      "correct-> ei | eh <-actual\n",
      "correct-> y  | x` <-actual\n",
      "correct-> sh | c` <-actual\n",
      "correct-> rd | ri <-actual\n",
      "correct-> y  | x` <-actual\n",
      "correct-> fl | fi <-actual\n",
      "correct-> oc | oc <-actual\n",
      "correct-> k, | in <-actual\n",
      "correct-> ut | wr <-actual\n",
      "correct-> \n",
      "s | oo <-actual\n",
      "correct-> ph |  i <-actual\n",
      "correct-> ms | is <-actual\n",
      "correct-> el | un <-actual\n",
      "correct->  n | `m <-actual\n",
      "correct-> ot | mt <-actual\n",
      "correct-> y  | x` <-actual\n",
      "correct-> fl | fi <-actual\n",
      "correct-> oc | oc <-actual\n",
      "correct-> k; | a` <-actual\n",
      "correct->  3 | \n",
      "a <-actual\n",
      "correct-> 4: | v( <-actual\n",
      "correct-> 9  | 8  <-actual\n",
      "correct-> ef | u` <-actual\n",
      "correct-> e, | cl <-actual\n",
      "correct->  O |  G <-actual\n",
      "correct->  y | 0` <-actual\n",
      "correct-> sh | c` <-actual\n",
      "correct-> rd | ri <-actual\n",
      "correct-> wo | go <-actual\n",
      "correct-> rd | ri <-actual\n",
      "correct-> LO | Go <-actual\n",
      "correct-> RD | ~` <-actual\n",
      "correct-> 34 | no <-actual\n",
      "correct-> :1 | r2 <-actual\n",
      "correct-> 0  | 80 <-actual\n",
      "correct-> us | fc <-actual\n",
      "correct-> GO | nn <-actual\n",
      "correct-> D; | nl <-actual\n",
      "correct-> \n",
      "B | ma <-actual\n",
      "correct-> eh | u` <-actual\n",
      "correct-> ol | ol <-actual\n",
      "correct->  I | 0p <-actual\n",
      "correct-> ag | ag <-actual\n",
      "correct-> ns | we <-actual\n",
      "correct-> sh | c` <-actual\n",
      "correct-> rd | ri <-actual\n",
      "correct-> s; | ob <-actual\n",
      "correct->  I | 0p <-actual\n",
      "correct-> il | in <-actual\n",
      "correct-> l  | m  <-actual\n",
      "correct-> qu | a` <-actual\n",
      "correct-> my | li <-actual\n",
      "correct-> lo | oo <-actual\n",
      "correct-> ck | a` <-actual\n",
      "correct-> t\n",
      " | n0 <-actual\n",
      "correct-> ei | eh <-actual\n",
      "correct-> us | fc <-actual\n",
      "correct-> em | um <-actual\n",
      "correct-> o  | n  <-actual\n",
      "correct-> ee | ee <-actual\n",
      "correct-> lo | oo <-actual\n",
      "correct-> ck | a` <-actual\n",
      "correct-> r\n",
      " | x( <-actual\n",
      "correct-> sh | c` <-actual\n",
      "correct-> l  | m  <-actual\n",
      "correct-> sh | c` <-actual\n",
      "correct-> rd | ri <-actual\n",
      "correct-> fe | ne <-actual\n",
      "correct-> ms | is <-actual\n",
      "correct-> el | un <-actual\n",
      "correct-> y  | x` <-actual\n",
      "correct-> I  | )f <-actual\n",
      "correct-> el | un <-actual\n",
      "correct-> y\n",
      " | :( <-actual\n",
      "correct-> fl | fi <-actual\n",
      "correct-> oc | oc <-actual\n",
      "correct-> y  | x` <-actual\n",
      "correct-> y  | x` <-actual\n",
      "correct-> no | no <-actual\n",
      "correct-> em | um <-actual\n",
      "correct-> \n",
      "3 | he <-actual\n",
      "correct-> 4: | v( <-actual\n",
      "correct-> 11 | s <-actual\n",
      "correct-> hu | je <-actual\n",
      "correct-> Lo | on <-actual\n",
      "correct-> rd | ri <-actual\n",
      "correct-> OD | g` <-actual\n",
      "correct-> Be | 2i <-actual\n",
      "correct-> ho | jw <-actual\n",
      "correct-> ld | mt <-actual\n",
      "correct-> I, | \u001a* <-actual\n",
      "correct-> I, | \u001a* <-actual\n",
      "correct-> il | in <-actual\n",
      "correct-> l  | m  <-actual\n",
      "correct-> rc | rg <-actual\n",
      "correct-> h\n",
      " | \n",
      "\n",
      " <-actual\n",
      "correct-> my | li <-actual\n",
      "correct-> ek | e` <-actual\n",
      "correct-> 34 | no <-actual\n",
      "correct-> :1 | r2 <-actual\n",
      "correct-> As | ap <-actual\n",
      "correct-> ph |  i <-actual\n",
      "correct-> ek | e` <-actual\n",
      "correct-> fl | fi <-actual\n",
      "correct-> oc | oc <-actual\n",
      "correct-> g\n",
      " | n* <-actual\n",
      "correct-> sh | c` <-actual\n",
      "correct-> ee | ee <-actual\n",
      "correct-> p  | 8  <-actual\n",
      "correct-> tt | ah <-actual\n",
      "correct-> so | cj <-actual\n",
      "correct-> il | in <-actual\n",
      "correct-> l  | m  <-actual\n",
      "correct-> I  | )f <-actual\n",
      "correct-> ek | e` <-actual\n",
      "correct-> ut | wr <-actual\n",
      "correct-> y  | x` <-actual\n",
      "correct-> sh | c` <-actual\n",
      "correct-> ee | ee <-actual\n",
      "correct-> p, | y& <-actual\n",
      "correct-> il | in <-actual\n",
      "correct-> l\n",
      " | rj <-actual\n",
      "correct-> em | um <-actual\n",
      "correct-> ut | wr <-actual\n",
      "correct-> l  | m  <-actual\n",
      "correct-> pl | `f <-actual\n",
      "correct-> y  | x` <-actual\n",
      "correct-> ee | ee <-actual\n",
      "correct-> sc | sc <-actual\n",
      "correct-> \n",
      "c | he <-actual\n",
      "correct-> lo | oo <-actual\n",
      "correct-> ud | wl <-actual\n",
      "correct-> y  | x` <-actual\n",
      "correct-> \n",
      "3 | he <-actual\n",
      "correct-> 4: | v( <-actual\n",
      "correct-> 13 | qg <-actual\n",
      "correct->  I | 0p <-actual\n",
      "correct-> il | in <-actual\n",
      "correct-> l  | m  <-actual\n",
      "correct-> br | sr <-actual\n",
      "correct-> em | um <-actual\n",
      "correct-> ut | wr <-actual\n",
      "correct-> pe |  a <-actual\n",
      "correct-> op | n  <-actual\n",
      "correct-> \n",
      "t | Be <-actual\n",
      "correct-> ri | ri <-actual\n",
      "correct-> ri | ri <-actual\n",
      "correct-> to | dn <-actual\n",
      "correct-> wn | go <-actual\n",
      "correct-> ee | ee <-actual\n",
      "correct-> em | um <-actual\n",
      "correct-> \n",
      "u | Nu <-actual\n",
      "correct-> ta | de <-actual\n",
      "correct->  I | 0p <-actual\n",
      "correct-> sr | ag <-actual\n",
      "correct-> ae | cg <-actual\n",
      "correct-> l  | m  <-actual\n",
      "correct-> by | pm <-actual\n",
      "correct->  r |  f <-actual\n",
      "correct-> l  | m  <-actual\n",
      "correct-> bi | ri <-actual\n",
      "correct-> d\n",
      " | J( <-actual\n",
      "correct-> pl | `f <-actual\n",
      "correct-> tr |  c <-actual\n",
      "correct-> 34 | no <-actual\n",
      "correct-> :1 | r2 <-actual\n",
      "correct-> I  | )f <-actual\n",
      "correct-> ee | ee <-actual\n",
      "correct-> em | um <-actual\n",
      "correct-> a  | m  <-actual\n",
      "correct-> go | go <-actual\n",
      "correct->  p |    <-actual\n",
      "correct-> tu |  b <-actual\n",
      "correct-> ta | de <-actual\n",
      "correct->  I | 0p <-actual\n",
      "correct-> sr | ag <-actual\n",
      "correct-> ae | cg <-actual\n",
      "correct-> l  | m  <-actual\n",
      "correct-> sh | c` <-actual\n",
      "correct-> l  | m  <-actual\n",
      "correct-> ei | eh <-actual\n",
      "correct-> ld | mt <-actual\n",
      "correct-> e: | on <-actual\n",
      "correct-> y  | x` <-actual\n",
      "correct-> ld | mt <-actual\n",
      "correct-> ,\n",
      " | ra <-actual\n",
      "correct->  p |    <-actual\n",
      "correct-> tu |  b <-actual\n",
      "correct-> y  | x` <-actual\n",
      "correct-> fe | ne <-actual\n",
      "correct-> ta | de <-actual\n",
      "correct->  I | 0p <-actual\n",
      "correct-> sr | ag <-actual\n",
      "correct-> ae | cg <-actual\n",
      "correct-> l. | kn <-actual\n",
      "correct-> 34 | no <-actual\n",
      "correct-> :1 | r2 <-actual\n",
      "correct-> 5  | 3  <-actual\n",
      "correct-> I  | )f <-actual\n",
      "correct-> ee | ee <-actual\n",
      "correct-> my | li <-actual\n",
      "correct-> lo | oo <-actual\n",
      "correct-> ck | a` <-actual\n",
      "correct-> I  | )f <-actual\n",
      "correct-> au | cu <-actual\n",
      "correct-> to | dn <-actual\n",
      "correct-> ie | ie <-actual\n",
      "correct-> ow | Oe <-actual\n",
      "correct-> n, | ol <-actual\n",
      "correct-> \n",
      "t | Be <-actual\n",
      "correct-> GO | nn <-actual\n",
      "correct-> D. | be <-actual\n",
      "correct-> 34 | no <-actual\n",
      "correct-> :1 | r2 <-actual\n",
      "correct-> I  | )f <-actual\n",
      "correct-> ee | ee <-actual\n",
      "correct-> ri | ri <-actual\n",
      "correct-> dr |  r <-actual\n",
      "correct-> il | in <-actual\n",
      "correct-> l  | m  <-actual\n",
      "correct-> bi | ri <-actual\n",
      "correct-> p  | 8  <-actual\n",
      "correct-> ke | ku <-actual\n",
      "correct-> n, | ol <-actual\n",
      "correct-> il | in <-actual\n",
      "correct-> l\n",
      " | rj <-actual\n",
      "correct-> ck | a` <-actual\n",
      "correct-> bu | aq <-actual\n",
      "correct-> I  | )f <-actual\n",
      "correct-> tr |  c <-actual\n",
      "correct-> oy | ni <-actual\n",
      "correct-> \n",
      "s | oo <-actual\n",
      "correct-> tr |  c <-actual\n",
      "correct-> g; | `  <-actual\n",
      "correct->  I | 0p <-actual\n",
      "correct-> il | in <-actual\n",
      "correct-> l  | m  <-actual\n",
      "correct-> fe | ne <-actual\n",
      "correct->  j |  i <-actual\n",
      "correct-> ud | wl <-actual\n",
      "correct-> gm | sm <-actual\n",
      "correct-> 34 | no <-actual\n",
      "correct-> :1 | r2 <-actual\n",
      "correct->  y | 0` <-actual\n",
      "correct-> O  | ng <-actual\n",
      "correct-> my | li <-actual\n",
      "correct-> lo | oo <-actual\n",
      "correct-> ck | a` <-actual\n",
      "correct-> us | fc <-actual\n",
      "correct-> GO | nn <-actual\n",
      "correct-> D; | nl <-actual\n",
      "correct-> eh | u` <-actual\n",
      "correct-> ol | ol <-actual\n",
      "correct->  I | 0p <-actual\n",
      "correct-> \n",
      "j | h( <-actual\n",
      "correct-> ud | wl <-actual\n",
      "correct-> ge | ge <-actual\n",
      "correct-> tl | dd <-actual\n",
      "correct-> tt | ah <-actual\n",
      "correct-> tw | !c <-actual\n",
      "correct-> ee | ee <-actual\n",
      "correct-> ra | rm <-actual\n",
      "correct-> ms | is <-actual\n",
      "correct-> go | go <-actual\n",
      "correct-> 34 | no <-actual\n",
      "correct-> :1 | r2 <-actual\n",
      "correct-> Se | sa <-actual\n",
      "correct-> em | um <-actual\n",
      "correct-> o  | n  <-actual\n",
      "correct-> yo | if <-actual\n",
      "correct-> u  | w  <-actual\n",
      "correct-> to | dn <-actual\n",
      "correct-> d\n",
      " | J( <-actual\n",
      "correct-> pa |  e <-actual\n",
      "correct-> ur | eg <-actual\n",
      "correct-> e, | cl <-actual\n",
      "correct-> ut | wr <-actual\n",
      "correct->  y | 0` <-actual\n",
      "correct-> mu | ie <-actual\n",
      "correct-> ad | ad <-actual\n",
      "correct-> ow | Oe <-actual\n",
      "correct->  y | 0` <-actual\n",
      "correct-> fe | ne <-actual\n",
      "correct->  r |  f <-actual\n",
      "correct-> ue | uc <-actual\n",
      "correct-> yo | if <-actual\n",
      "correct-> ur | eg <-actual\n",
      "correct-> \n",
      "p | Go <-actual\n",
      "correct-> tu |  b <-actual\n",
      "correct-> s? | no <-actual\n",
      "correct-> o  | n  <-actual\n",
      "correct-> ru | p` <-actual\n",
      "correct-> nk | n` <-actual\n",
      "correct-> ut | wr <-actual\n",
      "correct->  y | 0` <-actual\n",
      "correct-> mu | ie <-actual\n",
      "correct-> l  | m  <-actual\n",
      "correct-> du | !c <-actual\n",
      "correct->  y | 0` <-actual\n",
      "correct-> fe | ne <-actual\n",
      "correct-> ?  | .  <-actual\n",
      "correct->  3 | \n",
      "a <-actual\n",
      "correct-> 4: | v( <-actual\n",
      "correct-> 19 | q. <-actual\n",
      "correct-> my | li <-actual\n",
      "correct-> lo | oo <-actual\n",
      "correct-> ck | a` <-actual\n",
      "correct-> ey | di <-actual\n",
      "correct-> t\n",
      " | n0 <-actual\n",
      "correct-> ye | yd <-actual\n",
      "correct-> tr |  c <-actual\n",
      "correct->  y | 0` <-actual\n",
      "correct-> fe | ne <-actual\n",
      "correct-> ey | di <-actual\n",
      "correct-> ri | ri <-actual\n",
      "correct-> nk | n` <-actual\n",
      "correct-> ye | yd <-actual\n",
      "correct-> \n",
      "h | jm <-actual\n",
      "correct-> ul | en <-actual\n",
      "correct-> yo | if <-actual\n",
      "correct-> ur | eg <-actual\n",
      "correct-> ee | ee <-actual\n",
      "correct-> 34 | no <-actual\n",
      "correct-> :2 | \u0012q <-actual\n",
      "correct-> 0  | 80 <-actual\n",
      "correct-> ef | u` <-actual\n",
      "correct-> us | fc <-actual\n",
      "correct-> GO | nn <-actual\n",
      "correct-> D  | re <-actual\n",
      "correct-> to | dn <-actual\n",
      "correct-> m; | #\" <-actual\n",
      "correct-> eh | u` <-actual\n",
      "correct-> ol | ol <-actual\n",
      "correct->  I | 0p <-actual\n",
      "correct-> ev | ea <-actual\n",
      "correct->  I | 0p <-actual\n",
      "correct-> ,\n",
      " | ra <-actual\n",
      "correct->  j |  i <-actual\n",
      "correct-> ud | wl <-actual\n",
      "correct-> ge | ge <-actual\n",
      "correct-> tl | dd <-actual\n",
      "correct-> tw | !c <-actual\n",
      "correct-> ee | ee <-actual\n",
      "correct-> tl | dd <-actual\n",
      "correct-> e. | cn <-actual\n",
      "correct-> 34 | no <-actual\n",
      "correct-> :2 | \u0012q <-actual\n",
      "correct-> Be | 2i <-actual\n",
      "correct-> us | fc <-actual\n",
      "correct-> ye | yd <-actual\n",
      "correct-> ru | p` <-actual\n",
      "correct-> sh | c` <-actual\n",
      "correct-> ld | mt <-actual\n",
      "correct-> pu |  u <-actual\n",
      "correct-> sh | c` <-actual\n",
      "correct-> is | is <-actual\n",
      "correct->  y | 0` <-actual\n",
      "correct-> ho | jw <-actual\n",
      "correct-> rn | vn <-actual\n",
      "correct-> il | in <-actual\n",
      "correct-> l  | m  <-actual\n",
      "correct-> ye | yd <-actual\n",
      "correct-> sc | sc <-actual\n",
      "correct-> em | um <-actual\n",
      "correct-> br | sr <-actual\n",
      "correct-> oa | og <-actual\n",
      "correct-> d; | v` <-actual\n",
      "correct-> \n",
      "3 | he <-actual\n",
      "correct-> 4: | v( <-actual\n",
      "correct-> 22 | wj <-actual\n",
      "correct->  T | r$ <-actual\n",
      "correct-> il | in <-actual\n",
      "correct-> l  | m  <-actual\n",
      "correct-> I  | )f <-actual\n",
      "correct-> y  | x` <-actual\n",
      "correct-> fl | fi <-actual\n",
      "correct-> oc | oc <-actual\n",
      "correct-> k, | in <-actual\n",
      "correct-> y  | x` <-actual\n",
      "correct-> sh | c` <-actual\n",
      "correct-> l  | m  <-actual\n",
      "correct-> no | no <-actual\n",
      "correct-> \n",
      "p | Go <-actual\n",
      "correct-> y; | s` <-actual\n",
      "correct->  I | 0p <-actual\n",
      "correct-> il | in <-actual\n",
      "correct-> l  | m  <-actual\n",
      "correct-> ju | Ou <-actual\n",
      "correct-> dg | de <-actual\n",
      "correct-> tw | !c <-actual\n",
      "correct-> ee | ee <-actual\n",
      "correct-> tt | ah <-actual\n",
      "correct-> tl | dd <-actual\n",
      "correct-> e. | cn <-actual\n",
      "correct-> 34 | no <-actual\n",
      "correct-> :2 | \u0012q <-actual\n",
      "correct-> I  | )f <-actual\n",
      "correct-> p  | 8  <-actual\n",
      "correct-> sh | c` <-actual\n",
      "correct-> rd | ri <-actual\n",
      "correct-> em | um <-actual\n",
      "correct-> ee | ee <-actual\n",
      "correct-> d\n",
      " | J( <-actual\n",
      "correct-> em | um <-actual\n",
      "correct-> ev | ea <-actual\n",
      "correct-> y  | x` <-actual\n",
      "correct-> rv | 0x <-actual\n",
      "correct-> d; | v` <-actual\n",
      "correct-> sh | c` <-actual\n",
      "correct-> l  | m  <-actual\n",
      "correct-> fe | ne <-actual\n",
      "correct-> m, | on <-actual\n",
      "correct-> sh | c` <-actual\n",
      "correct-> l  | m  <-actual\n",
      "correct-> \n",
      "s | oo <-actual\n",
      "correct-> ph |  i <-actual\n",
      "correct-> d. | p. <-actual\n",
      "correct-> 34 | no <-actual\n",
      "correct-> :2 | \u0012q <-actual\n",
      "correct-> I  | )f <-actual\n",
      "correct-> LO | Go <-actual\n",
      "correct-> RD | ~` <-actual\n",
      "correct-> il | in <-actual\n",
      "correct-> l  | m  <-actual\n",
      "correct-> my | li <-actual\n",
      "correct-> va | ve <-actual\n",
      "correct->  D |  v <-actual\n",
      "correct->  p |    <-actual\n",
      "correct-> ri | ri <-actual\n",
      "correct-> nc | ne <-actual\n",
      "correct-> em | um <-actual\n",
      "correct-> I  | )f <-actual\n",
      "correct-> LO | Go <-actual\n",
      "correct-> RD | ~` <-actual\n",
      "correct-> sp | 1  <-actual\n",
      "correct-> ok | ob <-actual\n",
      "correct-> 34 | no <-actual\n",
      "correct-> :2 | \u0012q <-actual\n",
      "correct-> 5  | 3  <-actual\n",
      "correct-> I  | )f <-actual\n",
      "correct-> ak | e` <-actual\n",
      "correct-> a  | m  <-actual\n",
      "correct-> na | ne <-actual\n",
      "correct-> pe |  a <-actual\n",
      "correct-> e, | cl <-actual\n",
      "correct-> il | in <-actual\n",
      "correct-> l  | m  <-actual\n",
      "correct-> us | fc <-actual\n",
      "correct-> ev | ea <-actual\n",
      "correct-> il | in <-actual\n",
      "correct-> to | dn <-actual\n",
      "correct-> ut | wr <-actual\n",
      "correct-> la | rd <-actual\n",
      "correct-> ey | di <-actual\n",
      "correct-> af | ad <-actual\n",
      "correct-> el | un <-actual\n",
      "correct-> y\n",
      " | :( <-actual\n",
      "correct-> il | in <-actual\n",
      "correct-> rn | vn <-actual\n",
      "correct-> wo | go <-actual\n",
      "correct-> 34 | no <-actual\n",
      "correct-> :2 | \u0012q <-actual\n",
      "correct-> I  | )f <-actual\n",
      "correct-> ak | e` <-actual\n",
      "correct-> em | um <-actual\n",
      "correct->  p |    <-actual\n",
      "correct-> la | rd <-actual\n",
      "correct-> ab | !v <-actual\n",
      "correct-> my | li <-actual\n",
      "correct-> il | in <-actual\n",
      "correct-> l  | m  <-actual\n",
      "correct-> a\n",
      " | N+ <-actual\n",
      "correct-> bl | rm <-actual\n",
      "correct-> I  | )f <-actual\n",
      "correct-> au | cu <-actual\n",
      "correct-> ho | jw <-actual\n",
      "correct-> to | dn <-actual\n",
      "correct-> do | dm <-actual\n",
      "correct-> wn | go <-actual\n",
      "correct-> ;\n",
      " | 3( <-actual\n",
      "correct-> sh | c` <-actual\n",
      "correct-> l  | m  <-actual\n",
      "correct-> ho | jw <-actual\n",
      "correct-> bl | rm <-actual\n",
      "correct-> \n",
      "3 | he <-actual\n",
      "correct-> 4: | v( <-actual\n",
      "correct-> 27 | c. <-actual\n",
      "correct-> ie | ie <-actual\n",
      "correct-> ld | mt <-actual\n",
      "correct->  y | 0` <-actual\n",
      "correct-> ie | ie <-actual\n",
      "correct-> ld | mt <-actual\n",
      "correct-> ru | p` <-actual\n",
      "correct-> h\n",
      " | \n",
      "\n",
      " <-actual\n",
      "correct-> sh | c` <-actual\n",
      "correct-> l  | m  <-actual\n",
      "correct-> yi | ij <-actual\n",
      "correct-> el | un <-actual\n",
      "correct-> cr | qr <-actual\n",
      "correct-> ey | di <-actual\n",
      "correct-> fe | ne <-actual\n",
      "correct-> ei | eh <-actual\n",
      "correct-> la | rd <-actual\n",
      "correct-> d\n",
      " | J( <-actual\n",
      "correct-> sh | c` <-actual\n",
      "correct-> l  | m  <-actual\n",
      "correct-> ow | Oe <-actual\n",
      "correct-> I  | )f <-actual\n",
      "correct-> OR | uh <-actual\n",
      "correct-> D, | r  <-actual\n",
      "correct-> I  | )f <-actual\n",
      "correct-> ke | ku <-actual\n",
      "correct-> ba | ba <-actual\n",
      "correct-> \n",
      "y | f` <-actual\n",
      "correct-> ok | ob <-actual\n",
      "correct-> e, | cl <-actual\n",
      "correct-> el | un <-actual\n",
      "correct-> ho | jw <-actual\n",
      "correct-> rv | 0x <-actual\n",
      "correct-> \n",
      "t | Be <-actual\n",
      "correct-> ms | is <-actual\n",
      "correct-> el | un <-actual\n",
      "correct-> m. | gn <-actual\n",
      "correct-> 34 | no <-actual\n",
      "correct-> :2 | \u0012q <-actual\n",
      "correct-> ey | di <-actual\n",
      "correct->  n | `m <-actual\n",
      "correct-> o  | n  <-actual\n",
      "correct-> a  | m  <-actual\n",
      "correct-> pr |  w <-actual\n",
      "correct-> ey | di <-actual\n",
      "correct-> o  | n  <-actual\n",
      "correct-> n, | ol <-actual\n",
      "correct->  n | `m <-actual\n",
      "correct-> ei | eh <-actual\n",
      "correct-> \n",
      "t | Be <-actual\n",
      "correct-> la | rd <-actual\n",
      "correct-> ev | ea <-actual\n",
      "correct-> em | um <-actual\n",
      "correct-> bu | aq <-actual\n",
      "correct-> ey | di <-actual\n",
      "correct-> af | ad <-actual\n",
      "correct-> el | un <-actual\n",
      "correct-> \n",
      "n | hd <-actual\n",
      "correct-> sh | c` <-actual\n",
      "correct-> l  | m  <-actual\n",
      "correct-> ke | ku <-actual\n",
      "correct-> af | ad <-actual\n",
      "correct-> ra | rm <-actual\n",
      "correct-> \n",
      "3 | he <-actual\n",
      "correct-> 4: | v( <-actual\n",
      "correct-> 29 | an <-actual\n",
      "correct->  I | 0p <-actual\n",
      "correct-> il | in <-actual\n",
      "correct-> l  | m  <-actual\n",
      "correct-> ra | rm <-actual\n",
      "correct-> is | is <-actual\n",
      "correct-> a  | m  <-actual\n",
      "correct-> pl | `f <-actual\n",
      "correct->  r |  f <-actual\n",
      "correct-> ow | Oe <-actual\n",
      "correct-> n, | ol <-actual\n",
      "correct-> y  | x` <-actual\n",
      "correct-> sh | c` <-actual\n",
      "correct-> l\n",
      " | rj <-actual\n",
      "correct->  n | `m <-actual\n",
      "correct-> o  | n  <-actual\n",
      "correct-> su | 2f <-actual\n",
      "correct-> ge | ge <-actual\n",
      "correct->  n | `m <-actual\n",
      "correct-> ei | eh <-actual\n",
      "correct-> sh | c` <-actual\n",
      "correct-> \n",
      "t | Be <-actual\n",
      "correct-> ny | vi <-actual\n",
      "correct-> e. | cn <-actual\n",
      "correct-> 34 | no <-actual\n",
      "correct-> :3 | rg <-actual\n",
      "correct-> 0  | 80 <-actual\n",
      "correct-> us | fc <-actual\n",
      "correct-> y  | x` <-actual\n",
      "correct-> ow | Oe <-actual\n",
      "correct-> I  | )f <-actual\n",
      "correct-> LO | Go <-actual\n",
      "correct-> RD | ~` <-actual\n",
      "correct-> m, | on <-actual\n",
      "correct-> \n",
      "t | Be <-actual\n",
      "correct-> ey | di <-actual\n",
      "correct-> ev | ea <-actual\n",
      "correct-> Is | ip <-actual\n",
      "correct-> ra | rm <-actual\n",
      "correct-> el | un <-actual\n",
      "correct-> my | li <-actual\n",
      "correct->  p |    <-actual\n",
      "correct-> eo | qn <-actual\n",
      "correct-> pl | `f <-actual\n",
      "correct-> e, | cl <-actual\n",
      "correct-> d\n",
      " | J( <-actual\n",
      "correct-> GO | nn <-actual\n",
      "correct-> D. | be <-actual\n",
      "correct-> 34 | no <-actual\n",
      "correct-> :3 | rg <-actual\n",
      "correct-> ye | yd <-actual\n",
      "correct-> y  | x` <-actual\n",
      "correct-> fl | fi <-actual\n",
      "correct-> oc | oc <-actual\n",
      "correct-> k, | in <-actual\n",
      "correct-> lo | oo <-actual\n",
      "correct-> ck | a` <-actual\n",
      "correct-> my | li <-actual\n",
      "correct->  p |    <-actual\n",
      "correct-> tu |  b <-actual\n",
      "correct-> n, | ol <-actual\n",
      "correct->  I | 0p <-actual\n",
      "correct-> yo | if <-actual\n",
      "correct-> ur | eg <-actual\n",
      "correct-> \n",
      "G | n+ <-actual\n",
      "correct-> Lo | on <-actual\n",
      "correct-> rd | ri <-actual\n",
      "correct-> OD | g` <-actual\n",
      "correct-> \n",
      "3 | he <-actual\n",
      "correct-> 5: | o( <-actual\n",
      "correct-> Mo | o. <-actual\n",
      "correct-> ov | o` <-actual\n",
      "correct-> OR | uh <-actual\n",
      "correct-> D  | re <-actual\n",
      "correct-> o  | n  <-actual\n",
      "correct-> yi | ij <-actual\n",
      "correct-> 35 | na <-actual\n",
      "correct-> :2 | \u0012q <-actual\n",
      "correct->  S | \u001a! <-actual\n",
      "correct-> f\n",
      " | G* <-actual\n",
      "correct-> n, | ol <-actual\n",
      "correct-> hy | ni <-actual\n",
      "correct-> ag | ag <-actual\n",
      "correct-> ns | we <-actual\n",
      "correct-> Se | sa <-actual\n",
      "correct-> pr |  w <-actual\n",
      "correct-> op | n  <-actual\n",
      "correct-> sy |  <-actual\n",
      "correct->  3 | \n",
      "a <-actual\n",
      "correct-> 5: | o( <-actual\n",
      "correct-> 3\n",
      " | s\n",
      " <-actual\n",
      "correct-> y  | x` <-actual\n",
      "correct-> to | dn <-actual\n",
      "correct->  T | r$ <-actual\n",
      "correct-> hu | je <-actual\n",
      "correct-> Lo | on <-actual\n",
      "correct-> rd | ri <-actual\n",
      "correct-> OD | g` <-actual\n",
      "correct-> Be | 2i <-actual\n",
      "correct-> ho | jw <-actual\n",
      "correct-> ld | mt <-actual\n",
      "correct-> O  | ng <-actual\n",
      "correct-> Se | sa <-actual\n",
      "correct-> I  | )f <-actual\n",
      "correct-> e, | cl <-actual\n",
      "correct->  I | 0p <-actual\n",
      "correct-> il | in <-actual\n",
      "correct-> l  | m  <-actual\n",
      "correct-> tc | da <-actual\n",
      "correct-> ag | ag <-actual\n",
      "correct-> ns | we <-actual\n",
      "correct-> ee | ee <-actual\n",
      "correct-> I\n",
      " | (o <-actual\n",
      "correct-> ak | e` <-actual\n",
      "correct-> ee | ee <-actual\n",
      "correct-> so | cj <-actual\n",
      "correct-> la | rd <-actual\n",
      "correct-> \n",
      "3 | he <-actual\n",
      "correct-> 5: | o( <-actual\n",
      "correct-> I  | )f <-actual\n",
      "correct-> hy | ni <-actual\n",
      "correct-> ie | ie <-actual\n",
      "correct-> e, | cl <-actual\n",
      "correct-> ho | jw <-actual\n",
      "correct-> u  | w  <-actual\n",
      "correct-> sh | c` <-actual\n",
      "correct-> ol | ol <-actual\n",
      "correct-> e, | cl <-actual\n",
      "correct-> ho | jw <-actual\n",
      "correct-> u\n",
      " | (* <-actual\n",
      "correct-> sh | c` <-actual\n",
      "correct-> ow | Oe <-actual\n",
      "correct-> I  | )f <-actual\n",
      "correct-> OR | uh <-actual\n",
      "correct-> D. | be <-actual\n",
      "correct-> 35 | na <-actual\n",
      "correct-> ec | ek <-actual\n",
      "correct-> au | cu <-actual\n",
      "correct-> ho | jw <-actual\n",
      "correct-> u  | w  <-actual\n",
      "correct-> ad | ad <-actual\n",
      "correct->  p |    <-actual\n",
      "correct-> pe |  a <-actual\n",
      "correct-> tu |  b <-actual\n",
      "correct-> sh | c` <-actual\n",
      "correct-> lo | oo <-actual\n",
      "correct-> \n",
      "o | ht <-actual\n",
      "correct-> il | in <-actual\n",
      "correct-> dr |  r <-actual\n",
      "correct-> Is | ip <-actual\n",
      "correct-> ra | rm <-actual\n",
      "correct-> el | un <-actual\n",
      "correct-> y  | x` <-actual\n",
      "correct-> rc | rg <-actual\n",
      "correct-> wo | go <-actual\n",
      "correct-> rd | ri <-actual\n",
      "correct-> ti | ti <-actual\n",
      "correct-> f\n",
      " | G* <-actual\n",
      "correct-> ei | eh <-actual\n",
      "correct-> la | rd <-actual\n",
      "correct-> ty | 0h <-actual\n",
      "correct-> im | qo <-actual\n",
      "correct-> qu | a` <-actual\n",
      "correct-> y  | x` <-actual\n",
      "correct-> 35 | na <-actual\n",
      "correct-> :6 | x( <-actual\n",
      "correct->  I | 0p <-actual\n",
      "correct-> e, | cl <-actual\n",
      "correct-> GO | nn <-actual\n",
      "correct-> D, | r  <-actual\n",
      "correct->  I | 0p <-actual\n",
      "correct-> il | in <-actual\n",
      "correct-> l  | m  <-actual\n",
      "correct-> pr |  w <-actual\n",
      "correct-> ee | ee <-actual\n",
      "correct-> o\n",
      " | g\n",
      " <-actual\n",
      "correct-> bl | rm <-actual\n",
      "correct-> lo | oo <-actual\n",
      "correct->  p |    <-actual\n",
      "correct-> ur | eg <-actual\n",
      "correct-> su | 2f <-actual\n",
      "correct-> ee | ee <-actual\n",
      "correct-> ho | jw <-actual\n",
      "correct-> u  | w  <-actual\n",
      "correct->  n | `m <-actual\n",
      "correct-> ot | mt <-actual\n",
      "correct-> lo | oo <-actual\n",
      "correct-> ,\n",
      " | ra <-actual\n",
      "correct-> ev | ea <-actual\n",
      "correct-> lo | oo <-actual\n",
      "correct->  p |    <-actual\n",
      "correct-> ur | eg <-actual\n",
      "correct-> su | 2f <-actual\n",
      "correct-> ee | ee <-actual\n",
      "correct-> \n",
      "3 | he <-actual\n",
      "correct-> 5: | o( <-actual\n",
      "correct-> us | fc <-actual\n",
      "correct-> il | in <-actual\n",
      "correct-> l  | m  <-actual\n",
      "correct-> I  | )f <-actual\n",
      "correct-> ke | ku <-actual\n",
      "correct->  S | \u001a! <-actual\n",
      "correct-> ei | eh <-actual\n",
      "correct-> ol | ol <-actual\n",
      "correct-> e, | cl <-actual\n",
      "correct-> ut | wr <-actual\n",
      "correct-> ff | va <-actual\n",
      "correct-> \n",
      "h | jm <-actual\n",
      "correct-> im | qo <-actual\n",
      "correct-> pa |  e <-actual\n",
      "correct->  r |  f <-actual\n",
      "correct-> ur | eg <-actual\n",
      "correct-> \n",
      "3 | he <-actual\n",
      "correct-> 5: | o( <-actual\n",
      "correct-> I  | )f <-actual\n",
      "correct-> il | in <-actual\n",
      "correct-> l  | m  <-actual\n",
      "correct-> ta | de <-actual\n",
      "correct-> is | is <-actual\n",
      "correct-> la | rd <-actual\n",
      "correct-> hy | ni <-actual\n",
      "correct-> il | in <-actual\n",
      "correct-> ls | z# <-actual\n",
      "correct-> ,\n",
      " | ra <-actual\n",
      "correct-> hy | ni <-actual\n",
      "correct->  v |  t <-actual\n",
      "correct-> ys | oj <-actual\n",
      "correct-> hy | ni <-actual\n",
      "correct->  r |  f <-actual\n",
      "correct-> y  | x` <-actual\n",
      "correct-> sl | aj <-actual\n",
      "correct-> wo | go <-actual\n",
      "correct-> rd | ri <-actual\n",
      "correct-> \n",
      "3 | he <-actual\n",
      "correct-> 5: | o( <-actual\n",
      "correct-> 9  | 8  <-actual\n",
      "correct-> I  | )f <-actual\n",
      "correct-> ak | e` <-actual\n",
      "correct-> ee | ee <-actual\n",
      "correct->  p |    <-actual\n",
      "correct-> pe |  a <-actual\n",
      "correct-> tu |  b <-actual\n",
      "correct-> ol | ol <-actual\n",
      "correct-> ns | we <-actual\n",
      "correct-> y  | x` <-actual\n",
      "correct-> ci | ei <-actual\n",
      "correct-> ti | ti <-actual\n",
      "correct->  n | `m <-actual\n"
     ]
    }
   ],
   "source": [
    "wrong_idx = []\n",
    "correct_idx = []\n",
    "\n",
    "for i in range(size):\n",
    "    correct = prediction_to_string(test_labels2[i])\n",
    "    predicted = prediction_to_string(predictions[i])\n",
    "    if correct != predicted:\n",
    "        wrong_idx.append(i)\n",
    "    else:\n",
    "        correct_idx.append(i)\n",
    "    print(\"correct-> \" + correct + \" | \" + predicted + \" <-actual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
